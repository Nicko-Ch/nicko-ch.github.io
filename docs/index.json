[{"content":"分布式缓存 Hash算法 简述 对资源进行取模运算：hash(资源) % 机器数 = 余数\n然后去余数对应的服务器存取资源\n缺点：一旦机器数量变更，将导致所有缓存失效\n一致性Hash 简述 设置一个Hash环，大小为2^32\n对资源进行取模运算：hash(资源) % 2^32 = 余数\n然后顺时针的往下寻找服务器\n优点：相较于hash算法，激起数量的变更，一致性hash只会导致部分缓存失效\n缺点：因为不均衡，产生hash偏斜，可能会导致大量缓存跑到某一台服务器\nHash偏斜 解决方法：新增虚拟节点，让分布尽可能均匀\n","permalink":"https://nicko-ch.github.io/posts/solution/20221203-%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/","summary":"分布式缓存 Hash算法 简述 对资源进行取模运算：hash(资源) % 机器数 = 余数\n然后去余数对应的服务器存取资源\n缺点：一旦机器数量变更，将导致所有缓存失效\n一致性Hash 简述 设置一个Hash环，大小为2^32\n对资源进行取模运算：hash(资源) % 2^32 = 余数\n然后顺时针的往下寻找服务器\n优点：相较于hash算法，激起数量的变更，一致性hash只会导致部分缓存失效\n缺点：因为不均衡，产生hash偏斜，可能会导致大量缓存跑到某一台服务器\nHash偏斜 解决方法：新增虚拟节点，让分布尽可能均匀","title":"分布式缓存"},{"content":"限流算法 1 漏桶算法 假设当前请求b到来，at为上一次请求处理时间，w为剩余容量，c为总容量，r为滴漏速度\n伪代码 when(b): bt = now() // b到来时间为当前时间 \twb = (bt - at) * r // b到来的过程量=（b时间 - 上一次请求时间）* 流速 \tw = max(w - wb, 0) // 剩余容量 = 最大值（剩余容量 - wb带来的容量，0） 木桶剩余最小为0 if(w \u0026lt; c) // 如果剩余容量未满 \tw++ // 剩余容量++ \treturn true else: return false 2 令牌桶算法 假设当前请求b到来，at为上一次请求处理时间，w为剩余容量，c为总容量，r为滴漏速度\n伪代码 when(b): bt = now() // b到来时间为当前时间 \twb = (bt - at) * r // b到来的过程量=（b时间 - 上一次请求时间）* 流速 \tw = min(w + wb, c) // 剩余容量 = 最小值（剩余容量 + wb带来的容量，c） if (w \u0026gt; 1): // 如果桶内令牌大于1 \tw-- // 令牌-- \treturn true else: return false 3 比较 放入速度\n漏桶：不固定\n令牌：固定\n处理速度\n漏桶：固定\n令牌：不固定\n故：漏桶多用于系统整流， 令牌桶多用于突发流量\n","permalink":"https://nicko-ch.github.io/posts/solution/20221112-%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/","summary":"限流算法 1 漏桶算法 假设当前请求b到来，at为上一次请求处理时间，w为剩余容量，c为总容量，r为滴漏速度\n伪代码 when(b): bt = now() // b到来时间为当前时间 \twb = (bt - at) * r // b到来的过程量=（b时间 - 上一次请求时间）* 流速 \tw = max(w - wb, 0) // 剩余容量 = 最大值（剩余容量 - wb带来的容量，0） 木桶剩余最小为0 if(w \u0026lt; c) // 如果剩余容量未满 \tw++ // 剩余容量++ \treturn true else: return false 2 令牌桶算法 假设当前请求b到来，at为上一次请求处理时间，w为剩余容量，c为总容量，r为滴漏速度\n伪代码 when(b): bt = now() // b到来时间为当前时间 \twb = (bt - at) * r // b到来的过程量=（b时间 - 上一次请求时间）* 流速 \tw = min(w + wb, c) // 剩余容量 = 最小值（剩余容量 + wb带来的容量，c） if (w \u0026gt; 1): // 如果桶内令牌大于1 \tw-- // 令牌-- \treturn true else: return false 3 比较 放入速度","title":"限流算法"},{"content":"设计与实现 前言 查询数据类型 OBJECT ENCODING {key} 1. 基础数据类型 1.1 SDS 与 C字符串 区别 1.1.1 SDS简单动态字符串定义 struct sdshdr{ //记录buf数组中已使用字节的数量  //等于 SDS 保存字符串的长度  int len; //记录 buf 数组中未使用字节的数量  int free; //字节数组，用于保存字符串  char buf[]; } 1.1.2 可重用C函数 SDS遵循与C语言字符串一样的规则，以‘\\0’(空字符)结尾，所以SDS可以直接重用部分C语言的字符串函数。（空字符不计入len属性，所以对于SDS使用者完全透明）\n1.1.3 二进制安全 泛指二进制数据在传输、存储、读取的时候都不会被篡改，如C语言中的字符串类型必须为空字符（\\0）结束，则后续如果跟有其他数据，则读取处理将会跟原数据不同，即非二进制安全\n例如：\n在C语言中读取会返回“Redis”，空字符往后的则被忽略。 而在Redis中读取会返回“Redis Cluster ”，以len属性判断字符串是否结束\n1.1.4 获取长度 C语言字符串获取长度，需要遍历字符串中的每一位进行累加计算，时间复杂度为O(N)\nSDS获取长度，只需要直接获取len属性，时间复杂度为O(1)\n1.1.5 杜绝缓冲区溢出  C字符串中，如果未给变量申请足够的空间，进行了如srtcat复制操作，将可能导致新字符串过长，导致变量内存内容被覆盖。 与C语言不同，SDS会闲计算自身空间，如果不足会自动扩展。  1.1.6 空间预分配 为了防止频繁的进行空间分配，SDS每次扩容的时候都会进行一定的冗余扩充\n 如果对 SDS 进行修改之后， SDS 的长度（也即是 len 属性的值）将小于 1 MB ， 那么程序分配和 len 属性同样大小的未使用空间， 这时 SDS len 属性的值将和 free 属性的值相同。 举个例子， 如果进行修改之后， SDS 的 len 将变成 13 字节， 那么程序也会分配13 字节的未使用空间， SDS 的 buf 数组的实际长度将变成 13 + 13 + 1 = 27 字节（额外的一字节用于保存空字符）。 如果对 SDS 进行修改之后， SDS 的长度将大于等于 1 MB ， 那么程序会分配 1 MB 的未使用空间。 举个例子， 如果进行修改之后， SDS 的 len 将变成 30 MB ， 那么程序会分配 1 MB 的未使用空间， SDS 的 buf 数组的实际长度将为 30 MB + 1 MB + 1 byte 。  1.1.7 空间惰性释放 同样为了防止内存空间频繁调整，当SDS进行缩容的时候，并不会立即释放空间，而是将空余的容量加到free属性中。\n总结 C 字符串和 SDS 之间的区别\n1.2 链表 1.2.1 链表定义 typedef struct listNode { // 前置节点  struct listNode *prev; // 后置节点  struct listNode *next; // 节点的值  void *value; } listNode; 虽然仅仅使用多个 listNode 结构就可以组成链表， 但使用 adlist.h/list 来持有链表的话， 操作起来会更方便：\ntypedef struct list { // 表头节点  listNode *head; // 表尾节点  listNode *tail; // 链表所包含的节点数量  unsigned long len; // 节点值复制函数  void *(*dup)(void *ptr); // 节点值释放函数  void (*free)(void *ptr); // 节点值对比函数  int (*match)(void *ptr, void *key); } list; list 结构为链表提供了表头指针 head 、表尾指针 tail ， 以及链表长度计数器 len ， 而 dup 、 free 和 match 成员则是用于实现多态链表所需的类型特定函数：\n dup 函数用于复制链表节点所保存的值； free 函数用于释放链表节点所保存的值； match 函数则用于对比链表节点所保存的值和另一个输入值是否相等。  1.2.2 特性 Redis 的链表实现的特性可以总结如下：\n 双端： 链表节点带有 prev 和 next 指针， 获取某个节点的前置节点和后置节点的复杂度都是O(1)。 无环： 表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL ， 对链表的访问以 NULL 为终点。 带表头指针和表尾指针： 通过 list 结构的 head 指针和 tail 指针， 程序获取链表的表头节点和表尾节点的复杂度为O(1)。 带链表长度计数器： 程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数， 程序获取链表中节点数量的复杂度为O(1)。 多态： 链表节点使用 void* 指针来保存节点值， 并且可以通过 list 结构的 dup 、 free 、 match 三个属性为节点值设置类型特定函数， 所以链表可以用于保存各种不同类型的值。  1.3 字典 1.3.1 底层结构 哈希表\ntypedef struct dictht { // 哈希表数组  dictEntry **table; // 哈希表大小  unsigned long size; // 哈希表大小掩码，用于计算索引值  // 总是等于 size - 1  unsigned long sizemask; // 该哈希表已有节点的数量  unsigned long used; } dictht; table 属性是一个数组， 数组中的每个元素都是一个指向 dict.h/dictEntry 结构的指针， 每个 dictEntry 结构保存着一个键值对。\nsize 属性记录了哈希表的大小， 也即是 table 数组的大小， 而 used 属性则记录了哈希表目前已有节点（键值对）的数量。\nsizemask 属性的值总是等于 size - 1 ， 这个属性和哈希值一起决定一个键应该被放到 table 数组的哪个索引上面。\n哈希表节点\ntypedef struct dictEntry { // 键  void *key; // 值  union { void *val; uint64_t u64; int64_t s64; } v; // 指向下个哈希表节点，形成链表  struct dictEntry *next; } dictEntry; key 属性保存着键值对中的键， 而 v 属性则保存着键值对中的值， 其中键值对的值可以是一个指针， 或者是一个 uint64_t 整数， 又或者是一个 int64_t 整数。\nnext 属性是指向另一个哈希表节点的指针， 这个指针可以将多个哈希值相同的键值对连接在一次， 以此来解决键冲突（collision）的问题。\n举个例子， 图 4-2 就展示了如何通过 next 指针， 将两个索引值相同的键 k1 和 k0 连接在一起。\n字典\ntypedef struct dict { // 类型特定函数  dictType *type; // 私有数据  void *privdata; // 哈希表  dictht ht[2]; // rehash 索引  // 当 rehash 不在进行时，值为 -1  int rehashidx; /* rehashing not in progress if rehashidx == -1 */ } dict; type 属性和 privdata 属性是针对不同类型的键值对， 为创建多态字典而设置的：\n type 属性是一个指向 dictType 结构的指针， 每个 dictType 结构保存了一簇用于操作特定类型键值对的函数， Redis 会为用途不同的字典设置不同的类型特定函数。 而 privdata 属性则保存了需要传给那些类型特定函数的可选参数。  1.3.2 解决键冲突 Redis 的哈希表使用链地址法（separate chaining）来解决键冲突： 每个哈希表节点都有一个 next 指针， 多个哈希表节点可以用 next 指针构成一个单向链表， 被分配到同一个索引上的多个节点可以用这个单向链表连接起来， 这就解决了键冲突的问题。\n举个例子， 假设程序要将键值对 k2 和 v2 添加到图 4-6 所示的哈希表里面， 并且计算得出 k2 的索引值为 2 ， 那么键 k1 和 k2 将产生冲突， 而解决冲突的办法就是使用 next 指针将键 k2 和 k1 所在的节点连接起来， 如图 4-7 所示。\n1.3.3 rehash 扩展和收缩哈希表的工作可以通过执行 rehash （重新散列）操作来完成， Redis 对字典的哈希表执行 rehash 的步骤如下：\n 为字典的 ht[1] 哈希表分配空间， 这个哈希表的空间大小取决于要执行的操作， 以及 ht[0] 当前包含的键值对数量 （也即是ht[0].used 属性的值）：  如果执行的是扩展操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 （2 的 n 次方幂）； 如果执行的是收缩操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 （2 的 n 次方幂）。   将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上。 当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）， 释放 ht[0] ， 将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表， 为下一次 rehash 做准备。   rehash并不是一步到位，而是每次重算并转移hash键值对，并且记录当前转换偏移量在字典的rehashidx 属性，下次直接从偏移量开始转移，直到变为空表\n 1.4 跳表 1.4.1 基础结构 typedef struct zskiplistNode { // 后退指针  struct zskiplistNode *backward; // 分值  double score; // 成员对象  robj *obj; // 层  struct zskiplistLevel { // 前进指针  struct zskiplistNode *forward; // 跨度  unsigned int span; } level[]; } zskiplistNode; 跳表的优点是讲链表中节点查询的时间复杂度优化到平均O(logN)、最坏O(N)，还可以顺序性地操作节点。\n跳表基础结构，类似基于链表，按一定规律拆分出层级作为索引层，查询时自上而下的从索引层进行查询，实现了二分查找的数据结构。\n1.5 整数集合 1.5.1 基本结构 typedef struct intset { // 编码方式  uint32_t encoding; // 集合包含的元素数量  uint32_t length; // 保存元素的数组  int8_t contents[]; } intset; 1.5.2 升级 contents属性虽然类型为int8_t，但是其实际的内存存储类型是由encoding属性决定的。即新加入的数据如果超出了原有encoding属性的大小，则整数集合将会升级，将新数据前的所有数据计算好空间分配，倒序的讲一个一个的数据重新赋值。因此向整数集合添加新元素的时间复杂度为O(N)。\n 整数集合不支持降级操作\n 1.6 压缩链表 1.6.1 基本结构 表头\n表头包括四个部分，分别是内存字节数zlbytes，尾节点距离起始地址的字节数zltail_offset，节点数量zllength，标志结束的记号zlend。\nhttps://user-gold-cdn.xitu.io/2020/6/30/173045e086679c6a?w=230\u0026amp;h=45\u0026amp;f=jpeg\u0026amp;s=3785\nhttps://user-gold-cdn.xitu.io/2020/6/30/173045e2c18692c4?w=66\u0026amp;h=45\u0026amp;f=jpeg\u0026amp;s=1382\n zlbytes：记录整个压缩列表占用的内存字节数。 zltail_offset：记录压缩列表尾节点距离压缩列表的起始地址的字节数（目的是为了直接定位到尾节点，方便反向查询）。 zllength：记录了压缩列表的节点数量。即在上图中节点数量为2。 zlend：保存一个常数255(0xFF)，标记压缩列表的末端。  数据节点 数据节点包括三个部分，分别是前一个节点的长度prev_entry_len，当前数据类型和编码格式encoding，具体数据指针value。\nhttps://user-gold-cdn.xitu.io/2020/6/30/173049b68b0ad426?w=271\u0026amp;h=45\u0026amp;f=jpeg\u0026amp;s=4034\n prev_entry_len：记录前驱节点的长度。 encoding：记录当前数据类型和编码格式。 value：存放具体的数据。  1.6.2 遍历过程 展示了一个从表尾节点向表头节点进行遍历的完整过程：\n 首先，我们拥有指向压缩列表表尾节点 entry4 起始地址的指针 p1 （指向表尾节点的指针可以通过指向压缩列表起始地址的指针加上zltail 属性的值得出）； 通过用 p1 减去 entry4 节点 previous_entry_length 属性的值， 我们得到一个指向 entry4 前一节点 entry3 起始地址的指针 p2 ； 通过用 p2 减去 entry3 节点 previous_entry_length 属性的值， 我们得到一个指向 entry3 前一节点 entry2 起始地址的指针 p3 ； 通过用 p3 减去 entry2 节点 previous_entry_length 属性的值， 我们得到一个指向 entry2 前一节点 entry1 起始地址的指针 p4 ， entry1为压缩列表的表头节点； 最终， 我们从表尾节点向表头节点遍历了整个列表。  1.6.3 连锁更新 因为previous_entry_length 属性仅长 1 字节，假如新添加的数据长度大于254（大于1字节），则需要将后续链表中的所有previous_entry_length 属性扩展为5 字节 ，然后重新计算属性值，这过程称为连锁更新 ，而重新分配空间的最坏复杂度为O（N的2次方）\n1.6.4 总结  压缩列表是一种为节约内存而开发的顺序型数据结构。 压缩列表被用作列表键和哈希键的底层实现之一。 压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者整数值。 添加新节点到压缩列表， 或者从压缩列表中删除节点， 可能会引发连锁更新操作， 但这种操作出现的几率并不高。  1.7 对象 1.7.1 对象定义 typedef struct redisObject { // 类型  unsigned type:4; // 编码  unsigned encoding:4; // 指向底层实现数据结构的指针  void *ptr; // ...  } robj; redis的对象分为键对象和值对象 ，一般的键对象都为字符串对象，所以称呼对象一般都以值对象为准。\n1.7.2 内存回收 因为C语言不具备自动内存回收机制，所以Redis自己构建了一套以引用计数为基础的回收机制。即当某一对象被引用，对象的refcount（引用计数）属性将+1，当对象不再引用则计数-1，直到计数为0时候，对象将会被释放。\n1.7.3 对象共享 除了用于实现引用计数内存回收机制之外， 对象的引用计数属性还带有对象共享的作用。\n举个例子， 图 8-21 就展示了包含整数值 100 的字符串对象同时被键 A 和键 B 共享之后的样子， 可以看到， 除了对象的引用计数从之前的 1 变成了 2 之外， 其他属性都没有变化。\n共享对象机制对于节约内存非常有帮助， 数据库中保存的相同值对象越多， 对象共享机制就能节约越多的内存。\n为什么 Redis 不共享键的字符串对象？\n当服务器考虑将一个共享对象设置为键的值对象时， 程序需要先检查给定的共享对象和键想创建的目标对象是否完全相同， 只有在共享对象和目标对象完全相同的情况下， 程序才会将共享对象用作键的值对象， 而一个共享对象保存的值越复杂， 验证共享对象和目标对象是否相同所需的复杂度就会越高， 消耗的 CPU 时间也会越多：\n 如果共享对象是保存整数值的字符串对象， 那么验证操作的复杂度为O(1) ； 如果共享对象是保存字符串值的字符串对象， 那么验证操作的复杂度为O(N) ； 如果共享对象是包含了多个值（或者对象的）对象， 比如列表对象或者哈希对象， 那么验证操作的复杂度将会是O(N的2次方) 。  因此， 尽管共享更复杂的对象可以节约更多的内存， 但受到 CPU 时间的限制， Redis 只对包含整数值的字符串对象进行共享。\n2 单机数据库的实现 2.1 数据库 2.2 RDB文件结构 2.3 AOF文件结构 3. 多机数据库的实现 3.1 主从复制 Redis复制功能分为同步（sync）和命令传播（command propageate）两个操作；\n同步：将从服务器更新与主服务器状态一致\n命令传播：将主服务器中的修改命令，发送至从服务器进行运行，让主从服务器重回一致状态\n3.2 同步 步骤：\n 从服务器向主服务器发送 SYNC 命令。 收到 SYNC 命令的主服务器执行 BGSAVE 命令， 在后台生成一个 RDB 文件， 并使用一个缓冲区记录从现在开始执行的所有写命令。 当主服务器的 BGSAVE 命令执行完毕时， 主服务器会将 BGSAVE 命令生成的 RDB 文件发送给从服务器， 从服务器接收并载入这个 RDB 文件， 将自己的数据库状态更新至主服务器执行 BGSAVE 命令时的数据库状态。 主服务器将记录在缓冲区里面的所有写命令发送给从服务器， 从服务器执行这些写命令， 将自己的数据库状态更新至主服务器数据库当前所处的状态。  3.3 命令传播 在同步操作执行完毕之后， 主从服务器两者的数据库将达到一致状态， 但这种一致并不是一成不变的 —— 每当主服务器执行客户端发送的写命令时， 主服务器的数据库就有可能会被修改， 并导致主从服务器状态不再一致。\n举个例子， 假设一个主服务器和一个从服务器刚刚完成同步操作， 它们的数据库都保存了相同的五个键 k1 至 k5 ， 如图 IMAGE_CONSISTENT 所示。\n如果这时， 客户端向主服务器发送命令 DEL k3 ， 那么主服务器在执行完这个 DEL 命令之后， 主从服务器的数据库将出现不一致： 主服务器的数据库已经不再包含键 k3 ， 但这个键却仍然包含在从服务器的数据库里面， 如图 IMAGE_INCONSISTENT 所示。\n为了让主从服务器再次回到一致状态， 主服务器需要对从服务器执行命令传播操作： 主服务器会将自己执行的写命令 —— 也即是造成主从服务器不一致的那条写命令 —— 发送给从服务器执行， 当从服务器执行了相同的写命令之后， 主从服务器将再次回到一致状态。\n在上面的例子中， 主服务器因为执行了命令 DEL k3 而导致主从服务器不一致， 所以主服务器将向从服务器发送相同的命令 DEL k3 ： 当从服务器执行完这个命令之后， 主从服务器将再次回到一致状态 —— 现在主从服务器两者的数据库都不再包含键 k3 了， 如图 IMAGE_PROPAGATE_DEL_k3 所示。\n","permalink":"https://nicko-ch.github.io/posts/redis/20220916-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/","summary":"设计与实现 前言 查询数据类型 OBJECT ENCODING {key} 1. 基础数据类型 1.1 SDS 与 C字符串 区别 1.1.1 SDS简单动态字符串定义 struct sdshdr{ //记录buf数组中已使用字节的数量  //等于 SDS 保存字符串的长度  int len; //记录 buf 数组中未使用字节的数量  int free; //字节数组，用于保存字符串  char buf[]; } 1.1.2 可重用C函数 SDS遵循与C语言字符串一样的规则，以‘\\0’(空字符)结尾，所以SDS可以直接重用部分C语言的字符串函数。（空字符不计入len属性，所以对于SDS使用者完全透明）\n1.1.3 二进制安全 泛指二进制数据在传输、存储、读取的时候都不会被篡改，如C语言中的字符串类型必须为空字符（\\0）结束，则后续如果跟有其他数据，则读取处理将会跟原数据不同，即非二进制安全\n例如：\n在C语言中读取会返回“Redis”，空字符往后的则被忽略。 而在Redis中读取会返回“Redis Cluster ”，以len属性判断字符串是否结束\n1.1.4 获取长度 C语言字符串获取长度，需要遍历字符串中的每一位进行累加计算，时间复杂度为O(N)\nSDS获取长度，只需要直接获取len属性，时间复杂度为O(1)\n1.1.5 杜绝缓冲区溢出  C字符串中，如果未给变量申请足够的空间，进行了如srtcat复制操作，将可能导致新字符串过长，导致变量内存内容被覆盖。 与C语言不同，SDS会闲计算自身空间，如果不足会自动扩展。  1.1.6 空间预分配 为了防止频繁的进行空间分配，SDS每次扩容的时候都会进行一定的冗余扩充\n 如果对 SDS 进行修改之后， SDS 的长度（也即是 len 属性的值）将小于 1 MB ， 那么程序分配和 len 属性同样大小的未使用空间， 这时 SDS len 属性的值将和 free 属性的值相同。 举个例子， 如果进行修改之后， SDS 的 len 将变成 13 字节， 那么程序也会分配13 字节的未使用空间， SDS 的 buf 数组的实际长度将变成 13 + 13 + 1 = 27 字节（额外的一字节用于保存空字符）。 如果对 SDS 进行修改之后， SDS 的长度将大于等于 1 MB ， 那么程序会分配 1 MB 的未使用空间。 举个例子， 如果进行修改之后， SDS 的 len 将变成 30 MB ， 那么程序会分配 1 MB 的未使用空间， SDS 的 buf 数组的实际长度将为 30 MB + 1 MB + 1 byte 。  1.","title":"设计与实现"},{"content":"I/O多路复用 1、什么是I/O多路复用  **单线程或单进程同时监测若干个文件描述符是否可以执行IO操作的能力**\n 2、流？I/O操作？阻塞？ （1）流  可以进行I/O操作的内核对象 文件、管道、套接字…… 流的入口：文件描述符(fd)  （2）I/O操作 所有对流的读写操作，我们都可以称之为IO操作。\n（3）阻塞 阻塞场景: 你有一份快递，家里有个座机，快递到了主动给你打电话，期间你可以休息。\n非阻塞，忙轮询场景: 你性子比较急躁， 每分钟就要打电话询问快递小哥一次， 到底有没有到，快递员接你电话要停止运输，这样很耽误快递小哥的运输速度。\n3、解决阻塞等待办法 （1）非阻塞、忙轮询 伪代码 while true { for i in 流[] { if i has 数据 { 读 或者 其他处理 } } } 特点  用户态不断请求内核态查看IO情况 请求间隔短会导致cpu无效占用率高 请求间隔长会导致io长时间无法处理  （2）select 伪代码 while true { select(流[]); //阻塞  //有消息抵达 \tfor i in 流[] { if i has 数据 { 读 或者 其他处理 } } } 特点  时间复杂度O(n) 开设一个代接收点，待内核态有io处理信号，则返回告诉用户 select只能通知用户IO事件发生，无法准确告诉是哪个IO流待处理，需要用户遍历查找 实现底层用的数组结构，理论上有最大连接数：1024(x86) 或 2048(x64) 每次调用select，都需要把集合fd从用户态拷贝到内核态  （3）poll 原理与select类似，但实现底层结构更换为链表，理论上没有最大连接数限制\n（4）epoll 伪代码 while true { 可处理的流[] = epoll_wait(epoll_fd); //阻塞  //有消息抵达，全部放在 “可处理的流[]”中 \tfor i in 可处理的流[] { 读 或者 其他处理 } } 触发方式 (1) 水平触发\n水平触发的主要特点是，如果用户在监听epoll事件，当内核有事件的时候，会拷贝给用户态事件，但是如果用户只处理了一次，那么剩下没有处理的会在下一次epoll_wait再次返回该事件。\n(2) 边缘触发\n边缘触发，相对跟水平触发相反，当内核有事件到达， 只会通知用户一次，至于用户处理还是不处理，以后将不会再通知。这样减少了拷贝过程，增加了性能，但是相对来说，如果用户马虎忘记处理，将会产生事件丢的情况。\n特点  时间复杂度O(1) 底层实现哈希表 事件通知，系统注册的回调函数被触发，将就绪fd防盗rdlist里面，用户可直接处理io请求 调用epoll_ctl时拷贝进内核并保存，之后每次epoll_wait不拷贝  （5）select、poll与epoll区别    \\ select poll epoll     操作方式 遍历 遍历 回调   底层实现 数组 链表 哈希表   IO效率 每次调用都进行线性遍历，时间复杂度为O(n) 每次调用都进行线性遍历，时间复杂度为O(n) 事件通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到rdllist里面。时间复杂度O(1)   最大连接数 1024（x86）或 2048（x64） 无上限 无上限   fd拷贝 每次调用select，都需要把fd集合从用户态拷贝到内核态 每次调用poll，都需要把fd集合从用户态拷贝到内核态 调用epoll_ctl时拷贝进内核并保存，之后每次epoll_wait不拷贝    ","permalink":"https://nicko-ch.github.io/posts/computer-principles/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/20220822-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","summary":"I/O多路复用 1、什么是I/O多路复用  **单线程或单进程同时监测若干个文件描述符是否可以执行IO操作的能力**\n 2、流？I/O操作？阻塞？ （1）流  可以进行I/O操作的内核对象 文件、管道、套接字…… 流的入口：文件描述符(fd)  （2）I/O操作 所有对流的读写操作，我们都可以称之为IO操作。\n（3）阻塞 阻塞场景: 你有一份快递，家里有个座机，快递到了主动给你打电话，期间你可以休息。\n非阻塞，忙轮询场景: 你性子比较急躁， 每分钟就要打电话询问快递小哥一次， 到底有没有到，快递员接你电话要停止运输，这样很耽误快递小哥的运输速度。\n3、解决阻塞等待办法 （1）非阻塞、忙轮询 伪代码 while true { for i in 流[] { if i has 数据 { 读 或者 其他处理 } } } 特点  用户态不断请求内核态查看IO情况 请求间隔短会导致cpu无效占用率高 请求间隔长会导致io长时间无法处理  （2）select 伪代码 while true { select(流[]); //阻塞  //有消息抵达 \tfor i in 流[] { if i has 数据 { 读 或者 其他处理 } } } 特点  时间复杂度O(n) 开设一个代接收点，待内核态有io处理信号，则返回告诉用户 select只能通知用户IO事件发生，无法准确告诉是哪个IO流待处理，需要用户遍历查找 实现底层用的数组结构，理论上有最大连接数：1024(x86) 或 2048(x64) 每次调用select，都需要把集合fd从用户态拷贝到内核态  （3）poll 原理与select类似，但实现底层结构更换为链表，理论上没有最大连接数限制","title":"计算机考研408 - I/O多路复用"},{"content":"描述 快速排序是对插入算法的一种优化，利用对问题的二分化，实现递归完成快速排序 ，在所有算法中二分化是最常用的方式，将问题尽量的分成两种情况加以分析， 最终以形成类似树的方式加以利用，因为在比较模型中的算法中，最快的排序时间复杂度为 O(log~n~).\n原理  选取边界值：temp 遍历比较数组中每个值与边界值大小关系：小于边界值放小于数组，大于边界值放大于数组 递归排序大、小数组 合并返回当前已排完序数组  PS：注意递归结束条件，数组中长度小于2，代表\npackage main import \u0026#34;fmt\u0026#34; func main() { sortSlice := quickSort([]int{1, 9, 10, 30, 2, 5, 45, 8, 63, 234, 12}) fmt.Println(sortSlice) } func quickSort(arr []int) []int { if len(arr) \u0026lt;= 2 { return arr } temp := arr[0] var low, high = make([]int, 0), make([]int, 0) for i := 1; i \u0026lt; len(arr); i++ { if arr[i] \u0026lt; temp { low = append(low, arr[i]) } else { high = append(high, arr[i]) } } lowSlice := quickSort(low) highSlice := quickSort(high) return append(append(lowSlice, temp), highSlice...) } ","permalink":"https://nicko-ch.github.io/posts/computer-principles/%E7%AE%97%E6%B3%95/20220418-%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/","summary":"描述 快速排序是对插入算法的一种优化，利用对问题的二分化，实现递归完成快速排序 ，在所有算法中二分化是最常用的方式，将问题尽量的分成两种情况加以分析， 最终以形成类似树的方式加以利用，因为在比较模型中的算法中，最快的排序时间复杂度为 O(log~n~).\n原理  选取边界值：temp 遍历比较数组中每个值与边界值大小关系：小于边界值放小于数组，大于边界值放大于数组 递归排序大、小数组 合并返回当前已排完序数组  PS：注意递归结束条件，数组中长度小于2，代表\npackage main import \u0026#34;fmt\u0026#34; func main() { sortSlice := quickSort([]int{1, 9, 10, 30, 2, 5, 45, 8, 63, 234, 12}) fmt.Println(sortSlice) } func quickSort(arr []int) []int { if len(arr) \u0026lt;= 2 { return arr } temp := arr[0] var low, high = make([]int, 0), make([]int, 0) for i := 1; i \u0026lt; len(arr); i++ { if arr[i] \u0026lt; temp { low = append(low, arr[i]) } else { high = append(high, arr[i]) } } lowSlice := quickSort(low) highSlice := quickSort(high) return append(append(lowSlice, temp), highSlice.","title":"算法系列 - 快速排序"},{"content":"1. 控制器类型 1.1 有状态服务 Statefulset  稳定持久化 稳定网络标志(地址) 有序部署 有序收缩(删除)  1.2 无状态服务 RC（ReplicationController） 副本数量与期望值之间的管理\nRS（ReplicaSet） 功能类似于RC，但是多了集合式的标签选择器\nDeployment 支持滚动更新以及回滚\nDaemonSet 单例模式\n确保Node上有且只运行一个同类型pod\nJob 负责批处理任务，即仅执行一次的任务，它可以保证批处理任务一个或者多个Pod成功结束\nCron Job 周期性执行任务\n2. 网络通讯方式 2.1 同 Pod 间不同容器间 IO\n2.2 不同 Pod 间的通讯 同物理机 Docker0 网桥实现报文转发\n不同物理机 flannel UDP 数据包二次封装\n","permalink":"https://nicko-ch.github.io/posts/kubernetes/20220323-kubernetes%E5%9F%BA%E7%A1%80/","summary":"1. 控制器类型 1.1 有状态服务 Statefulset  稳定持久化 稳定网络标志(地址) 有序部署 有序收缩(删除)  1.2 无状态服务 RC（ReplicationController） 副本数量与期望值之间的管理\nRS（ReplicaSet） 功能类似于RC，但是多了集合式的标签选择器\nDeployment 支持滚动更新以及回滚\nDaemonSet 单例模式\n确保Node上有且只运行一个同类型pod\nJob 负责批处理任务，即仅执行一次的任务，它可以保证批处理任务一个或者多个Pod成功结束\nCron Job 周期性执行任务\n2. 网络通讯方式 2.1 同 Pod 间不同容器间 IO\n2.2 不同 Pod 间的通讯 同物理机 Docker0 网桥实现报文转发\n不同物理机 flannel UDP 数据包二次封装","title":"Kubernetes基础"},{"content":"单元测试用例 文件命名规则 单元测试需要创建单独的测试文件，不能在原有文件中书写，名字规则为 xxx_test.go。这个规则很好理解。\n包命名规则 单元测试文件的包名为原文件的包名添加下划线接test，举例如下：\n// 原文件包名：  package xxx // 单元测试文件包名：  package xxx_test 方法命名规则 单元测试文件中的测试方法和原文件中的待测试的方法名相对应，以Test开头，举例如下：\n// 原文件方法： func Xxx(name string) error // 单元测试文件方法： func TestXxx() 方法参数 单元测试方法的参数必须是t *testing.T，举例如下：\nfunc TestZipFiles(t *testing.T) { ... 命令行执行 *go test **-v** cdfPrint_test.go **-run** TestPrintCDF // **-v** 指定文件 // **-run** 指定函数* ","permalink":"https://nicko-ch.github.io/posts/golang/20220321-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B/","summary":"单元测试用例 文件命名规则 单元测试需要创建单独的测试文件，不能在原有文件中书写，名字规则为 xxx_test.go。这个规则很好理解。\n包命名规则 单元测试文件的包名为原文件的包名添加下划线接test，举例如下：\n// 原文件包名：  package xxx // 单元测试文件包名：  package xxx_test 方法命名规则 单元测试文件中的测试方法和原文件中的待测试的方法名相对应，以Test开头，举例如下：\n// 原文件方法： func Xxx(name string) error // 单元测试文件方法： func TestXxx() 方法参数 单元测试方法的参数必须是t *testing.T，举例如下：\nfunc TestZipFiles(t *testing.T) { ... 命令行执行 *go test **-v** cdfPrint_test.go **-run** TestPrintCDF // **-v** 指定文件 // **-run** 指定函数* ","title":"Go高级编程 - 单元测试用例"},{"content":"Golang中Defer必掌握的7知识点 知识点1：defer的执行顺序 多个defer出现的时候，它是一个“栈”的关系，也就是先进后出。一个函数中，写在前面的defer会比写在后面的defer调用的晚。\npackage main import \u0026#34;fmt\u0026#34; func main() { defer func1() defer func2() defer func3() } func func1() { fmt.Println(\u0026#34;A\u0026#34;) } func func2() { fmt.Println(\u0026#34;B\u0026#34;) } func func3() { fmt.Println(\u0026#34;C\u0026#34;) } 输出结果：\nC B A 结论为：先压栈后出栈\n知识点2：defer与return谁先谁后 package main import \u0026#34;fmt\u0026#34; func deferFunc() int { fmt.Println(\u0026#34;defer func called\u0026#34;) return 0 } func returnFunc() int { fmt.Println(\u0026#34;return func called\u0026#34;) return 0 } func returnAndDefer() int { defer deferFunc() return returnFunc() } func main() { returnAndDefer() } 输出结果：\nreturn func called defer func called 结论为：return之后的语句先执行，defer后的语句后执行\n知识点3：函数返回值的初始化 如 ： func DeferFunc1(i int) (t int) {}\n其中返回值t int，这个t会在函数起始处被初始化为对应类型的零值并且作用域为整个函数。\npackage main import \u0026#34;fmt\u0026#34; func DeferFunc1(i int) (t int) { fmt.Println(\u0026#34;t = \u0026#34;, t) return 2 } func main() { DeferFunc11(10) } 输出结果：\nt = 0 结论为：只要声明函数的返回值变量名称，就会在函数初始化时候为之赋值为0，而且在函数体作用域可见。\n知识点4：有名函数返回值遇见defer情况 在没有defer的情况下，其实函数的返回就是与return一致的，但是有了defer就不一样了。\n我们通过知识点2得知，先return，再defer，所以在执行完return之后，还要再执行defer里的语句，依然可以修改本应该返回的结果。\npackage main import \u0026#34;fmt\u0026#34; func returnButDefer() (t int) { //t初始化0， 并且作用域为该函数全域  defer func() { t = t * 10 }() return 1 } func main() { fmt.Println(returnButDefer()) } 该returnButDefer()本应的返回值是1，但是在return之后，又被defer的匿名func函数执行，所以t=t*10被执行，最后returnButDefer()返回给上层main()的结果为10\n10 知识点5：defer遇见panic 我们知道，能够触发defer的是遇见return(或函数体到末尾)和遇见panic。\n根据知识点2，我们知道，defer遇见return情况如下：\n那么，遇到panic时，遍历本协程的defer链表，并执行defer。在执行defer过程中:遇到recover则停止panic，返回recover处继续往下执行。如果没有遇到recover，遍历完本协程的defer链表后，向stderr抛出panic信息。\nA. defer遇见panic，但是并不捕获异常的情况 package main import ( \u0026#34;fmt\u0026#34; ) func main() { defer_call() fmt.Println(\u0026#34;main 正常结束\u0026#34;) } func defer_call() { defer func() { fmt.Println(\u0026#34;defer: panic 之前1\u0026#34;) }() defer func() { fmt.Println(\u0026#34;defer: panic 之前2\u0026#34;) }() panic(\u0026#34;异常内容\u0026#34;) //触发defer出栈  defer func() { fmt.Println(\u0026#34;defer: panic 之后，永远执行不到\u0026#34;) }() } 结果\ndefer: panic 之前2 defer: panic 之前1 panic: 异常内容 //... 异常堆栈信息 B. defer遇见panic，并捕获异常 package main import ( \u0026#34;fmt\u0026#34; ) func main() { defer_call() fmt.Println(\u0026#34;main 正常结束\u0026#34;) } func defer_call() { defer func() { fmt.Println(\u0026#34;defer: panic 之前1, 捕获异常\u0026#34;) if err := recover(); err != nil { fmt.Println(err) } }() defer func() { fmt.Println(\u0026#34;defer: panic 之前2, 不捕获\u0026#34;) }() panic(\u0026#34;异常内容\u0026#34;) //触发defer出栈  defer func() { fmt.Println(\u0026#34;defer: panic 之后, 永远执行不到\u0026#34;) }() } 结果\ndefer: panic 之前2, 不捕获 defer: panic 之前1, 捕获异常 异常内容 main 正常结束 结论为：defer 最大的功能是 panic 后依然有效\n所以defer可以保证你的一些资源一定会被关闭，从而避免一些异常出现的问题。\n知识点6：defer中包含panic package main import ( \u0026#34;fmt\u0026#34; ) func main() { defer func() { if err := recover(); err != nil{ fmt.Println(err) }else { fmt.Println(\u0026#34;fatal\u0026#34;) } }() defer func() { panic(\u0026#34;defer panic\u0026#34;) }() panic(\u0026#34;panic\u0026#34;) } 结果\ndefer panic 结论为：panic仅有最后一个可以被revover捕获。\n触发panic(\u0026quot;panic\u0026quot;)后defer顺序出栈执行，第一个被执行的defer中 会有panic(\u0026quot;defer panic\u0026quot;)异常语句，这个异常将会覆盖掉main中的异常panic(\u0026quot;panic\u0026quot;)，最后这个异常被第二个执行的defer捕获到。\n知识点7：defer下的函数参数包含子函数 package main import \u0026#34;fmt\u0026#34; func function(index int, value int) int { fmt.Println(index) return index } func main() { defer function(1, function(3, 0)) defer function(2, function(4, 0)) } 这里，有4个函数，他们的index序号分别为1，2，3，4。\n那么这4个函数的先后执行顺序是什么呢？这里面有两个defer， 所以defer一共会压栈两次，先进栈1，后进栈2。 那么在压栈function1的时候，需要连同函数地址、函数形参一同进栈，那么为了得到function1的第二个参数的结果，所以就需要先执行function3将第二个参数算出，那么function3就被第一个执行。同理压栈function2，就需要执行function4算出function2第二个参数的值。然后函数结束，先出栈fuction2、再出栈function1.\n所以顺序如下：\n defer压栈function1，压栈函数地址、形参1、形参2(调用function3) \u0026ndash;\u0026gt; 打印3 defer压栈function2，压栈函数地址、形参1、形参2(调用function4) \u0026ndash;\u0026gt; 打印4 defer出栈function2, 调用function2 \u0026ndash;\u0026gt; 打印2 defer出栈function1, 调用function1\u0026ndash;\u0026gt; 打印1  3 4 2 1 结论为：defer中包含形参为子函数，会先解析子函数形参进行压栈\n练习：defer面试真题 package main import \u0026#34;fmt\u0026#34; func DeferFunc1(i int) (t int) { t = i defer func() { t += 3 }() return t } func DeferFunc2(i int) int { t := i defer func() { t += 3 }() return t } func DeferFunc3(i int) (t int) { defer func() { t += i }() return 2 } func DeferFunc4() (t int) { defer func(i int) { fmt.Println(i) fmt.Println(t) }(t) t = 1 return 2 } func main() { fmt.Println(DeferFunc1(1)) fmt.Println(DeferFunc2(1)) fmt.Println(DeferFunc3(1)) DeferFunc4() } DeferFunc1 func DeferFunc1(i int) (t int) { t = i defer func() { t += 3 }() return t }  将返回值t赋值为传入的i，此时t为1 执行return语句将t赋值给t（等于啥也没做） 执行defer方法，将t + 3 = 4 函数返回 4因为t的作用域为整个函数所以修改有效。  DeferFunc2 func DeferFunc2(i int) int { t := i defer func() { t += 3 }() return t }  创建变量t并赋值为1 执行return语句，注意这里是将t赋值给返回值，此时返回值为1（这个返回值并不是t） 执行defer方法，将t + 3 = 4 函数返回返回值1  也可以按照如下代码理解\nfunc DeferFunc2(i int) (result int) { t := i defer func() { t += 3 }() return t } 上面的代码return的时候相当于将t赋值给了result，当defer修改了t的值之后，对result是不会造成影响的。\nDeferFunc3 func DeferFunc3(i int) (t int) { defer func() { t += i }() return 2 }  首先执行return将返回值t赋值为2 执行defer方法将t + 1 最后返回 3  DeferFunc4 func DeferFunc4() (t int) { defer func(i int) { fmt.Println(i) fmt.Println(t) }(t) t = 1 return 2 }  初始化返回值t为零值 0 首先执行defer的第一步，赋值defer中的func入参t为0 执行defer的第二步，将defer压栈 将t赋值为1 执行return语句，将返回值t赋值为2 执行defer的第三步，出栈并执行因为在入栈时defer执行的func的入参已经赋值了，此时它作为的是一个形式参数，所以打印为0；相对应的因为最后已经将t的值修改为2，所以再打印一个2  结果 4 1 3 0 2 Refference  https://www.yuque.com/aceld/golang/qnubsg#4311f2c0\n ","permalink":"https://nicko-ch.github.io/posts/golang/20220108-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-golang%E4%B8%ADdefer%E5%BF%85%E6%8E%8C%E6%8F%A1%E7%9A%847%E7%9F%A5%E8%AF%86%E7%82%B9/","summary":"Golang中Defer必掌握的7知识点 知识点1：defer的执行顺序 多个defer出现的时候，它是一个“栈”的关系，也就是先进后出。一个函数中，写在前面的defer会比写在后面的defer调用的晚。\npackage main import \u0026#34;fmt\u0026#34; func main() { defer func1() defer func2() defer func3() } func func1() { fmt.Println(\u0026#34;A\u0026#34;) } func func2() { fmt.Println(\u0026#34;B\u0026#34;) } func func3() { fmt.Println(\u0026#34;C\u0026#34;) } 输出结果：\nC B A 结论为：先压栈后出栈\n知识点2：defer与return谁先谁后 package main import \u0026#34;fmt\u0026#34; func deferFunc() int { fmt.Println(\u0026#34;defer func called\u0026#34;) return 0 } func returnFunc() int { fmt.Println(\u0026#34;return func called\u0026#34;) return 0 } func returnAndDefer() int { defer deferFunc() return returnFunc() } func main() { returnAndDefer() } 输出结果：","title":"Go高级编程 - Golang中Defer必掌握的7知识点"},{"content":"Golang逃逸分析 1、 原理 go语言编译器会自动决定把一个变量放在栈还是放在堆，编译器会做**逃逸分析(escape analysis)**，**当发现变量的作用域没有跑出函数范围，就可以在栈上，反之则必须分配在堆。**\n2、如何分析 2.1、案例 package main func foo(arg_val int) (*int) { var foo_val1 int = 11; var foo_val2 int = 12; var foo_val3 int = 13; var foo_val4 int = 14; var foo_val5 int = 15; //此处循环是防止go编译器将foo优化成inline(内联函数)  //如果是内联函数，main调用foo将是原地展开，所以foo_val1-5相当于main作用域的变量  //即使foo_val3发生逃逸，地址与其他也是连续的  for i := 0; i \u0026lt; 5; i++ { println(\u0026amp;arg_val, \u0026amp;foo_val1, \u0026amp;foo_val2, \u0026amp;foo_val3, \u0026amp;foo_val4, \u0026amp;foo_val5) } //返回foo_val3给main函数  return \u0026amp;foo_val3; } func main() { main_val := foo(666) println(*main_val, main_val) } 运行结果\n$ go run pro_2.go 0xc000030758 0xc000030738 0xc000030730 0xc000082000 0xc000030728 0xc000030720 0xc000030758 0xc000030738 0xc000030730 0xc000082000 0xc000030728 0xc000030720 0xc000030758 0xc000030738 0xc000030730 0xc000082000 0xc000030728 0xc000030720 0xc000030758 0xc000030738 0xc000030730 0xc000082000 0xc000030728 0xc000030720 0xc000030758 0xc000030738 0xc000030730 0xc000082000 0xc000030728 0xc000030720 13 0xc000082000 结论：\n可以看出fool_val3是返回main的局部变量，明显与fool_val1-4不是连续的地址\n2.2、go tool compile -m分析 我们用go tool compile -m测试一下\n$ go tool compile -m pro_2.go pro_2.go:24:6: can inline main pro_2.go:7:9: moved to heap: foo_val3 果然,在编译的时候, foo_val3具有被编译器判定为逃逸变量, 将foo_val3放在堆中开辟.\n我们在用汇编证实一下:\n$ go tool compile -S pro_2.go \u0026gt; pro_2.S 打开pro_2.S文件, 搜索runtime.newobject关键字\n... 16 0x0021 00033 (pro_2.go:5) PCDATA $0, $0 17 0x0021 00033 (pro_2.go:5) PCDATA $1, $0 18 0x0021 00033 (pro_2.go:5) MOVQ $11, \u0026#34;\u0026#34;.foo_val1+48(SP) 19 0x002a 00042 (pro_2.go:6) MOVQ $12, \u0026#34;\u0026#34;.foo_val2+40(SP) 20 0x0033 00051 (pro_2.go:7) PCDATA $0, $1 21 0x0033 00051 (pro_2.go:7) LEAQ type.int(SB), AX 22 0x003a 00058 (pro_2.go:7) PCDATA $0, $0 23 0x003a 00058 (pro_2.go:7) MOVQ AX, (SP) 24 0x003e 00062 (pro_2.go:7) CALL runtime.newobject(SB) //foo_val3是被new出来的 25 0x0043 00067 (pro_2.go:7) PCDATA $0, $1 26 0x0043 00067 (pro_2.go:7) MOVQ 8(SP), AX 27 0x0048 00072 (pro_2.go:7) PCDATA $1, $1 28 0x0048 00072 (pro_2.go:7) MOVQ AX, \u0026#34;\u0026#34;.\u0026amp;foo_val3+56(SP) 29 0x004d 00077 (pro_2.go:7) MOVQ $13, (AX) 30 0x0054 00084 (pro_2.go:8) MOVQ $14, \u0026#34;\u0026#34;.foo_val4+32(SP) 31 0x005d 00093 (pro_2.go:9) MOVQ $15, \u0026#34;\u0026#34;.foo_val5+24(SP) 32 0x0066 00102 (pro_2.go:9) XORL CX, CX 33 0x0068 00104 (pro_2.go:15) JMP 252 ... 看出来, foo_val3是被runtime.newobject()在堆空间开辟的, 而不是像其他几个是基于地址偏移的开辟的栈空间.\n3、逃逸范例 3.1、 逃逸规则 **一般给引用类型进行赋值，则可能出现逃逸。**原理解析为当用户引用一个引用类型的对象是，已经是通过指针间接访问，如果再访问引用类型的对象的成员，则会出现二次间接引用，这就极大可能出现逃逸现象。\nGo语言中的引用类型有\n func（函数类型） interface（接口类型） slice（切片类型） map（字典类型） channel（管道类型） *（指针类型）等。  3.2、逃逸案例 案例一、 []interface{}数据类型，通过[]赋值必定会出现逃逸。\npackage main func main() { data := []interface{}{100, 200} data[0] = 100 } 我们通过编译看看逃逸结果\naceld:test ldb$ go tool compile -m 1.go 1.go:3:6: can inline main 1.go:4:23: []interface {}{...} does not escape 1.go:4:24: 100 does not escape 1.go:4:29: 200 does not escape 1.go:6:10: 100 escapes to heap 我们能看到，data[0] = 100 发生了逃逸现象。\n案例二、 map[string]interface{}类型尝试通过赋值，必定会出现逃逸。\npackage main func main() { data := make(map[string]interface{}) data[\u0026#34;key\u0026#34;] = 200 } 我们通过编译看看逃逸结果\naceld:test ldb$ go tool compile -m 2.go 2.go:3:6: can inline main 2.go:4:14: make(map[string]interface {}) does not escape 2.go:6:14: 200 escapes to heap 我们能看到，data[\u0026quot;key\u0026quot;] = 200 发生了逃逸。\n案例三、 map[interface{}]interface{}类型尝试通过赋值，会导致key和value的赋值，出现逃逸。\npackage main func main() { data := make(map[interface{}]interface{}) data[100] = 200 } 我们通过编译看看逃逸结果\naceld:test ldb$ go tool compile -m 3.go 3.go:3:6: can inline main 3.go:4:14: make(map[interface {}]interface {}) does not escape 3.go:6:6: 100 escapes to heap 3.go:6:12: 200 escapes to heap 我们能看到，data[100] = 200 中，100和200均发生了逃逸。\n案例四、 map[string][]string数据类型，赋值会发生[]string发生逃逸。\npackage main func main() { data := make(map[string][]string) data[\u0026#34;key\u0026#34;] = []string{\u0026#34;value\u0026#34;} } 我们通过编译看看逃逸结果\naceld:test ldb$ go tool compile -m 4.go 4.go:3:6: can inline main 4.go:4:14: make(map[string][]string) does not escape 4.go:6:24: []string{...} escapes to heap 我们能看到，[]string{...}切片发生了逃逸。\n案例五、 []*int数据类型，赋值的右值会发生逃逸现象。\npackage main func main() { a := 10 data := []*int{nil} data[0] = \u0026amp;a } 我们通过编译看看逃逸结果\naceld:test ldb$ go tool compile -m 5.go 5.go:3:6: can inline main 5.go:4:2: moved to heap: a 5.go:6:16: []*int{...} does not escape 其中 moved to heap: a，最终将变量a 移动到了堆上。\n案例六、 func(*int)函数类型，进行函数赋值，会使传递的形参出现逃逸现象。\npackage main import \u0026#34;fmt\u0026#34; func foo(a *int) { return } func main() { data := 10 f := foo f(\u0026amp;data) fmt.Println(data) } 我们通过编译看看逃逸结果\naceld:test ldb$ go tool compile -m 6.go 6.go:5:6: can inline foo 6.go:12:3: inlining call to foo 6.go:14:13: inlining call to fmt.Println 6.go:5:10: a does not escape 6.go:14:13: data escapes to heap 6.go:14:13: []interface {}{...} does not escape :1: .this does not escape 我们会看到data已经被逃逸到堆上。\n案例七、 func([]string): 函数类型，进行[]string{\u0026quot;value\u0026quot;}赋值，会使传递的参数出现逃逸现象。\npackage main import \u0026#34;fmt\u0026#34; func foo(a []string) { return } func main() { s := []string{\u0026#34;aceld\u0026#34;} foo(s) fmt.Println(s) } 我们通过编译看看逃逸结果\naceld:test ldb$ go tool compile -m 7.go 7.go:5:6: can inline foo 7.go:11:5: inlining call to foo 7.go:13:13: inlining call to fmt.Println 7.go:5:10: a does not escape 7.go:10:15: []string{...} escapes to heap 7.go:13:13: s escapes to heap 7.go:13:13: []interface {}{...} does not escape :1: .this does not escape 我们看到 s escapes to heap，s被逃逸到堆上。\n案例八、 chan []string数据类型，想当前channel中传输[]string{\u0026quot;value\u0026quot;}会发生逃逸现象。\npackage main func main() { ch := make(chan []string) s := []string{\u0026#34;aceld\u0026#34;} go func() { ch \u0026lt;- s }() } 我们通过编译看看逃逸结果\naceld:test ldb$ go tool compile -m 8.go 8.go:8:5: can inline main.func1 8.go:6:15: []string{...} escapes to heap 8.go:8:5: func literal escapes to heap 我们看到[]string{...} escapes to heap, s被逃逸到堆上。\n","permalink":"https://nicko-ch.github.io/posts/golang/20220106-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-golang%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/","summary":"Golang逃逸分析 1、 原理 go语言编译器会自动决定把一个变量放在栈还是放在堆，编译器会做**逃逸分析(escape analysis)**，**当发现变量的作用域没有跑出函数范围，就可以在栈上，反之则必须分配在堆。**\n2、如何分析 2.1、案例 package main func foo(arg_val int) (*int) { var foo_val1 int = 11; var foo_val2 int = 12; var foo_val3 int = 13; var foo_val4 int = 14; var foo_val5 int = 15; //此处循环是防止go编译器将foo优化成inline(内联函数)  //如果是内联函数，main调用foo将是原地展开，所以foo_val1-5相当于main作用域的变量  //即使foo_val3发生逃逸，地址与其他也是连续的  for i := 0; i \u0026lt; 5; i++ { println(\u0026amp;arg_val, \u0026amp;foo_val1, \u0026amp;foo_val2, \u0026amp;foo_val3, \u0026amp;foo_val4, \u0026amp;foo_val5) } //返回foo_val3给main函数  return \u0026amp;foo_val3; } func main() { main_val := foo(666) println(*main_val, main_val) } 运行结果","title":"Go高级编程 - Golang逃逸分析"},{"content":"性能监测与优化实践方法 场景1：如何分析程序的运行时间与CPU利用率情况？ （1）shell内置time指令 $ time go run test2.go \u0026amp;{{0 0} 张三 0} real\t0m0.843s user\t0m0.216s sys\t0m0.389s  real ：从程序开始到结束，实际使用时间； user ：程序在用户态使用时间； sys ：程序在内核态使用时间。  一般情况下 real \u0026gt;= user + sys，因为系统还有其它进程(切换其他进程中间对于本进程会有空白期)。\n（2）/user/bin/time 指令 使用时需要输入决定路径，带上参数-v\n$ /usr/bin/time -v go run test2.go Command being timed: \u0026#34;go run test2.go\u0026#34; User time (seconds): 0.12 System time (seconds): 0.06 Percent of CPU this job got: 115% Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.16 Average shared text size (kbytes): 0 Average unshared data size (kbytes): 0 Average stack size (kbytes): 0 Average total size (kbytes): 0 Maximum resident set size (kbytes): 41172 Average resident set size (kbytes): 0 Major (requiring I/O) page faults: 1 Minor (reclaiming a frame) page faults: 15880 Voluntary context switches: 897 Involuntary context switches: 183 Swaps: 0 File system inputs: 256 File system outputs: 2664 Socket messages sent: 0 Socket messages received: 0 Signals delivered: 0 Page size (bytes): 4096 Exit status: 0  CPU占用率； 内存使用情况； Page Fault 情况； 进程切换情况； 文件系统IO； Socket 使用情况； ……  场景2：如何分析golang程序的内存使用情况？ （1）内存占用情况查看 场景例子代码demo\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;time\u0026#34; ) func test() { //slice 会动态扩容，用slice来做堆内存申请  container := make([]int, 8) log.Println(\u0026#34; ===\u0026gt; loop begin.\u0026#34;) for i := 0; i \u0026lt; 32*1000*1000; i++ { container = append(container, i) } log.Println(\u0026#34; ===\u0026gt; loop end.\u0026#34;) } func main() { log.Println(\u0026#34;Start.\u0026#34;) test() log.Println(\u0026#34;force gc.\u0026#34;) runtime.GC() //强制调用gc回收  log.Println(\u0026#34;Done.\u0026#34;) time.Sleep(3600 * time.Second) //睡眠，保持程序不退出 } 编译\n$go build -o snippet_mem \u0026amp;\u0026amp; ./snippet_mem 然后在./snippet_mem进程没有执行完，我们再开一个窗口，通过top命令查看进程的内存占用情况\n$top -p $(pidof snippet_mem) 结果如下：\n我们看出来，没有退出的snippet_mem进程有约830m的内存被占用。\n直观上来说，这个程序在test()函数执行完后，切片contaner的内存应该被释放，不应该占用830M那么大。\n下面让我们使用GODEBUG来分析程序的内存使用情况。\n（2）GODEBUG与gctrace 用法 执行snippet_mem程序之前添加环境变量GODEBUG='gctrace=1'来跟踪打印垃圾回收器信息\n$ GODEBUG=\u0026#39;gctrace=1\u0026#39; ./snippet_mem 设置gctrace=1会使得垃圾回收器在每次回收时汇总所回收内存的大小以及耗时，并将这些内容汇总成单行内容打印到标准错误输出中。\n格式 gc # @#s #%: #+#+# ms clock, #+#/#/#+# ms cpu, #-\u0026gt;#-\u0026gt;# MB, # MB goal, # P 含义\ngc # GC次数的编号，每次GC时递增 @#s 距离程序开始执行时的时间 #% GC占用的执行时间百分比 #+...+# GC使用的时间 #-\u0026gt;#-\u0026gt;# MB GC开始，结束，以及当前活跃堆内存的大小，单位M # MB goal 全局堆内存大小 # P 使用processor的数量 如果每条信息最后，以(forced)结尾，那么该信息是由runtime.GC()调用触发\n我们来选择其中一行来解释一下：\ngc 17 @0.149s 1%: 0.004+36+0.003 ms clock, 0.009+0/0.051/36+0.006 ms cpu, 181*-*\u0026gt;181-\u0026gt;101 MB, 182 MB goal, 2 P 该条信息含义如下：\n gc 17: Gc 调试编号为17 @0.149s:此时程序已经执行了0.149s 1%: 0.149s中其中gc模块占用了1%的时间 0.004+36+0.003 ms clock: 垃圾回收的时间，分别为STW（stop-the-world）清扫的时间+并发标记和扫描的时间+STW标记的时间 0.009+0/0.051/36+0.006 ms cpu: 垃圾回收占用cpu时间 181-\u0026gt;181-\u0026gt;101 MB： GC开始前堆内存181M， GC结束后堆内存181M，当前活跃的堆内存101M 182 MB goal: 全局堆内存大小 2 P: 本次GC使用了2个P(调度器中的Processer)  结合例子分析：\n执行GODEBUG调试\n$ GODEBUG=\u0026#39;gctrace=1\u0026#39; ./snippet_mem 输出\n2020/03/02 11:22:37 Start. 2020/03/02 11:22:37 ===\u0026gt; loop begin. gc 1 @0.002s 5%: 0.14+0.45+0.002 ms clock, 0.29+0/0.042/0.33+0.005 ms cpu, 4-\u0026gt;4-\u0026gt;0 MB, 5 MB goal, 2 P gc 2 @0.003s 4%: 0.13+3.7+0.019 ms clock, 0.27+0/0.037/2.8+0.038 ms cpu, 4-\u0026gt;4-\u0026gt;2 MB, 5 MB goal, 2 P gc 3 @0.008s 3%: 0.002+1.1+0.001 ms clock, 0.005+0/0.083/1.0+0.003 ms cpu, 6-\u0026gt;6-\u0026gt;2 MB, 7 MB goal, 2 P gc 4 @0.010s 3%: 0.003+0.99+0.002 ms clock, 0.006+0/0.041/0.82+0.004 ms cpu, 5-\u0026gt;5-\u0026gt;2 MB, 6 MB goal, 2 P gc 5 @0.011s 4%: 0.079+0.80+0.003 ms clock, 0.15+0/0.046/0.51+0.006 ms cpu, 6-\u0026gt;6-\u0026gt;3 MB, 7 MB goal, 2 P gc 6 @0.013s 4%: 0.15+3.7+0.002 ms clock, 0.31+0/0.061/3.3+0.005 ms cpu, 8-\u0026gt;8-\u0026gt;8 MB, 9 MB goal, 2 P gc 7 @0.019s 3%: 0.004+2.5+0.005 ms clock, 0.008+0/0.051/2.1+0.010 ms cpu, 20-\u0026gt;20-\u0026gt;6 MB, 21 MB goal, 2 P gc 8 @0.023s 5%: 0.014+3.7+0.002 ms clock, 0.029+0.040/1.2/0+0.005 ms cpu, 15-\u0026gt;15-\u0026gt;8 MB, 16 MB goal, 2 P gc 9 @0.031s 4%: 0.003+1.6+0.001 ms clock, 0.007+0.094/0/0+0.003 ms cpu, 19-\u0026gt;19-\u0026gt;10 MB, 20 MB goal, 2 P gc 10 @0.034s 3%: 0.006+5.2+0.004 ms clock, 0.013+0/0.045/5.0+0.008 ms cpu, 24-\u0026gt;24-\u0026gt;13 MB, 25 MB goal, 2 P gc 11 @0.040s 3%: 0.12+2.6+0.002 ms clock, 0.24+0/0.043/2.5+0.004 ms cpu, 30-\u0026gt;30-\u0026gt;16 MB, 31 MB goal, 2 P gc 12 @0.043s 3%: 0.11+4.4+0.002 ms clock, 0.23+0/0.044/4.1+0.005 ms cpu, 38-\u0026gt;38-\u0026gt;21 MB, 39 MB goal, 2 P gc 13 @0.049s 3%: 0.008+10+0.040 ms clock, 0.017+0/0.045/10+0.080 ms cpu, 47-\u0026gt;47-\u0026gt;47 MB, 48 MB goal, 2 P gc 14 @0.070s 2%: 0.004+12+0.002 ms clock, 0.008+0/0.062/12+0.005 ms cpu, 122-\u0026gt;122-\u0026gt;41 MB, 123 MB goal, 2 P gc 15 @0.084s 2%: 0.11+11+0.038 ms clock, 0.22+0/0.064/3.9+0.076 ms cpu, 93-\u0026gt;93-\u0026gt;93 MB, 94 MB goal, 2 P gc 16 @0.122s 1%: 0.005+25+0.010 ms clock, 0.011+0/0.12/24+0.021 ms cpu, 238-\u0026gt;238-\u0026gt;80 MB, 239 MB goal, 2 P gc 17 @0.149s 1%: 0.004+36+0.003 ms clock, 0.009+0/0.051/36+0.006 ms cpu, 181-\u0026gt;181-\u0026gt;101 MB, 182 MB goal, 2 P gc 18 @0.187s 1%: 0.12+19+0.004 ms clock, 0.25+0/0.049/19+0.008 ms cpu, 227-\u0026gt;227-\u0026gt;126 MB, 228 MB goal, 2 P gc 19 @0.207s 1%: 0.096+27+0.004 ms clock, 0.19+0/0.077/0.73+0.009 ms cpu, 284-\u0026gt;284-\u0026gt;284 MB, 285 MB goal, 2 P gc 20 @0.287s 0%: 0.005+944+0.040 ms clock, 0.011+0/0.048/1.3+0.081 ms cpu, 728-\u0026gt;728-\u0026gt;444 MB, 729 MB goal, 2 P 2020/03/02 11:22:38 ===\u0026gt; loop end. 2020/03/02 11:22:38 force gc. gc 21 @1.236s 0%: 0.004+0.099+0.001 ms clock, 0.008+0/0.018/0.071+0.003 ms cpu, 444-\u0026gt;444-\u0026gt;0 MB, 888 MB goal, 2 P (forced) 2020/03/02 11:22:38 Done. GC forced gc 22 @122.455s 0%: 0.010+0.15+0.003 ms clock, 0.021+0/0.025/0.093+0.007 ms cpu, 0-\u0026gt;0-\u0026gt;0 MB, 4 MB goal, 2 P GC forced gc 23 @242.543s 0%: 0.007+0.075+0.002 ms clock, 0.014+0/0.022/0.085+0.004 ms cpu, 0-\u0026gt;0-\u0026gt;0 MB, 4 MB goal, 2 P GC forced gc 24 @362.545s 0%: 0.018+0.19+0.006 ms clock, 0.037+0/0.055/0.15+0.013 ms cpu, 0-\u0026gt;0-\u0026gt;0 MB, 4 MB goal, 2 P GC forced gc 25 @482.548s 0%: 0.012+0.25+0.005 ms clock, 0.025+0/0.025/0.11+0.010 ms cpu, 0-\u0026gt;0-\u0026gt;0 MB, 4 MB goal, 2 P GC forced gc 26 @602.551s 0%: 0.009+0.10+0.003 ms clock, 0.018+0/0.021/0.075+0.006 ms cpu, 0-\u0026gt;0-\u0026gt;0 MB, 4 MB goal, 2 P GC forced gc 27 @722.554s 0%: 0.012+0.30+0.005 ms clock, 0.025+0/0.15/0.22+0.011 ms cpu, 0-\u0026gt;0-\u0026gt;0 MB, 4 MB goal, 2 P GC forced gc 28 @842.556s 0%: 0.027+0.18+0.003 ms clock, 0.054+0/0.11/0.14+0.006 ms cpu, 0-\u0026gt;0-\u0026gt;0 MB, 4 MB goal, 2 P ... 分析\n先看在test()函数执行完后立即打印的gc 21那行的信息。444-\u0026gt;444-\u0026gt;0 MB, 888 MB goal表示垃圾回收器已经把444M的内存标记为非活跃的内存。\n再看下一个记录gc 22。0-\u0026gt;0-\u0026gt;0 MB, 4 MB goal表示垃圾回收器中的全局堆内存大小由888M下降为4M。\n结论\n1、在test()函数执行完后，demo程序中的切片容器所申请的堆空间都被垃圾回收器回收了。\n2、如果此时在top指令查询内存的时候，如果依然是800+MB，说明垃圾回收器回收了应用层的内存后，（可能）并不会立即将内存归还给系统。\n（3）runtime.ReadMemStats 稍微修改一下demo，加入readMemStats()函数\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;time\u0026#34; ) func readMemStats() { var ms runtime.MemStats runtime.ReadMemStats(\u0026amp;ms) log.Printf(\u0026#34; ===\u0026gt; Alloc:%d(bytes) HeapIdle:%d(bytes) HeapReleased:%d(bytes)\u0026#34;, ms.Alloc, ms.HeapIdle, ms.HeapReleased) } func test() { //slice 会动态扩容，用slice来做堆内存申请  container := make([]int, 8) log.Println(\u0026#34; ===\u0026gt; loop begin.\u0026#34;) for i := 0; i \u0026lt; 32*1000*1000; i++ { container = append(container, i) if ( i == 16*1000*1000) { readMemStats() } } log.Println(\u0026#34; ===\u0026gt; loop end.\u0026#34;) } func main() { log.Println(\u0026#34; ===\u0026gt; [Start].\u0026#34;) readMemStats() test() readMemStats() log.Println(\u0026#34; ===\u0026gt; [force gc].\u0026#34;) runtime.GC() //强制调用gc回收  log.Println(\u0026#34; ===\u0026gt; [Done].\u0026#34;) readMemStats() go func() { for { readMemStats() time.Sleep(10 * time.Second) } }() time.Sleep(3600 * time.Second) //睡眠，保持程序不退出 } 这里我们， 封装了一个函数readMemStats()，这里面主要是调用runtime中的ReadMemStats()方法获得内存信息，然后通过log打印出来。\n$ go run demo2.go 2020/03/02 18:21:17 ===\u0026gt; [Start]. 2020/03/02 18:21:17 ===\u0026gt; Alloc:71280(bytes) HeapIdle:66633728(bytes) HeapReleased:66600960(bytes) 2020/03/02 18:21:17 ===\u0026gt; loop begin. 2020/03/02 18:21:18 ===\u0026gt; Alloc:132535744(bytes) HeapIdle:336756736(bytes) HeapReleased:155721728(bytes) 2020/03/02 18:21:38 ===\u0026gt; loop end. 2020/03/02 18:21:38 ===\u0026gt; Alloc:598300600(bytes) HeapIdle:609181696(bytes) HeapReleased:434323456(bytes) 2020/03/02 18:21:38 ===\u0026gt; [force gc]. 2020/03/02 18:21:38 ===\u0026gt; [Done]. 2020/03/02 18:21:38 ===\u0026gt; Alloc:55840(bytes) HeapIdle:1207427072(bytes) HeapReleased:434266112(bytes) 2020/03/02 18:21:38 ===\u0026gt; Alloc:56656(bytes) HeapIdle:1207394304(bytes) HeapReleased:434266112(bytes) 2020/03/02 18:21:48 ===\u0026gt; Alloc:56912(bytes) HeapIdle:1207394304(bytes) HeapReleased:1206493184(bytes) 2020/03/02 18:21:58 ===\u0026gt; Alloc:57488(bytes) HeapIdle:1207394304(bytes) HeapReleased:1206493184(bytes) 2020/03/02 18:22:08 ===\u0026gt; Alloc:57616(bytes) HeapIdle:1207394304(bytes) HeapReleased:1206493184(bytes) c2020/03/02 18:22:18 ===\u0026gt; Alloc:57744(bytes) HeapIdle:1207394304(bytes) HeapReleased:1206493184(by 可以看到，打印[Done].之后那条trace信息，Alloc已经下降，即内存已被垃圾回收器回收。在2020/03/02 18:21:38和2020/03/02 18:21:48的两条trace信息中，HeapReleased开始上升，即垃圾回收器把内存归还给系统。\n另外，MemStats还可以获取其它哪些信息以及字段的含义可以参见官方文档：\n http://golang.org/pkg/runtime/#MemStats\n （4）pprof工具 因为pprof工具支持网页查看，故再次修改demo代码\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;time\u0026#34; \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; ) func readMemStats() { var ms runtime.MemStats runtime.ReadMemStats(\u0026amp;ms) log.Printf(\u0026#34; ===\u0026gt; Alloc:%d(bytes) HeapIdle:%d(bytes) HeapReleased:%d(bytes)\u0026#34;, ms.Alloc, ms.HeapIdle, ms.HeapReleased) } func test() { //slice 会动态扩容，用slice来做堆内存申请  container := make([]int, 8) log.Println(\u0026#34; ===\u0026gt; loop begin.\u0026#34;) for i := 0; i \u0026lt; 32*1000*1000; i++ { container = append(container, i) if ( i == 16*1000*1000) { readMemStats() } } log.Println(\u0026#34; ===\u0026gt; loop end.\u0026#34;) } func main() { //启动pprof  go func() { log.Println(http.ListenAndServe(\u0026#34;0.0.0.0:10000\u0026#34;, nil)) }() log.Println(\u0026#34; ===\u0026gt; [Start].\u0026#34;) readMemStats() test() readMemStats() log.Println(\u0026#34; ===\u0026gt; [force gc].\u0026#34;) runtime.GC() //强制调用gc回收  log.Println(\u0026#34; ===\u0026gt; [Done].\u0026#34;) readMemStats() go func() { for { readMemStats() time.Sleep(10 * time.Second) } }() time.Sleep(3600 * time.Second) //睡眠，保持程序不退出 } 我们正常运行程序，然后同时打开浏览器，\n输入地址：http://127.0.0.1:10000/debug/pprof/heap?debug=1\n浏览器的内容其中有一部分如下，记录了目前的内存情况\n# ... # runtime.MemStats # Alloc = 228248 # TotalAlloc = 1293696976 # Sys = 834967896 # Lookups = 0 # Mallocs = 2018 # Frees = 671 # HeapAlloc = 228248 # HeapSys = 804913152 # HeapIdle = 804102144 # HeapInuse = 811008 # HeapReleased = 108552192 # HeapObjects = 1347 # Stack = 360448 / 360448 # MSpan = 28288 / 32768 # MCache = 3472 / 16384 # BuckHashSys = 1449617 # GCSys = 27418976 # OtherSys = 776551 # NextGC = 4194304 # LastGC = 1583203571137891390 # ... 场景3：如何分析Golang程序的CPU性能情况？ （1）性能分析注意事项  性能分析必须在一个可重复的、稳定的环境中来进行。 机器必须闲置 不要在共享硬件上进行性能分析; 不要在性能分析期间，在同一个机器上去浏览网页 注意省电模式和过热保护，如果突然进入这些模式，会导致分析数据严重不准确 不要使用虚拟机、共享的云主机，太多干扰因素，分析数据会很不一致； 不要在 macOS 10.11 及以前的版本运行性能分析，有 bug，之后的版本修复了。  （2）CPU性能分析 demo代码\npackage main import ( \u0026#34;bytes\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; ) func test() { log.Println(\u0026#34; ===\u0026gt; loop begin.\u0026#34;) for i := 0; i \u0026lt; 1000; i++ { log.Println(genSomeBytes()) } log.Println(\u0026#34; ===\u0026gt; loop end.\u0026#34;) } //生成一个随机字符串 func genSomeBytes() *bytes.Buffer { var buff bytes.Buffer for i := 1; i \u0026lt; 20000; i++ { buff.Write([]byte{\u0026#39;0\u0026#39; + byte(rand.Intn(10))}) } return \u0026amp;buff } func main() { go func() { for { test() time.Sleep(time.Second * 1) } }() //启动pprof  http.ListenAndServe(\u0026#34;0.0.0.0:10000\u0026#34;, nil) } A） Web界面查看 浏览器访问http://127.0.0.1:10000/debug/pprof/\nB）使用pprof工具查看 go tool pprof [binary] [profile]  binary: 必须指向生成这个性能分析数据的那个二进制可执行文件； profile: 必须是该二进制可执行文件所生成的性能分析数据文件。  binary 和 profile 必须严格匹配。\n$ go tool pprof ./demo4 profile File: demo4 Type: cpu Time: Mar 3, 2020 at 11:18pm (CST) Duration: 30.13s, Total samples = 6.27s (20.81%) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) help可以查看一些指令,我么可以通过top来查看cpu的性能情况.\n(pprof) top Showing nodes accounting for 5090ms, 81.18% of 6270ms total Dropped 80 nodes (cum \u0026lt;= 31.35ms) Showing top 10 nodes out of 60 flat flat% sum% cum cum% 1060ms 16.91% 16.91% 2170ms 34.61% math/rand.(*lockedSource).Int63 850ms 13.56% 30.46% 850ms 13.56% sync.(*Mutex).Unlock (inline) 710ms 11.32% 41.79% 2950ms 47.05% math/rand.(*Rand).Int31n 570ms 9.09% 50.88% 990ms 15.79% bytes.(*Buffer).Write 530ms 8.45% 59.33% 540ms 8.61% syscall.Syscall 370ms 5.90% 65.23% 370ms 5.90% runtime.procyield 270ms 4.31% 69.54% 4490ms 71.61% main.genSomeBytes 250ms 3.99% 73.52% 3200ms 51.04% math/rand.(*Rand).Intn 250ms 3.99% 77.51% 250ms 3.99% runtime.memmove 230ms 3.67% 81.18% 690ms 11.00% runtime.suspendG (pprof) 这里面有几列数据,需要说明一下.\n flat：当前函数占用CPU的耗时 flat%：:当前函数占用CPU的耗时百分比 sum%：函数占用CPU的耗时累计百分比 cum：当前函数加上调用当前函数的函数占用CPU的总耗时 cum%：当前函数加上调用当前函数的函数占用CPU的总耗时百分比 最后一列：函数名称  结论：通过结果我们可以看出, 该程序的大部分cpu性能消耗在 main.getSoneBytes()方法中,其中math/rand取随机数消耗比较大.\nC）可视化查看 还是基于go tool pprof获得profile文件\n$ go tool pprof ./demo4 profileFile: demo4 Type: cpu Time: Mar 3, 2020 at 11:18pm (CST) Duration: 30.13s, Total samples = 6.27s (20.81%) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) web 这里如果报找不到graphviz工具,需要安装一下\nUbuntu安装\n$sudo apt-get install graphviz Mac安装\nbrew install graphviz windows安装\n下载https://graphviz.gitlab.io/_pages/Download/Download_windows.html\n将graphviz安装目录下的bin文件夹添加到Path环境变量中。 在终端输入dot -version查看是否安装成功。\n","permalink":"https://nicko-ch.github.io/posts/golang/20220101-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-%E6%80%A7%E8%83%BD%E7%9B%91%E6%B5%8B%E4%B8%8E%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5%E6%96%B9%E6%B3%95/","summary":"性能监测与优化实践方法 场景1：如何分析程序的运行时间与CPU利用率情况？ （1）shell内置time指令 $ time go run test2.go \u0026amp;{{0 0} 张三 0} real\t0m0.843s user\t0m0.216s sys\t0m0.389s  real ：从程序开始到结束，实际使用时间； user ：程序在用户态使用时间； sys ：程序在内核态使用时间。  一般情况下 real \u0026gt;= user + sys，因为系统还有其它进程(切换其他进程中间对于本进程会有空白期)。\n（2）/user/bin/time 指令 使用时需要输入决定路径，带上参数-v\n$ /usr/bin/time -v go run test2.go Command being timed: \u0026#34;go run test2.go\u0026#34; User time (seconds): 0.12 System time (seconds): 0.06 Percent of CPU this job got: 115% Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.16 Average shared text size (kbytes): 0 Average unshared data size (kbytes): 0 Average stack size (kbytes): 0 Average total size (kbytes): 0 Maximum resident set size (kbytes): 41172 Average resident set size (kbytes): 0 Major (requiring I/O) page faults: 1 Minor (reclaiming a frame) page faults: 15880 Voluntary context switches: 897 Involuntary context switches: 183 Swaps: 0 File system inputs: 256 File system outputs: 2664 Socket messages sent: 0 Socket messages received: 0 Signals delivered: 0 Page size (bytes): 4096 Exit status: 0  CPU占用率； 内存使用情况； Page Fault 情况； 进程切换情况； 文件系统IO； Socket 使用情况； ……  场景2：如何分析golang程序的内存使用情况？ （1）内存占用情况查看 场景例子代码demo","title":"Go高级编程 - 性能监测与优化实践方法"},{"content":"Hugo is the world’s fastest framework for building websites. It is written in Go.\nIt makes use of a variety of open source projects including:\n https://github.com/russross/blackfriday https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper  Learn more and contribute on GitHub.\n","permalink":"https://nicko-ch.github.io/about/","summary":"Hugo is the world’s fastest framework for building websites. It is written in Go.\nIt makes use of a variety of open source projects including:\n https://github.com/russross/blackfriday https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper  Learn more and contribute on GitHub.","title":"About"},{"content":"物理层 将计算机通过物理的方式连接起来，通过0/1的形式传输数据\n数据链路层 将电信号0和1以帧形势整合成一个个的数据包，将数据以包的形式进行解析。并且将数据包发送到子网络中的所有机器，让机器识别数据包头中的MAC地址跟自己是否匹配，从而捕获分析数据，此过程称为广播。\n网络层 在外网中，通过MAC地址去广播通信效率非常低，所以网络层主要是通过IP协议与其他的子网络进行通信。数据包通过外网ip发送到置顶的子网，子网设备内部再通过广播获取数据包。\n传输层 机器接受到数据包后，通过网卡内的端口传输到各各应用进程中。典型代表：udp、tcp协议\n应用层 应用进程通过Email、HTTP、FTP等通用协议进行收发数据包实现通信。\n","permalink":"https://nicko-ch.github.io/posts/computer-principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/20210822-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%80%83%E7%A0%94408-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","summary":"物理层 将计算机通过物理的方式连接起来，通过0/1的形式传输数据\n数据链路层 将电信号0和1以帧形势整合成一个个的数据包，将数据以包的形式进行解析。并且将数据包发送到子网络中的所有机器，让机器识别数据包头中的MAC地址跟自己是否匹配，从而捕获分析数据，此过程称为广播。\n网络层 在外网中，通过MAC地址去广播通信效率非常低，所以网络层主要是通过IP协议与其他的子网络进行通信。数据包通过外网ip发送到置顶的子网，子网设备内部再通过广播获取数据包。\n传输层 机器接受到数据包后，通过网卡内的端口传输到各各应用进程中。典型代表：udp、tcp协议\n应用层 应用进程通过Email、HTTP、FTP等通用协议进行收发数据包实现通信。","title":"计算机考研408 - 计算机网络"},{"content":"进位计数制 r进制 → 十进制 二进制 ↔ 八/十六进制 十进制 → r进制 整数位(除基取余法) 小数位(乘积取整法) ","permalink":"https://nicko-ch.github.io/posts/computer-principles/%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/20210816-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%80%83%E7%A0%94408-%E8%BF%9B%E4%BD%8D%E8%AE%A1%E6%95%B0%E5%88%B6/","summary":"进位计数制 r进制 → 十进制 二进制 ↔ 八/十六进制 十进制 → r进制 整数位(除基取余法) 小数位(乘积取整法) ","title":"计算机考研408 - 进位计数制"},{"content":"方法一：git reset\n原理： git reset的作用是修改HEAD的位置，即将HEAD指向的位置改变为之前存在的某个版本，如下图所示，假设我们要回退到版本一：\n适用场景： 如果想恢复到之前某个提交的版本，且那个版本之后提交的版本我们都不要了，就可以用这种方法。\n具体操作：\n1. 查看版本号：\n可以使用命令“git log”查看：\n也可以在github网站上查看：\n","permalink":"https://nicko-ch.github.io/posts/git/20210604-git%E6%81%A2%E5%A4%8D%E4%B9%8B%E5%89%8D%E7%89%88%E6%9C%AC%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95resetrevert/","summary":"方法一：git reset\n原理： git reset的作用是修改HEAD的位置，即将HEAD指向的位置改变为之前存在的某个版本，如下图所示，假设我们要回退到版本一：\n适用场景： 如果想恢复到之前某个提交的版本，且那个版本之后提交的版本我们都不要了，就可以用这种方法。\n具体操作：\n1. 查看版本号：\n可以使用命令“git log”查看：\n也可以在github网站上查看：","title":"Git恢复之前版本的两种方法reset、revert"},{"content":"核心原理 Namespace  独立进程，实现容器的 隔离性\n Linux Namespaces机制提供一种资源隔离方案。PID,IPC,Network等系统资源不再是全局性的，而是属于某个特定的Namespace。每个namespace下的资源对于其他namespace下的资源都是透明，不可见的。系统中可以同时存在两个进程号为0,1,2的进程，由于属于不同的namespace，所以它们之间并不冲突。而在用户层面上只能看到属于用户自己namespace下的资源，例如使用ps命令只能列出自己namespace下的进程。\nCgroups  控制进程资源分配，实现容器的 限制性\n Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。\n基于namespace实现的隔离性，只限于容器中的可视范围控制。实际上对于宿主机而言，容器中的进程也是宿主进程中的其中一个，所以理论上，容器进程和宿主进程占用的资源权限是一致的。为了防止某个容器抢占大量的资源导致其他容器乃至宿主机的奔溃，所以docker使用的linux中的cgroups进行进程资源的限制。\nps：限制某进程使用的CPU核数等\nRootfs  修改容器进程对于文件系统挂载点的可视范围，实现容器的 一致性\n 在 Linux 操作系统里，有一个名为 chroot 的命令可以帮助你在 shell 中方便地完成这个工作。顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置。\n实际上，Mount Namespace 正是基于对 chroot 的不断改良才被发明出来的，它也是 Linux 操作系统里的第一个 Namespace。它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。\n而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。\nrootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。\n由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。\n镜像 为了防止容器碎片化，提高容器的复用率。Docker支持用Dockerfile的形式，对于现有容器镜像进行二次开发和定制化。\nUnion File System Union File System 也叫 UnionFS，最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。比如，我现在有两个目录 A 和 B，它们分别有两个文件：\n$ tree\r.\r├── A\r│ ├── a\r│ └── x\r└── B\r├── b\r└── x\r然后，我使用联合挂载的方式，将这两个目录挂载到一个公共的目录 C 上：\n$ mkdir C\r$ mount -t aufs -o dirs=./A:./B none ./C\r这时，我再查看目录 C 的内容，就能看到目录 A 和 B 下的文件被合并到了一起：\n$ tree ./C\r./C\r├── a\r├── b\r└── x\rLayer Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。\n1. 只读层 它是这个容器的 rootfs 最下面的五层，对应的正是 ubuntu:latest 镜像的五层。可以看到，它们的挂载方式都是只读的（ro+wh，即 readonly+whiteout）。\n这时，我们可以分别查看一下这些层的内容：\n$ ls /var/lib/docker/aufs/diff/72b0744e06247c7d0...\retc sbin usr var\r$ ls /var/lib/docker/aufs/diff/32e8e20064858c0f2...\rrun\r$ ls /var/lib/docker/aufs/diff/a524a729adadedb900...\rbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var\r可以看到，这些层，都以增量的方式分别包含了 Ubuntu 操作系统的一部分。\n2. 可读写层 最上层的可读写层，挂载方式为：rw，即read write，Dockfile的操作将会让内容以文件的形式增量出现在这层。\n所以，最上面这个可读写层的作用，就是专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里。而当我们使用完了这个被修改过的容器之后，还可以使用 docker commit 和 push 指令，保存这个被修改过的可读写层，并上传到 Docker Hub 上，供其他人使用；而与此同时，原先的只读层里的内容则不会有任何变化。这，就是增量 rootfs 的好处。\n3. Init层 它是一个以“-init”结尾的层，夹在只读层和读写层之间。Init 层是 Docker 项目单独生成的一个内部层，专门用来存放 /etc/hosts、/etc/resolv.conf 等信息。\n需要这样一层的原因是，这些文件本来属于只读的 Ubuntu 镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如 hostname，所以就需要在可读写层对它们进行修改。\n可是，这些修改往往只对当前的容器有效，我们并不希望执行 docker commit 时，把这些信息连同可读写层一起提交掉。\n所以，Docker 做法是，在修改了这些文件之后，以一个单独的层挂载了出来。而用户执行 docker commit 只会提交可读写层，所以是不包含这些内容的。\n机制 Docker Exec $ docker exec -it 4ddf4638572d /bin/sh exec命令底层是调用了linux的setns()系统调用，作用是修改某进程内的namespace文件，将新的进程加入到指定的namespace中去。这样就实现了，讲宿主机的进程内嵌到指定的容器，并且访问视图namespace还是跟容器的一致。\nVolume  Volume 机制，允许你将宿主机上指定的目录或者文件，挂载到容器里面进行读取和修改操作。\n Linux 的绑定挂载（bind mount）机制。它的主要作用就是，允许你将一个目录或者文件，而不是整个设备，挂载到一个指定的目录上。并且，这时你在该挂载点上进行的任何操作，只是发生在被挂载的目录或者文件上，而原挂载点的内容则会被隐藏起来且不受影响。\n","permalink":"https://nicko-ch.github.io/posts/docker/20210602-docker%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/","summary":"核心原理 Namespace  独立进程，实现容器的 隔离性\n Linux Namespaces机制提供一种资源隔离方案。PID,IPC,Network等系统资源不再是全局性的，而是属于某个特定的Namespace。每个namespace下的资源对于其他namespace下的资源都是透明，不可见的。系统中可以同时存在两个进程号为0,1,2的进程，由于属于不同的namespace，所以它们之间并不冲突。而在用户层面上只能看到属于用户自己namespace下的资源，例如使用ps命令只能列出自己namespace下的进程。\nCgroups  控制进程资源分配，实现容器的 限制性\n Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。\n基于namespace实现的隔离性，只限于容器中的可视范围控制。实际上对于宿主机而言，容器中的进程也是宿主进程中的其中一个，所以理论上，容器进程和宿主进程占用的资源权限是一致的。为了防止某个容器抢占大量的资源导致其他容器乃至宿主机的奔溃，所以docker使用的linux中的cgroups进行进程资源的限制。\nps：限制某进程使用的CPU核数等\nRootfs  修改容器进程对于文件系统挂载点的可视范围，实现容器的 一致性\n 在 Linux 操作系统里，有一个名为 chroot 的命令可以帮助你在 shell 中方便地完成这个工作。顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置。\n实际上，Mount Namespace 正是基于对 chroot 的不断改良才被发明出来的，它也是 Linux 操作系统里的第一个 Namespace。它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。\n而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。\nrootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。\n由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。\n镜像 为了防止容器碎片化，提高容器的复用率。Docker支持用Dockerfile的形式，对于现有容器镜像进行二次开发和定制化。\nUnion File System Union File System 也叫 UnionFS，最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。比如，我现在有两个目录 A 和 B，它们分别有两个文件：\n$ tree\r.\r├── A\r│ ├── a\r│ └── x\r└── B\r├── b\r└── x\r然后，我使用联合挂载的方式，将这两个目录挂载到一个公共的目录 C 上：","title":"Docker核心原理"},{"content":"概述 基本名词 Producer (消息生产者)：\n向 kafka broker 发消息的客户端；\nConsumer (消息消费者)：\n向 kafka broker 取消息的客户端；\nConsumer Group (消费者组)：\n由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。\nBroker (服务器)：\n一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个broker可以容纳多个 topic。\nReplica (副本)：\n为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。\nLeader (主)：\n每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对 象都是 leader。\nFollower (从)：\n每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 leader 。\nTopic (主题)：\n主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。\nPartition (分区)：\n为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列；\nRebalance (重平衡)：\n消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。\n核心原理 分区 分区的作用就是提供负载均衡的能力，或者说对数据进行分区的主要原因，就是为了实现系统的高伸缩性（Scalability）\n分区策略：\n1、轮询策略：轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。\n2、随机策略：所谓随机就是我们随意地将消息放置到任意一个分区上。\n3、按key指定策略：将计算得出相同的key值，分配到相同的分区上。这种策略常用于某些需要顺序消费的业务应用场景。\n零拷贝 传统的io操作：\n1、第一次：将磁盘文件，读取到操作系统内核缓冲区；\n2、第二次：将内核缓冲区的数据，copy到application应用程序的buffer；\n3、第三步：将application应用程序buffer中的数据，copy到socket网络发送缓冲区(属于操作系统内核的缓冲区)；\n4、第四次：将socket buffer的数据，copy到网卡，由网卡进行网络传输。\n总结：假设内容中途不需要任何修改，内核态与用户态第二和第三步的操作则是没有意义的，为了减少io的消耗，人们提出了零拷贝的思想。\n零拷贝方式：\n原理上都是为了减少io操作的次数\n1、mmap（Memory Mapped Files）\n此方式适用于Producer到Broker的入列过程，这样即使Broker需要对消息进行修改，也可以减少io操作，直接讲内容修改映射到磁盘对应的空间，避免了用户态的过程io拷贝。\nPS：mmap也有一个很明显的缺陷——不可靠，写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。Kafka提供了一个参数——producer.type来控制是不是主动flush；如果Kafka写入到mmap之后就立即flush然后再返回Producer叫同步(sync)；写入mmap之后立即返回Producer不调用flush叫异步(async)。\n2、sendfile\n此方式适用于Broker到Consumer的出列过程，消费端获取消息的时候，不需要经过用户态的修改，可以内核态硬件之间直接进行io交互。\n","permalink":"https://nicko-ch.github.io/posts/kafka/20210412-kafa%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/","summary":"概述 基本名词 Producer (消息生产者)：\n向 kafka broker 发消息的客户端；\nConsumer (消息消费者)：\n向 kafka broker 取消息的客户端；\nConsumer Group (消费者组)：\n由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。\nBroker (服务器)：\n一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个broker可以容纳多个 topic。\nReplica (副本)：\n为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。\nLeader (主)：\n每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对 象都是 leader。\nFollower (从)：\n每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 leader 。\nTopic (主题)：\n主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。\nPartition (分区)：\n为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列；","title":"Kafa核心技术与实战"},{"content":"1. 为什么要用分布式ID 1.1 什么是分布式ID 拿MySQL数据库举个栗子：\n在我们业务数据量不大的时候，单库单表完全可以支撑现有业务，数据再大一点搞个MySQL主从同步读写分离也能对付。\n但随着数据日渐增长，主从同步也扛不住了，就需要对数据库进行分库分表，但分库分表后需要有一个唯一ID来标识一条数据，数据库的自增ID显然不能满足需求；特别一点的如订单、优惠券也都需要有唯一ID做标识。此时一个能够生成全局唯一ID的系统是非常必要的。那么这个全局唯一ID就叫分布式ID。\n1.2 那么分布式ID需要满足那些条件？  全局唯一：必须保证ID是全局性唯一的，基本要求 高性能：高可用低延时，ID生成响应要块，否则反倒会成为业务瓶颈 高可用：100%的可用性是骗人的，但是也要无限接近于100%的可用性 好接入：要秉着拿来即用的设计原则，在系统设计和实现上要尽可能的简单 趋势递增：最好趋势递增，这个要求就得看具体业务场景了，一般不严格要求  2. 分布式ID都有哪些生成方式 2.1 UUID 优点：\n 生成足够简单，本地生成无网络消耗，具有唯一性  缺点：\n 无序的字符串，不具备自增特性 没有具体的业务含义 长度较大，不适合作为数据库主键，严重影响查询性能  2.2 数据库自增ID 优点：\n 实现简单，ID主键，数值类型，带自增特性  缺点：\n DB单机生成，存在并发宕机风险，无法扛住高并发场景  2.3 数据库集群模式 为了应对单机数据库的并发压力，设计上可以用双主模式集群的方式解决，但是这样也会引入一个新的问题，两个Mysql实例都是自增ID从1开始，会产生重复的ID怎么办？\n解决方案：设置起始值和自增步长\nMySQL_1 配置：\nset @@auto_increment_offset = 1; -- 起始值\rset @@auto_increment_increment = 2; -- 步长\rMySQL_2 配置：\nset @@auto_increment_offset = 2; -- 起始值\rset @@auto_increment_increment = 2; -- 步长\r这样两个MySQL实例的自增ID分别就是：\n 1、3、5、7、9 2、4、6、8、10\n 如果日后并发上升，就要对Mysql节点进行扩容，这是一个比较麻烦的事情。并且这样会涉及到新增的Mysql实例起始值和步长修改问题，必要时可能还需要停机修改\n优点：\n 解决单点DB性能问题  缺点：\n 不利于后续扩展，而且实际上单个数据库自身压力还是大，依旧无法满足高并发场景。  2.4 数据库号段模式 号段模式是当下分布式ID生成器的主流实现方式之一，号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，例如 (1,1000] 代表1000个ID，具体的业务服务将本号段，生成1~1000的自增ID并加载到内存。表结构如下：\nCREATE TABLE id_generator (\rid int(10) NOT NULL,\rmax_id bigint(20) NOT NULL COMMENT '当前最大id',\rstep int(20) NOT NULL COMMENT '号段的布长',\rbiz_type int(20) NOT NULL COMMENT '业务类型',\rversion int(20) NOT NULL COMMENT '版本号',\rPRIMARY KEY (`id`)\r)\rbiz_type ：代表不同业务类型\nmax_id ：当前最大的可用id\nstep ：代表号段的长度\nversion ：是一个乐观锁，每次都更新version，保证并发时数据的正确性\n等这批号段ID用完，再次向数据库申请新号段，对max_id字段做一次update操作，update max_id= max_id + step，update成功则说明新号段获取成功，新的号段范围是(max_id ,max_id +step]。\nupdate id_generator set max_id = #{max_id+step}, version = version + 1 where version = # {version} and biz_type = XXX\r由于多业务端可能同时操作，所以采用版本号version乐观锁方式更新，这种分布式ID生成方式不强依赖于数据库，不会频繁的访问数据库，对数据库的压力小很多。\n2.5 Redis模式 Redis也同样可以实现，原理就是利用redis的 incr命令实现ID的原子性自增。\n127.0.0.1:6379\u0026gt; set seq_id 1 // 初始化自增ID为1\rOK\r127.0.0.1:6379\u0026gt; incr seq_id // 增加1，并返回递增后的数值\r(integer) 2\r用redis实现需要注意一点，要考虑到redis持久化的问题。redis有两种持久化方式RDB和AOF\n RDB会定时打一个快照进行持久化，假如连续自增但redis没及时持久化，而这会Redis挂掉了，重启Redis后会出现ID重复的情况。 AOF会对每条写命令进行持久化，即使Redis挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致Redis重启恢复的数据时间过长。  2.6 雪花算法（Snowflake） Snowflake生成的是Long类型的ID，一个Long类型占8个字节，每个字节占8比特，也就是说一个Long类型占64个比特。\nSnowflake ID组成结构：正数位（占1比特）+ 时间戳（占41比特）+ 机器ID（占5比特）+ 数据中心（占5比特）+ 自增值（占12比特），总共64比特组成的一个Long类型。\n 第一个bit位（1bit）：Java中long的最高位是符号位代表正负，正数是0，负数是1，一般生成ID都为正数，所以默认为0。 时间戳部分（41bit）：毫秒级的时间，不建议存当前时间戳，而是用（当前时间戳 - 固定开始时间戳）的差值，可以使产生的ID从更小的值开始；41位的时间戳可以使用69年，(1L \u0026laquo; 41) / (1000L * 60 * 60 * 24 * 365) = 69年 工作机器id（10bit）：也被叫做workId，这个可以灵活配置，机房或者机器号组合都可以。 序列号部分（12bit），自增值支持同一毫秒内同一个节点可以生成4096个ID  根据这个算法的逻辑，只需要将这个算法用Java语言实现出来，封装为一个工具方法，那么各个业务应用可以直接使用该工具方法来获取分布式ID，只需保证每个业务应用有自己的工作机器id即可，而不需要单独去搭建一个获取分布式ID的应用。\n2.7 百度（uid-generator） uid-generator是由百度技术部开发，项目GitHub地址 https://github.com/baidu/uid-generator\nuid-generator是基于Snowflake算法实现的，与原始的snowflake算法不同在于，uid-generator支持自定义时间戳、工作机器ID和 序列号 等各部分的位数，而且uid-generator中采用用户自定义workId的生成策略。\nuid-generator需要与数据库配合使用，需要新增一个WORKER_NODE表。当应用启动时会向数据库表中去插入一条数据，插入成功后返回的自增ID就是该机器的workId数据由host，port组成。\n对于uid-generator ID组成结构：\nworkId，占用了22个bit位，时间占用了28个bit位，序列化占用了13个bit位，需要注意的是，和原始的snowflake不太一样，时间的单位是秒，而不是毫秒，workId也不一样，而且同一应用每次重启就会消费一个workId。\n2.8 美团（Leaf） Leaf由美团开发，github地址：https://github.com/Meituan-Dianping/Leaf\nLeaf同时支持号段模式和snowflake算法模式，可以切换使用。\n号段模式 先导入源码 https://github.com/Meituan-Dianping/Leaf ，在建一张表leaf_alloc\nDROP TABLE IF EXISTS `leaf_alloc`;\rCREATE TABLE `leaf_alloc` (\r`biz_tag` varchar(128) NOT NULL DEFAULT '' COMMENT '业务key',\r`max_id` bigint(20) NOT NULL DEFAULT '1' COMMENT '当前已经分配了的最大id',\r`step` int(11) NOT NULL COMMENT '初始步长，也是动态调整的最小步长',\r`description` varchar(256) DEFAULT NULL COMMENT '业务key的描述',\r`update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '数据库维护的更新时间',\rPRIMARY KEY (`biz_tag`)\r) ENGINE=InnoDB;\r然后在项目中开启号段模式，配置对应的数据库信息，并关闭snowflake模式\nleaf.name=com.sankuai.leaf.opensource.test\rleaf.segment.enable=true\rleaf.jdbc.url=jdbc:mysql://localhost:3306/leaf_test?useUnicode=true\u0026amp;characterEncoding=utf8\u0026amp;characterSetResults=utf8\rleaf.jdbc.username=root\rleaf.jdbc.password=root\rleaf.snowflake.enable=false\r#leaf.snowflake.zk.address=\r#leaf.snowflake.port=\r启动leaf-server 模块的 LeafServerApplication项目就跑起来了\n号段模式获取分布式自增ID的测试url ：http：//localhost：8080/api/segment/get/leaf-segment-test\n监控号段模式：http://localhost:8080/cache\nsnowflake模式 Leaf的snowflake模式依赖于ZooKeeper，不同于原始snowflake算法也主要是在workId的生成上，Leaf中workId是基于ZooKeeper的顺序Id来生成的，每个应用在使用Leaf-snowflake时，启动时都会都在Zookeeper中生成一个顺序Id，相当于一台机器对应一个顺序节点，也就是一个workId。\nleaf.snowflake.enable=true\rleaf.snowflake.zk.address=127.0.0.1\rleaf.snowflake.port=2181\rsnowflake模式获取分布式自增ID的测试url：http://localhost:8080/api/snowflake/get/test\n2.9 滴滴（Tinyid） Tinyid由滴滴开发，Github地址：https://github.com/didi/tinyid。\nTinyid是基于号段模式原理实现的与Leaf如出一辙，每个服务获取一个号段（1000,2000]、（2000,3000]、（3000,4000]\nhttps://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aN77sK4V1x5e5dSVZcibkzSRRKsAGqcpaauibVfY9iaOR5LFvzDPictNjHXmmdhr31153iaiaStvXIJEo2g/640?wx_fmt=png\u0026amp;tp=webp\u0026amp;wxfrom=5\u0026amp;wx_lazy=1\u0026amp;wx_co=1\nTinyid提供http和tinyid-client两种方式接入\nHttp方式接入 （1）导入Tinyid源码：\ngit clone https://github.com/didi/tinyid.git\n（2）创建数据表：\nCREATE TABLE `tiny_id_info` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;自增主键\u0026#39;, `biz_type` varchar(63) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;业务类型，唯一\u0026#39;, `begin_id` bigint(20) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;开始id，仅记录初始值，无其他含义。初始化时begin_id和max_id应相同\u0026#39;, `max_id` bigint(20) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;当前最大id\u0026#39;, `step` int(11) DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;步长\u0026#39;, `delta` int(11) NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;每次id增量\u0026#39;, `remainder` int(11) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;余数\u0026#39;, `create_time` timestamp NOT NULL DEFAULT \u0026#39;2010-01-01 00:00:00\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `update_time` timestamp NOT NULL DEFAULT \u0026#39;2010-01-01 00:00:00\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, `version` bigint(20) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;版本号\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uniq_biz_type` (`biz_type`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT \u0026#39;id信息表\u0026#39;; CREATE TABLE `tiny_id_token` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;自增id\u0026#39;, `token` varchar(255) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;token\u0026#39;, `biz_type` varchar(63) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;此token可访问的业务类型标识\u0026#39;, `remark` varchar(255) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;备注\u0026#39;, `create_time` timestamp NOT NULL DEFAULT \u0026#39;2010-01-01 00:00:00\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `update_time` timestamp NOT NULL DEFAULT \u0026#39;2010-01-01 00:00:00\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT \u0026#39;token信息表\u0026#39;; INSERT INTO `tiny_id_info` (`id`, `biz_type`, `begin_id`, `max_id`, `step`, `delta`, `remainder`, `create_time`, `update_time`, `version`) VALUES (1, \u0026#39;test\u0026#39;, 1, 1, 100000, 1, 0, \u0026#39;2018-07-21 23:52:58\u0026#39;, \u0026#39;2018-07-22 23:19:27\u0026#39;, 1); INSERT INTO `tiny_id_info` (`id`, `biz_type`, `begin_id`, `max_id`, `step`, `delta`, `remainder`, `create_time`, `update_time`, `version`) VALUES (2, \u0026#39;test_odd\u0026#39;, 1, 1, 100000, 2, 1, \u0026#39;2018-07-21 23:52:58\u0026#39;, \u0026#39;2018-07-23 00:39:24\u0026#39;, 3); INSERT INTO `tiny_id_token` (`id`, `token`, `biz_type`, `remark`, `create_time`, `update_time`) VALUES (1, \u0026#39;0f673adf80504e2eaa552f5d791b644c\u0026#39;, \u0026#39;test\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2017-12-14 16:36:46\u0026#39;, \u0026#39;2017-12-14 16:36:48\u0026#39;); INSERT INTO `tiny_id_token` (`id`, `token`, `biz_type`, `remark`, `create_time`, `update_time`) VALUES (2, \u0026#39;0f673adf80504e2eaa552f5d791b644c\u0026#39;, \u0026#39;test_odd\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2017-12-14 16:36:46\u0026#39;, \u0026#39;2017-12-14 16:36:48\u0026#39;); （3）配置数据库：\ndatasource.tinyid.names=primary\rdatasource.tinyid.primary.driver-class-name=com.mysql.jdbc.Driver\rdatasource.tinyid.primary.url=jdbc:mysql://ip:port/databaseName?autoReconnect=true\u0026amp;useUnicode=true\u0026amp;characterEncoding=UTF-8\rdatasource.tinyid.primary.username=root\rdatasource.tinyid.primary.password=123456\r（4）启动tinyid-server后测试\n获取分布式自增ID: http://localhost:9999/tinyid/id/nextIdSimple?bizType=test\u0026amp;token=0f673adf80504e2eaa552f5d791b644c'\r返回结果: 3\r批量获取分布式自增ID:\rhttp://localhost:9999/tinyid/id/nextIdSimple?bizType=test\u0026amp;token=0f673adf80504e2eaa552f5d791b644c\u0026amp;batchSize=10'\r返回结果: 4,5,6,7,8,9,10,11,12,13\rJava客户端方式接入 重复Http方式的（2）（3）操作\n引入依赖\n \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.xiaoju.uemc.tinyid\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;tinyid-client\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;${tinyid.version}\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r配置文件\ntinyid.server =localhost:9999\rtinyid.token =0f673adf80504e2eaa552f5d791b644c\rtest 、tinyid.token是在数据库表中预先插入的数据，test 是具体业务类型，tinyid.token表示可访问的业务类型\n// 获取单个分布式自增ID\rLong id = TinyId . nextId( \u0026quot; test \u0026quot; );\r// 按需批量分布式自增ID\rList\u0026lt; Long \u0026gt; ids = TinyId . nextId( \u0026quot; test \u0026quot; , 10 );\r","permalink":"https://nicko-ch.github.io/posts/solution/20210408-%E5%88%86%E5%B8%83%E5%BC%8F%E5%94%AF%E4%B8%80id/","summary":"1. 为什么要用分布式ID 1.1 什么是分布式ID 拿MySQL数据库举个栗子：\n在我们业务数据量不大的时候，单库单表完全可以支撑现有业务，数据再大一点搞个MySQL主从同步读写分离也能对付。\n但随着数据日渐增长，主从同步也扛不住了，就需要对数据库进行分库分表，但分库分表后需要有一个唯一ID来标识一条数据，数据库的自增ID显然不能满足需求；特别一点的如订单、优惠券也都需要有唯一ID做标识。此时一个能够生成全局唯一ID的系统是非常必要的。那么这个全局唯一ID就叫分布式ID。\n1.2 那么分布式ID需要满足那些条件？  全局唯一：必须保证ID是全局性唯一的，基本要求 高性能：高可用低延时，ID生成响应要块，否则反倒会成为业务瓶颈 高可用：100%的可用性是骗人的，但是也要无限接近于100%的可用性 好接入：要秉着拿来即用的设计原则，在系统设计和实现上要尽可能的简单 趋势递增：最好趋势递增，这个要求就得看具体业务场景了，一般不严格要求  2. 分布式ID都有哪些生成方式 2.1 UUID 优点：\n 生成足够简单，本地生成无网络消耗，具有唯一性  缺点：\n 无序的字符串，不具备自增特性 没有具体的业务含义 长度较大，不适合作为数据库主键，严重影响查询性能  2.2 数据库自增ID 优点：\n 实现简单，ID主键，数值类型，带自增特性  缺点：\n DB单机生成，存在并发宕机风险，无法扛住高并发场景  2.3 数据库集群模式 为了应对单机数据库的并发压力，设计上可以用双主模式集群的方式解决，但是这样也会引入一个新的问题，两个Mysql实例都是自增ID从1开始，会产生重复的ID怎么办？\n解决方案：设置起始值和自增步长\nMySQL_1 配置：\nset @@auto_increment_offset = 1; -- 起始值\rset @@auto_increment_increment = 2; -- 步长\rMySQL_2 配置：\nset @@auto_increment_offset = 2; -- 起始值\rset @@auto_increment_increment = 2; -- 步长\r这样两个MySQL实例的自增ID分别就是：","title":"分布式唯一ID"},{"content":"基础篇 01丨基础架构：一条SQL查询语句是如何执行的？ 02丨日志系统：一条SQL更新语句是如何执行的？ 03丨事务隔离：为什么你改了我还看不见？  ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）\n  读未提交（read uncommitted）是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交（read committed）是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读（repeatable read）是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化（serializable ），顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。  04丨深入浅出索引（上） 哈希表 适用于只有等值查询的场景，效率高，但无法范围查询\n有序数组 等值查询和范围查询场景中的性能就都非常优秀，但是更新数据效率低下，所有后续数据需往后移\n二叉树（BST） 各方面都非常优秀，但是极端情况下可能会发展为链表\n平衡二叉树（AVL） 二叉树的变异体，会根据情况自动左右旋转，维持子节点的平衡，但是树高无法维护\n红黑树（RBT） 相比较平衡二叉树，平衡条件宽松，只需保证左右深度差一倍，使写的操作变化减少，提高写的性能\nB树 可以拥有多节点，解决平衡二叉树存在的树层级太高，降低查询复杂度\nB+树 B树的变异体，讲数据存储在叶节点（也成为聚簇索引），叶子节点会保存前后的指针地址\n05丨深入浅出索引（下） 覆盖索引 由于非主键索引存在回表的情况，所以select时选择主键字段，可以防止回表从而提高查询效率\n最左前缀原则 实践篇 09丨普通索引和唯一索引，应该怎么选择？ 查询过程  对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。   结论：性能上微乎其微，业务看具体场景\n 理论上唯一索引的性能会比普通索引快，但是引擎是按页进行读写的，所以查询key行数据时候，去取出的data page大概率会有下一行的记录，所以只需要在内存级别再判断一次下一行的记录是否符合条件。\n即使复杂情况，key行在data page最后一行，必须读取下一页。这种情况换做整型的索引，但个data page可以存放上千个key，出现这种概率的情况也是极小的。\n更新过程 了解新概念change buffer\n 当需要更新数据时候，在不影响一致性的情况下，innoDB会将这部分操作直接写到change buffer中。这样就不需要从磁盘中读取data page了。 将change buffer写入data page的过程称为merge，访问数据也则会触发，系统也会定期执行。 读取data page会占用buffer pool，这种方式可以提高内存利用率。  实际对比\n唯一索引需要将data page读入内存，判断是否存在该值，所以无法使用change buffer\n普通索引则只需要更新记录到change buffer即可结束\n 结论：读多写少的情况建议用普通索引，强业务一致性则用唯一索引\n redo log 和 change buffer 区别  redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。  10丨MySQL为什么有时候会选错索引？ 出现场景 优化器会根据不同情况选择对应的最有索引进行查询，当表数据中抽样统计的预估行数等信息出现误差时，导致优化器选择了非最优查询方式。\n执行流程 处理方法   使用analyze table命令刷新抽样统计\n  使用force index(i1)强制依赖某索引\nselect * from t force index(a) where a between 10000 and 20000;   11丨怎么给字符串字段加索引？ 完整索引 直接创建完整索引，查询次数少，但是比较占用空间\n前缀索引 节省空间，但是匹配精度降低，会增加查询扫描次数，并且无法使用覆盖索引\n倒序存储 基于前缀索引，倒序存储数据，增加数据区分度\nhash字段 创建hash字段索引，查询性能稳定，但是有额外的存储开销，并且不支持范围查询\n12丨为什么我的MySQL会“抖”一下？ 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n 执行某sql时，可能存在redo log刷新数据到到磁盘的情况，而刷新的情况可能会比较多，导致延迟比较长\n  **场景1：**redo log写满时，需要暂停所有更新操作，把数据刷入磁盘并且往前移checkpoint **场景2：**内存满了，会淘汰某些数据页，假如为“脏页”，就要先将数据刷入磁盘 **场景3：**空闲时间，应用会自动将脏页数据刷入磁盘 **场景4：**mysql关闭的话，也会将脏页数据刷入磁盘  13丨为什么表数据删掉一半，表文件大小不变？ **原因：**表数据的删除，只是讲行标记为可复用状态，但实际上还是占用内存磁盘空间的。\n**解决：**1. 重建表 alter table A engine=InnoDB\nOnline DDL（Mysql 5.6开始引入） 优化表重建过程中，有新的更新语句执行时不会阻塞整个流程\n重建表流程：\n 建立一个临时文件，扫描表 A 主键的所有数据页； 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中； 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态； 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态； 用临时文件替换表 A 的数据文件。  14丨count这么慢，我该怎么办？  MyISAM 表虽然 count(*) 很快，但是不支持事务； show table status 命令虽然返回很快，但是不准确； InnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。  对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。\n对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\n对于 count(字段) 来说：\n 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加； 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。  但是 count(*)是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。\n 结论：按照效率排序的话，count(字段)\u0026lt;count(主键 id)\u0026lt;count(1)≈count()，所以我建议你，尽量使用 count()\n 16丨“orderby”是怎么工作的？ 全字段排序流程  初始化 sort_buffer，确定放入 name、city、age 这三个字段； 从索引 city 找到第一个满足 city=\u0026lsquo;杭州’条件的主键 id，也就是图中的 ID_X； 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中； 从索引 city 取下一个记录的主键 id； 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y； 对 sort_buffer 中的数据按照字段 name 做快速排序； 按照排序结果取前 1000 行返回给客户端。  rowid排序流程  初始化 sort_buffer，确定放入两个字段，即 name 和 id； 从索引 city 找到第一个满足 city=\u0026lsquo;杭州’条件的主键 id，也就是图中的 ID_X； 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中； 从索引 city 取下一个记录的主键 id； 重复步骤 3、4 直到不满足 city=\u0026lsquo;杭州’条件为止，也就是图中的 ID_Y； 对 sort_buffer 中的数据按照字段 name 进行排序； 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。  优化  可将常需要排序的字段做联合索引 使用覆盖索引优化回表逻辑  普通排序：\n联合索引优化：\n结果Extra字段去除了Using filesort字眼，表示排序去除了文件排序方式\nalter table t add index city_user(city, name); 覆盖索引优化：\n结果Extra字段为Using index表示使用了覆盖索引，性能会更高\n17丨如何正确地显示随机消息？ 小结\n今天这篇文章，我是借着随机排序的需求，跟你介绍了 MySQL 对临时表排序的执行过程。\n如果你直接使用 order by rand()，这个语句需要 Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要量避开这种写法。\n今天的例子里面，我们不是仅仅在数据库内部解决问题，还会让应用代码配合拼接 SQL 语句。在实际应用的过程中，比较规范的用法就是：尽量将业务逻辑写在业务代码中，让数据库只做“读写数据”的事情。因此，这类方法的应用还是比较广泛的。\n18丨为什么这些SQL语句逻辑相同，性能却差异巨大？ 小结\n今天我给你举了三个例子，其实是在说同一件事儿，即：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\n第二个例子是隐式类型转换，第三个例子是隐式字符编码转换，它们都跟第一个例子一样，因为要求在索引字段上做函数操作而导致了全索引扫描。\nMySQL 的优化器确实有“偷懒”的嫌疑，即使简单地把 where id+1=1000 改写成 where id=1000-1 就能够用上索引快速查找，也不会主动做这个语句重写。\n因此，每次你的业务代码升级时，把可能出现的、新的 SQL 语句 explain 一下，是一个很好的习惯。\n19丨为什么我只查一行的语句，也执行这么慢？ ","permalink":"https://nicko-ch.github.io/posts/mysql/20210222-mysql%E5%AE%9E%E6%88%9845%E8%AE%B2/","summary":"基础篇 01丨基础架构：一条SQL查询语句是如何执行的？ 02丨日志系统：一条SQL更新语句是如何执行的？ 03丨事务隔离：为什么你改了我还看不见？  ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）\n  读未提交（read uncommitted）是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交（read committed）是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读（repeatable read）是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化（serializable ），顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。  04丨深入浅出索引（上） 哈希表 适用于只有等值查询的场景，效率高，但无法范围查询\n有序数组 等值查询和范围查询场景中的性能就都非常优秀，但是更新数据效率低下，所有后续数据需往后移\n二叉树（BST） 各方面都非常优秀，但是极端情况下可能会发展为链表\n平衡二叉树（AVL） 二叉树的变异体，会根据情况自动左右旋转，维持子节点的平衡，但是树高无法维护\n红黑树（RBT） 相比较平衡二叉树，平衡条件宽松，只需保证左右深度差一倍，使写的操作变化减少，提高写的性能\nB树 可以拥有多节点，解决平衡二叉树存在的树层级太高，降低查询复杂度\nB+树 B树的变异体，讲数据存储在叶节点（也成为聚簇索引），叶子节点会保存前后的指针地址\n05丨深入浅出索引（下） 覆盖索引 由于非主键索引存在回表的情况，所以select时选择主键字段，可以防止回表从而提高查询效率\n最左前缀原则 实践篇 09丨普通索引和唯一索引，应该怎么选择？ 查询过程  对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。   结论：性能上微乎其微，业务看具体场景\n 理论上唯一索引的性能会比普通索引快，但是引擎是按页进行读写的，所以查询key行数据时候，去取出的data page大概率会有下一行的记录，所以只需要在内存级别再判断一次下一行的记录是否符合条件。\n即使复杂情况，key行在data page最后一行，必须读取下一页。这种情况换做整型的索引，但个data page可以存放上千个key，出现这种概率的情况也是极小的。\n更新过程 了解新概念change buffer\n 当需要更新数据时候，在不影响一致性的情况下，innoDB会将这部分操作直接写到change buffer中。这样就不需要从磁盘中读取data page了。 将change buffer写入data page的过程称为merge，访问数据也则会触发，系统也会定期执行。 读取data page会占用buffer pool，这种方式可以提高内存利用率。  实际对比","title":"Mysql实战45讲 - 丁奇"},{"content":"基础用法  benchmark和普通单元测试用例一样，文件命名都为 _test.go 函数名以 Benchmark 开头，参数是 b *testing.B。 对比普通的单元测试用例： 函数名以 Test 开头，参数是 t *testing.T。  运行用例 基础用例  运行当前 package 内的用例：go test example 或 go test . 运行子 package 内的用例： go test example/\u0026lt;package name\u0026gt; 或 go test ./\u0026lt;package name\u0026gt; 如果想递归测试当前目录下的所有的 package：go test ./... 或 go test example/...。  $ go test -bench . goos: darwin goarch: amd64 pkg: example BenchmarkFib-8 200 5865240 ns/op PASS ok example 1.782s  正则匹配，例：只运行以 Fib 结尾的benchmark用例  $ go test -bench=\u0026#39;Fib$\u0026#39; . goos: darwin goarch: amd64 pkg: example BenchmarkFib-8 202 5980669 ns/op PASS ok example 1.813s  BenchmarkFib-8 中的 -8 即 GOMAXPROCS，默认等于 CPU 核数。可以通过 -cpu 参数改变 GOMAXPROCS，-cpu 支持传入一个列表作为参数，例如：  $ go test -bench=\u0026#39;Fib$\u0026#39; -cpu=2,4 . goos: darwin goarch: amd64 pkg: example BenchmarkFib-2 206 5774888 ns/op BenchmarkFib-4 205 5799426 ns/op PASS ok example 3.563s 在这个例子中，改变 CPU 的核数对结果几乎没有影响，因为这个 Fib 的调用是串行的。\n202 和 5980669 ns/op 表示用例执行了 202 次，每次花费约 0.006s。总耗时比 1s 略多。\n 对于性能测试来说，提升测试准确度的一个重要手段就是增加测试的次数。我们可以使用 -benchtime 和 -count 两个参数达到这个目的。  提升准确度 对于性能测试来说，提升测试准确度的一个重要手段就是增加测试的次数。我们可以使用 -benchtime 和 -count 两个参数达到这个目的。\nbenchmark 的默认时间是 1s，那么我们可以使用 -benchtime 指定为 5s。例如：\n$ go test -bench='Fib$' -benchtime=5s .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkFib-8 1033 5769818 ns/op\rPASS\rok example 6.554s\r 实际执行的时间是 6.5s，比 benchtime 的 5s 要长，测试用例编译、执行、销毁等是需要时间的。\n 将 -benchtime 设置为 5s，用例执行次数也变成了原来的 5倍，每次函数调用时间仍为 0.6s，几乎没有变化。\n benchtime 的值除了是时间外，还可以是具体的次数。例如，执行 30 次可以用 benchtime=30x：  $ go test -bench='Fib$' -benchtime=50x .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkFib-8 50 6121066 ns/op\rPASS\rok example 0.319s\r调用 50 次 fib(30)，仅花费了 0.319s。\n count 参数可以用来设置 benchmark 的轮数。例如，进行 3 轮 benchmark。  $ go test -bench='Fib$' -benchtime=5s -count=3 .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkFib-8 975 5946624 ns/op\rBenchmarkFib-8 1023 5820582 ns/op\rBenchmarkFib-8 961 6096816 ns/op\rPASS\rok example 19.463s\r内存分配情况  benchmem 参数可以度量内存分配的次数。内存分配次数也性能也是息息相关的，例如不合理的切片容量，将导致内存重新分配，带来不必要的开销。  在下面的例子中，generateWithCap 和 generate 的作用是一致的，生成一组长度为 n 的随机序列。唯一的不同在于，generateWithCap 创建切片时，将切片的容量(capacity)设置为 n，这样切片就会一次性申请 n 个整数所需的内存。\n// generate_test.go package main import ( \u0026#34;math/rand\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) func generateWithCap(n int) []int { rand.Seed(time.Now().UnixNano()) nums := make([]int, 0, n) for i := 0; i \u0026lt; n; i++ { nums = append(nums, rand.Int()) } return nums } func generate(n int) []int { rand.Seed(time.Now().UnixNano()) nums := make([]int, 0) for i := 0; i \u0026lt; n; i++ { nums = append(nums, rand.Int()) } return nums } func BenchmarkGenerateWithCap(b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { generateWithCap(1000000) } } func BenchmarkGenerate(b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { generate(1000000) } } 运行该用例的结果是：\ngo test -bench='Generate' .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkGenerateWithCap-8 44 24294582 ns/op\rBenchmarkGenerate-8 34 30342763 ns/op\rPASS\rok example 2.171s\r可以看到生成 100w 个数字的随机序列，GenerateWithCap 的耗时比 Generate 少 20%。\n我们可以使用 -benchmem 参数看到内存分配的情况：\ngoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkGenerateWithCap-8 43 24335658 ns/op 8003641 B/op 1 allocs/op\rBenchmarkGenerate-8 33 30403687 ns/op 45188395 B/op 40 allocs/op\rPASS\rok example 2.121s\rGenerate 分配的内存是 GenerateWithCap 的 6 倍，设置了切片容量，内存只分配一次，而不设置切片容量，内存分配了 40 次。\n测试不同的输入 不同的函数复杂度不同，O(1)，O(n)，O(n^2) 等，利用 benchmark 验证复杂度一个简单的方式，是构造不同的输入。对刚才的 benchmark 稍作改造，便能够达到目的。\n// generate_test.go package main import ( \u0026#34;math/rand\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) func generate(n int) []int { rand.Seed(time.Now().UnixNano()) nums := make([]int, 0) for i := 0; i \u0026lt; n; i++ { nums = append(nums, rand.Int()) } return nums } func benchmarkGenerate(i int, b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { generate(i) } } func BenchmarkGenerate1000(b *testing.B) { benchmarkGenerate(1000, b) } func BenchmarkGenerate10000(b *testing.B) { benchmarkGenerate(10000, b) } func BenchmarkGenerate100000(b *testing.B) { benchmarkGenerate(100000, b) } func BenchmarkGenerate1000000(b *testing.B) { benchmarkGenerate(1000000, b) } 这里，我们实现一个辅助函数 benchmarkGenerate 允许传入参数 i，并构造了 4 个不同输入的 benchmark 用例。运行结果如下：\n$ go test -bench . goos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkGenerate1000-8 34048 34643 ns/op\rBenchmarkGenerate10000-8 4070 295642 ns/op\rBenchmarkGenerate100000-8 403 3230415 ns/op\rBenchmarkGenerate1000000-8 39 32083701 ns/op\rPASS\rok example 6.597s\r通过测试结果可以发现，输入变为原来的 10 倍，函数每次调用的时长也差不多是原来的 10 倍，这说明复杂度是线性的。\nResetTimer 如果在 benchmark 开始前，需要一些准备工作，如果准备工作比较耗时，则需要将这部分代码的耗时忽略掉。比如下面的例子：\nfunc BenchmarkFib(b *testing.B) { time.Sleep(time.Second * 3) // 模拟耗时准备任务 \tfor n := 0; n \u0026lt; b.N; n++ { fib(30) // run fib(30) b.N times \t} } 运行结果是：\n$ go test -bench='Fib$' -benchtime=50x .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkFib-8 50 65912552 ns/op\rPASS\rok example 6.319s\r50次调用，每次调用约 0.66s，是之前的 0.06s 的 11 倍。究其原因，受到了耗时准备任务的干扰。我们需要用 ResetTimer 屏蔽掉：\nfunc BenchmarkFib(b *testing.B) { time.Sleep(time.Second * 3) // 模拟耗时准备任务 \tb.ResetTimer() // 重置定时器 \tfor n := 0; n \u0026lt; b.N; n++ { fib(30) // run fib(30) b.N times \t} } $ go test -bench='Fib$' -benchtime=50x .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkFib-8 50 6187485 ns/op\rPASS\rok example 6.330s\rStopTimer \u0026amp; StartTimer 还有一种情况，每次函数调用前后需要一些准备工作和清理工作，我们可以使用 StopTimer 暂停计时以及使用 StartTimer 开始计时。\n例如，如果测试一个冒泡函数的性能，每次调用冒泡函数前，需要随机生成一个数字序列，这是非常耗时的操作，这种场景下，就需要使用 StopTimer 和 StartTimer 避免将这部分时间计算在内。\n例如：\n// sort_test.go package main import ( \u0026#34;math/rand\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) func generateWithCap(n int) []int { rand.Seed(time.Now().UnixNano()) nums := make([]int, 0, n) for i := 0; i \u0026lt; n; i++ { nums = append(nums, rand.Int()) } return nums } func bubbleSort(nums []int) { for i := 0; i \u0026lt; len(nums); i++ { for j := 1; j \u0026lt; len(nums)-i; j++ { if nums[j] \u0026lt; nums[j-1] { nums[j], nums[j-1] = nums[j-1], nums[j] } } } } func BenchmarkBubbleSort(b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { b.StopTimer() nums := generateWithCap(10000) b.StartTimer() bubbleSort(nums) } } 执行该用例，每次排序耗时约 0.1s。\n$ go test -bench='Sort$' .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkBubbleSort-8 9 113280509 ns/op\rPASS\rok example 1.146s\r","permalink":"https://nicko-ch.github.io/posts/golang/20210220-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-benchmark/","summary":"基础用法  benchmark和普通单元测试用例一样，文件命名都为 _test.go 函数名以 Benchmark 开头，参数是 b *testing.B。 对比普通的单元测试用例： 函数名以 Test 开头，参数是 t *testing.T。  运行用例 基础用例  运行当前 package 内的用例：go test example 或 go test . 运行子 package 内的用例： go test example/\u0026lt;package name\u0026gt; 或 go test ./\u0026lt;package name\u0026gt; 如果想递归测试当前目录下的所有的 package：go test ./... 或 go test example/...。  $ go test -bench . goos: darwin goarch: amd64 pkg: example BenchmarkFib-8 200 5865240 ns/op PASS ok example 1.782s  正则匹配，例：只运行以 Fib 结尾的benchmark用例  $ go test -bench=\u0026#39;Fib$\u0026#39; .","title":"Go高级编程 - Benchmark"},{"content":"Golang\u0026quot;调度器\u0026quot;由来 单进程时代  单一执行流程，CPU只能顺序的执行任务队列 进程阻塞导致CPU占用，浪费硬件资源，影响执行效率  多进程、多线程时代  设计变得复杂  进程/线程的数量越多，切换CPU执行时间片成本越大 多线程随着同步竞争（如 锁、竞争资源冲突等）   缺点  高内存占用 （进程：虚拟内存4G；线程：约4MB） 高CPU调度消耗    协程（co-routine）  N:1  无法利用多个CPU 出现阻塞的瓶颈   1:1  跟多线程/多进程模型无异 协程切换成本高   M:N  能够利用多核 过于依赖协程调度器的优化和算法    调度器的优化  早期Go调度器  基本的全局Go队列和比较传统的轮询利用多个thread去调度 弊端  创建、销毁、调度G都需要每个M获取锁，形成了激烈的锁竞争 M转移G会造成延迟和额外的系统负载 系统调用（CPU在M之间的切换）导致频繁的线程阻塞和取消阻塞的操作增加了系统的开销     Goroutine优化  内存占用低（几KB，大量开辟） 灵活调度，切换成本低    GMP模型的设计思想 GMP模型简介 GMP\n G：goroutine 携程 P：processor 处理器 M：thread 内核线程\n 全局队列\n 存放等待运行的G  P的本地队列\n 存放等待运行的G 数量限制（不超过256个G） 优先将创建的G存放在P的本地队列中，如果满了会放在全局队列  P列表\n 程序启动时创建 数量最多有GOMAXPROCS个（可配置）  M列表\n 当前操作系统分配到当前GO程序的内核线程数  P和M的数量\n  P\n 环境变量$GOMAXPROCS 在程序中通过runtime.GOMAXPROCS()来设置\n   M\n Go语言本身限定M最大10000（忽略） runtime/debug 包中的SetMaxThreads函数设置 有一个M阻塞，会创建新的M； 有一个M空闲，会回收或者睡眠；\n   调度器设计策略 复用线程\n 避免频繁的创建、销毁线程，而是对线程的复用   work stealing 机制\n 当本线程无可运行的G时，尝试从其他线程绑定的P队列偷取G，而不是销毁线程。偷取数量不是单个，而是别的队列后半部分\n   hand off 机制\n 当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移到其他的空闲线程执行\n     利用并行\n GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分部在多个CPU上同时运行  抢占\n 在coroutine中等待一个协程主动让出CPU才执行下一个协程，在GO中，一个goroutine最多占用CPU 10ms，防止其他goroutine饿死  全局G队列\n 假如M的本地队列P为空，则优先从全局队列获取G，如果全局队列为空，才尝试去别的队列偷取  调度优先级  runnext-\u0026gt;local runq-\u0026gt;global runq-\u0026gt;netpoller-\u0026gt;steal\n go func() 经历过程 步骤流程  我们通过 go func()来创建一个goroutine； 有两个存储G的队列，一个是局部调度器P的本地队列、一个是全局G队列。新创建的G会先保存在P的本地队列中，如果P的本地队列已经满了就会保存在全局的队列中； G只能运行在M中，一个M必须持有一个P，M与P是1：1的关系。M会从P的本地队列列弹出一个可执行状态的G来执行，如果P的本地队列列为空，就会想其他的MP组合偷取一个可执行的G来执行； 一个M调度G执行的过程是一个循环机制； 当M执行某一个G时候如果发生了syscall或则其余阻塞操作，M会阻塞，如果当前有一些G在执行，runtime会把这个线程M从P中摘除(detach)，然后再创建一个新的操作系统的线程(如果有空闲的线程可用就复用空闲线程)来服务于这个P； 当M系统调用结束时候，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程M变成休眠状态， 加入到空闲线程中，然后这个G会被放入全局队列列中。  调度器的声明周期 M0  M0是启动程序后的编号为0的主线程，这个M对应的实例会再全局变量runtime.m0中，不需要再heap上分配，M0负责执行初始化操作和启动第一个G，在之后M0就和其他的M一样了。\n G0  G0是每次启动一个M都会第一个创建的goroutine，G0仅用于负责调度的G，G0不指向任何可执行的函数，每个M都会有一个自己的G0。在调度或系统调用时会使用G0的栈空间，全局变量的G0是M0的G0。\n 可视化GMP编程 基本trace编程 // 1. 创建trace文件 f, err := os.Create(\u0026#34;trace.out\u0026#34;) // 2. 启动trace trace.Start(f) // 3. 停止trace trace.Stop() // go build运行之后，会得到一个trace.out文件 使用可视化工具 $go tool trace trace.out Debug Trace调试 // schedtrace 为间隔多久打印信息 GODEBUG=schedtrace=1000 ./trace 参数解析  SCHED 调试信息 0ms 从程序启动到输出经历的时间 gomaxprocs P的数量（一般默认是和CPU的核数一致） idleprocs 处理idle状态的P的数量，gomaxprocs-idleprocs=目前正在执行的P数量 threads 线程数量（包括M0，包括GODEBUG调试的线程） spinningthreads 处于自旋状态的thread数量 idlethread 处理idle状态的thread runqueue 全局G队列的G数量 [0, 0] 每个P的local queue本地队列中，目前存在的G数量  场景 场景1  P拥有G1，M1获取P后开始运行G1，G1使⽤用go func()创建了G2，为了了局部性G2优先加入到P1的本地队列。  场景2  G1运行完成后(函数：goexit)，M上运行的goroutine切换为G0，G0负责调度时协程的切换（函数：schedule）。 从P的本地队列取G2，从G0切换到G2，并开始运行G2(函数：execute)。实现了线程M1的复⽤用。  场景3、4、5 场景6  规定：在创建G时，运行的G会尝试唤醒其他空闲的P和M组合去执行。 假定G2唤醒了M2，M2绑定了P2，并运行G0，但P2本地队列没有G，M2此时为自旋线程（没有G但为运行状态的线程，不断寻找G）。  场景7  M2尝试从全局队列(简称“GQ”)取一批G放到P2的本地队列（函数：findrunnable()）。M2从全局队列取的G数量量符合下⾯面的公式： $n = min(len(GQ)/GOMAXPROCS + 1, len(GQ/2))$  场景8  全局队列已经没有G，那m就要执行work stealing(偷取)：从其他有G的P哪里偷取一半G过来，放到自己的P本地队列。P2从P1的本地队列尾部取一半的G，本例中一半则只有1个G8，放到P2的本地队列并执行。  场景9  最多有GOMAXPROCS个自旋的线程(当前例子中的GOMAXPROCS=4，所以一共4个P)，多余的没事做线程会让他们休眠。  场景10  假定当前除了M3和M4为自旋线程，还有M5和M6为空闲的线程(没有得到P的绑定，注意我们这里最多就只能够存在4个P，所以P的数量应该永远是M\u0026gt;=P, 大部分都是M在抢占需要运行的P)，G8创建了了G9，G8进行了阻塞的系统调用，M2和P2立即解绑，P2会执行以下判断：如果P2本地队列有G、全局队列有G或有空闲的M，P2都会立⻢马唤醒1个M和它绑定，否则P2则会加入到空闲P列表，等待M来获取可用的p。本场景中，P2本地队列有G9，可以和其他空闲的线程M5绑定。  场景11  M2和P2会解绑，但M2会记住P2，然后G8和M2进⼊入系统调⽤用状态。当G8和M2退出系统调用时，会尝试获取P2，如果无法获取，则获取空闲的P，如果依然没有，G8会被记为可运行状态，并加入到全局队列,M2因为没有P的绑定而变成休眠状态(长时间休眠等待GC回收销毁)。  ","permalink":"https://nicko-ch.github.io/posts/golang/20210207-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-gmp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/","summary":"Golang\u0026quot;调度器\u0026quot;由来 单进程时代  单一执行流程，CPU只能顺序的执行任务队列 进程阻塞导致CPU占用，浪费硬件资源，影响执行效率  多进程、多线程时代  设计变得复杂  进程/线程的数量越多，切换CPU执行时间片成本越大 多线程随着同步竞争（如 锁、竞争资源冲突等）   缺点  高内存占用 （进程：虚拟内存4G；线程：约4MB） 高CPU调度消耗    协程（co-routine）  N:1  无法利用多个CPU 出现阻塞的瓶颈   1:1  跟多线程/多进程模型无异 协程切换成本高   M:N  能够利用多核 过于依赖协程调度器的优化和算法    调度器的优化  早期Go调度器  基本的全局Go队列和比较传统的轮询利用多个thread去调度 弊端  创建、销毁、调度G都需要每个M获取锁，形成了激烈的锁竞争 M转移G会造成延迟和额外的系统负载 系统调用（CPU在M之间的切换）导致频繁的线程阻塞和取消阻塞的操作增加了系统的开销     Goroutine优化  内存占用低（几KB，大量开辟） 灵活调度，切换成本低    GMP模型的设计思想 GMP模型简介 GMP\n G：goroutine 携程 P：processor 处理器 M：thread 内核线程","title":"Go高级编程 - GMP并发模型"},{"content":"标记清除法  STW（stop the world）→ 标记对象依赖关系 → 清楚待回收对象 → 结束STW\n 步骤：\n 暂停程序业务逻辑, 找出不可达的对象，和可达对象。 开始标记，程序找出它所有可达的对象，并做上标记。 开始清除未标记对象。 停止STW，让程序恢复运行。  缺点：\n STW严重影响程序的运行效率 标记需要扫描整个heap 清除数据也会导致产生多余的heap碎片  优化：\n 将步骤3和4互换位置，缩短STW的范围  三色标记法  白色：待回收对象 灰色：待扫描对象 黑色：已扫描对象\n 目标：处理完所有灰色的对象为止\n  步骤：\n  将所有的对象标记为默认颜色“白色”\n  从根节点（Root Set）出发，遍历将被根节点引用的对象标记为\u0026quot;灰色\u0026quot;\n  遍历灰色集合，将灰色对象引用的白色对象标记为“灰色”，然后将遍历完的灰色对象标记为“黑色”\n  重复步骤3，直到灰色集合中无任何对象\n  最后回收所有白色集合对象\n  缺点（不启动STW保护）：\n有可能造成对象丢失，即过程中黑色对象引用了白色对象，同时白色对象丢失了灰色对象的关系，导致GC把黑色对象引用的白色对象被回收\n需同时满足两条件：\n 一个白色对象被黑色对象引用（白色被挂载到黑色下） 灰色对象与被挂载的白色对象关系遭到破坏（灰色同时丢失了白色的挂载）  强弱三色不变式 强三色不变式  强制性不允许黑色对象引用白色对象（破坏条件1）\n 弱三色不变式  允许黑色对象引用白色对象，但白色对象必须存在链路上游有灰色对象保持有引用关系（破坏条件2）\n 屏障机制 插入屏障 （为保证性能不在栈上使用）\n 在A对象引用B对象的时候，B对象被标记为灰色。（将B挂载在A下，B必须标记为灰色）\n 满足强三色不变式（不存在黑色对象引用白色对象的情况，因为白色强制变为灰色）\n步骤：\n 当黑色对象引用白色对象时，触发写入屏障，使白色对象置为灰色对象。（使白色对象进入灰色集合，进入下一轮遍历） 堆上的灰色集合遍历完成后，栈进行STW，  缺点：\n结束时需要STW来重新扫描栈\n删除屏障 实际也是写，将后对象置为nil，又名为删除写屏障。\n 被删除的对象，如果自身为白色或者灰色，那么都会被标记为灰色。\n 满足弱三色不变式（保护灰色对象到白色对象的路径不会断）\n步骤：\n 当对象被删除时，触发删除写屏障，使删除对象置为灰色。（使删除对象这一轮GC不被删除） 第二轮GC，上一轮不被删除的对象讲没有上游指向，即可被GC回收  缺点：\n回收精度低，在一个对象被删除后，需要在第二轮GC才能被清楚。\n混合写屏障 栈不启用屏障\n 变形的弱三色不变式（结合了插入、删除写屏障两者的优点）\n 核心：\n GC开始时将栈上的可达对象全部扫描并标记为黑色（之后不再进行二次重复扫描，无需STW） GC期间，任何在栈上创建的新对象，均为黑色。 被删除的对象标记为灰色 被添加的对象标记为灰色  总结  GO V1.3 普通的标记清除法，整体过程需要STW，效率极低 GO V1.5 三色标记法，堆空间启动屏障，栈空间不启动，堆全部扫描后，需要重新启动一次STW扫描栈，效率普通 GO V1.8 三色标记法 + 混合写屏障机制，堆空间启动，栈空间不启动，通过特殊规则实现弱三色不变式，整体过程几乎不用STW，效率极高  ","permalink":"https://nicko-ch.github.io/posts/golang/20210105-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-gc%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%8E%9F%E7%90%86/","summary":"标记清除法  STW（stop the world）→ 标记对象依赖关系 → 清楚待回收对象 → 结束STW\n 步骤：\n 暂停程序业务逻辑, 找出不可达的对象，和可达对象。 开始标记，程序找出它所有可达的对象，并做上标记。 开始清除未标记对象。 停止STW，让程序恢复运行。  缺点：\n STW严重影响程序的运行效率 标记需要扫描整个heap 清除数据也会导致产生多余的heap碎片  优化：\n 将步骤3和4互换位置，缩短STW的范围  三色标记法  白色：待回收对象 灰色：待扫描对象 黑色：已扫描对象\n 目标：处理完所有灰色的对象为止\n  步骤：\n  将所有的对象标记为默认颜色“白色”\n  从根节点（Root Set）出发，遍历将被根节点引用的对象标记为\u0026quot;灰色\u0026quot;\n  遍历灰色集合，将灰色对象引用的白色对象标记为“灰色”，然后将遍历完的灰色对象标记为“黑色”\n  重复步骤3，直到灰色集合中无任何对象\n  最后回收所有白色集合对象\n  缺点（不启动STW保护）：\n有可能造成对象丢失，即过程中黑色对象引用了白色对象，同时白色对象丢失了灰色对象的关系，导致GC把黑色对象引用的白色对象被回收\n需同时满足两条件：\n 一个白色对象被黑色对象引用（白色被挂载到黑色下） 灰色对象与被挂载的白色对象关系遭到破坏（灰色同时丢失了白色的挂载）  强弱三色不变式 强三色不变式  强制性不允许黑色对象引用白色对象（破坏条件1）\n 弱三色不变式  允许黑色对象引用白色对象，但白色对象必须存在链路上游有灰色对象保持有引用关系（破坏条件2）","title":"Go高级编程 - GC垃圾回收原理"},{"content":"Advanced new() 和 make() 的区别 看起来二者没有什么区别，都在堆上分配内存，但是它们的行为不同，适用于不同的类型。\n new(T) 为每个新的类型T分配一片内存，初始化为 0 并且返回类型为*T的内存地址：这种方法 返回一个指向类型为 T，值为 0 的地址的指针，它适用于值类型如数组和结构体；它相当于 \u0026amp;T{}。 make(T) 返回一个类型为 T 的初始值，它只适用于3种内建的引用类型：切片、map 和 channel。  换言之，new 函数分配内存，make 函数初始化；下图给出了区别：\n译者注：如何理解new、make、slice、map、channel的关系\n1.slice、map以及channel都是golang内建的一种引用类型，三者在内存中存在多个组成部分， 需要对内存组成部分初始化后才能使用，而make就是对三者进行初始化的一种操作方式\n2. new 获取的是存储指定变量内存地址的一个变量，对于变量内部结构并不会执行相应的初始化操作， 所以slice、map、channel需要make进行初始化并获取对应的内存地址，而非new简单的获取内存地址\n fmt函数参数说明 基本\n%v\tthe value in a default format\rwhen printing structs, the plus flag (%+v) adds field names\r%#v\ta Go-syntax representation of the value\r%T\ta Go-syntax representation of the type of the value\r%%\ta literal percent sign; consumes no value\rThe default format for %v is:\nbool: %t\rint, int8 etc.: %d\ruint, uint8 etc.: %d, %#x if printed with %#v\rfloat32, complex64, etc: %g\rstring: %s\rchan: %p\rpointer: %p\rBoolean:\n%t\tthe word true or false\rInteger:\n%b\tbase 2\r%c\tthe character represented by the corresponding Unicode code point\r%d\tbase 10\r%o\tbase 8\r%q\ta single-quoted character literal safely escaped with Go syntax.\r%x\tbase 16, with lower-case letters for a-f\r%X\tbase 16, with upper-case letters for A-F\r%U\tUnicode format: U+1234; same as \u0026quot;U+%04X\u0026quot;\rFloating-point and complex constituents:\n%b\tdecimalless scientific notation with exponent a power of two,\rin the manner of strconv.FormatFloat with the 'b' format,\re.g. -123456p-78\r%e\tscientific notation, e.g. -1.234456e+78\r%E\tscientific notation, e.g. -1.234456E+78\r%f\tdecimal point but no exponent, e.g. 123.456\r%F\tsynonym for %f\r%g\t%e for large exponents, %f otherwise\r%G\t%E for large exponents, %F otherwise\rString and slice of bytes (treated equivalently with these verbs):\n%s\tthe uninterpreted bytes of the string or slice\r%q\ta double-quoted string safely escaped with Go syntax\r%x\tbase 16, lower-case, two characters per byte\r%X\tbase 16, upper-case, two characters per byte\rPointer:\n%p\tbase 16 notation, with leading 0x\r  调度模型  一言蔽之，调度的本质就是 P 将 G 合理的分配给某个 M 的过程。\n  内存模型 referrence   Page\n与TCMalloc中的Page相同，x64架构下1个Page的大小是8KB。上图的最下方，1个浅蓝色的长方形代表1个Page。\n  Span\n一组连续的Page成为Span，Span是内存管理基本单位，代码中用mspan表示\n  mcache\nmcache保存的是各种大小的Span，并按Span class分类，小对象直接从mcache分配内存，它起到了缓存的作用，并且可以无锁访问。\n  mcentral\n所有线程共享的内存块，需要加锁访问。mcentral的Span不够用时会向mheap申请内存\n  mheap\n堆内存的抽象，把从OS申请出的内存页组织成Span，并保存起来。mheap的Span不够用时会向OS申请内存。\n   并发模型  并发与并行区别 并发：指同一时刻有多条执行任务，CPU核心通过快速的切换时间单元实现的执行多任务。宏观上是同时的，但微观上仍是顺序执行的，只是进程间快速切换\n并行：值同一时刻，多条指令再多个CPU内核中同时执行，宏观和微观上都是同时执行的。\n ","permalink":"https://nicko-ch.github.io/posts/golang/20210104-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-%E5%9F%BA%E7%A1%80/","summary":"Advanced new() 和 make() 的区别 看起来二者没有什么区别，都在堆上分配内存，但是它们的行为不同，适用于不同的类型。\n new(T) 为每个新的类型T分配一片内存，初始化为 0 并且返回类型为*T的内存地址：这种方法 返回一个指向类型为 T，值为 0 的地址的指针，它适用于值类型如数组和结构体；它相当于 \u0026amp;T{}。 make(T) 返回一个类型为 T 的初始值，它只适用于3种内建的引用类型：切片、map 和 channel。  换言之，new 函数分配内存，make 函数初始化；下图给出了区别：\n译者注：如何理解new、make、slice、map、channel的关系\n1.slice、map以及channel都是golang内建的一种引用类型，三者在内存中存在多个组成部分， 需要对内存组成部分初始化后才能使用，而make就是对三者进行初始化的一种操作方式\n2. new 获取的是存储指定变量内存地址的一个变量，对于变量内部结构并不会执行相应的初始化操作， 所以slice、map、channel需要make进行初始化并获取对应的内存地址，而非new简单的获取内存地址\n fmt函数参数说明 基本\n%v\tthe value in a default format\rwhen printing structs, the plus flag (%+v) adds field names\r%#v\ta Go-syntax representation of the value\r%T\ta Go-syntax representation of the type of the value\r%%\ta literal percent sign; consumes no value\rThe default format for %v is:","title":"Go高级编程 - 基础"},{"content":"","permalink":"https://nicko-ch.github.io/posts/golang/20201231-go%E4%BC%98%E7%A7%80%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%88%86%E4%BA%AB/","summary":"","title":"Go优秀开源项目分享"},{"content":"   Title Link Description     Golang深入理解GPM模型 https://www.bilibili.com/video/BV19r4y1w7Nx    Golang中GC回收机制三色标记与混合写屏障 https://www.bilibili.com/video/BV1wz4y1y7Kd    Golang修养之路 https://www.kancloud.cn/aceld/golang/1858955    Go语言规范 https://golang.google.cn/ref/spec    GO 命令教程 https://github.com/hyper0x/go_command_tutorial    Go 语言性能优化 https://cch123.github.io/perf_opt/    图解 Go pprof 收集数据的工作流 https://mp.weixin.qq.com/s/HQzz2NQ2lSg_LLsNB7C-mw    7天用Go从零实现Web框架Gee教程 https://geektutu.com/post/gee.html    build-web-application-with-golang https://github.com/astaxie/build-web-application-with-golang    B站最深度的Golang学习到实战 up主强力推荐 https://www.bilibili.com/video/BV1TK4y1a7ex    Go contributor 解答：关于 Go GC 的 20 个核心问题 https://blog.csdn.net/RA681t58CJxsgCkJ31/article/details/103884524    Go 语言笔试面试题汇总 https://geektutu.com/post/qa-golang.html    Go 语言简明教程 https://geektutu.com/post/quick-golang.html    Go 语言高性能编程 https://geektutu.com/post/high-performance-go.html    Go语言高级编程(Advanced Go Programming) https://chai2010.gitbooks.io/advanced-go-programming-book/content/    关于Golang GC的一些误解\u0026ndash;真的比Java算法更领先吗？ https://mp.weixin.qq.com/s/eDd212DhjIRGpytBkgfzAg    图示Golang垃圾回收机制 https://zhuanlan.zhihu.com/p/297177002?utm_source=wechat_session\u0026amp;utm_medium=social\u0026amp;utm_oi=26711194337280\u0026amp;utm_campaign=shareopn    无闻 unknwon/the-way-to-go_ZH_CN https://github.com/unknwon/the-way-to-go_ZH_CN/blob/master/eBook/directory.md    bilibili技术总监毛剑：B站高可用架构实践 https://zhuanlan.zhihu.com/p/139258985     ","permalink":"https://nicko-ch.github.io/posts/golang/20201221-refference-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B/","summary":"Title Link Description     Golang深入理解GPM模型 https://www.bilibili.com/video/BV19r4y1w7Nx    Golang中GC回收机制三色标记与混合写屏障 https://www.bilibili.com/video/BV1wz4y1y7Kd    Golang修养之路 https://www.kancloud.cn/aceld/golang/1858955    Go语言规范 https://golang.google.cn/ref/spec    GO 命令教程 https://github.com/hyper0x/go_command_tutorial    Go 语言性能优化 https://cch123.github.io/perf_opt/    图解 Go pprof 收集数据的工作流 https://mp.weixin.qq.com/s/HQzz2NQ2lSg_LLsNB7C-mw    7天用Go从零实现Web框架Gee教程 https://geektutu.com/post/gee.html    build-web-application-with-golang https://github.com/astaxie/build-web-application-with-golang    B站最深度的Golang学习到实战 up主强力推荐 https://www.bilibili.com/video/BV1TK4y1a7ex    Go contributor 解答：关于 Go GC 的 20 个核心问题 https://blog.","title":"Refference - Go高级编程"},{"content":"array 数组 声明方式\nvar identifier [len]type // var arr [5]int  var arrAge = [5]int{18, 20, 15, 22, 16} // 声明容量为5的数组并初始化 var arrLazy = [...]int{5, 6, 7, 8, 22} // 初始化数组自动计算容量（实际上已是切片） var arrLazy = []int{5, 6, 7, 8, 22}\t// 初始化得到的实际上是切片slice var arrKeyValue = [5]string{3: \u0026#34;Chris\u0026#34;, 4: \u0026#34;Ron\u0026#34;} // 0,1,2 都未空值 var arrKeyValue = []string{3: \u0026#34;Chris\u0026#34;, 4: \u0026#34;Ron\u0026#34;}\t// 初始化得到的实际上是切片slice  slice 切片 本质\n不是一组数组的指针，是一种数据结构，用来操作内部元素。\n切片名称 [low : high : max] low: 起始下标位置 high: 结束下标位置 len = high - low max: 容量 cap = max - low 声明方式\nvar slice []type = arr[start:end] // 已存在arr数组时  var slice []type = make([]type, len) // 未生成数组时用make声明 var slice1 := make([]type, len) // 同上，简写  var s2 := make([]int, 10) // cap(s2) == len(s2) == 10  // make 函数参数 func make([]T, len, cap) 基本元素\n 数组与切片定义区别  创建数组时 [n] 指定数组长度 创建切片时 [] 为空，或者...\n  字符串与切片 内存结构\n修改字符串中的某个字符\n例如，将字符串 \u0026ldquo;hello\u0026rdquo; 转换为 \u0026ldquo;cello\u0026rdquo;：\ns := \u0026#34;hello\u0026#34; c := []byte(s) c[0] = \u0026#39;c\u0026#39; s2 := string(c) // s2 == \u0026#34;cello\u0026#34;  append函数常用操作 我们在第 7.5 节提到的 append 非常有用，它能够用于各种方面的操作：\n  将切片 b 的元素追加到切片 a 之后：a = append(a, b...)\n  复制切片 a 的元素到新的切片 b 上：\nb = make([]T, len(a))\rcopy(b, a)\n  删除位于索引 i 的元素：a = append(a[:i], a[i+1:]...)\n  切除切片 a 中从索引 i 至 j 位置的元素：a = append(a[:i], a[j:]...)\n  为切片 a 扩展 j 个元素长度：a = append(a, make([]T, j)...)\n  在索引 i 的位置插入元素 x：a = append(a[:i], append([]T{x}, a[i:]...)...)\n  在索引 i 的位置插入长度为 j 的新切片：a = append(a[:i], append(make([]T, j), a[i:]...)...)\n  在索引 i 的位置插入切片 b 的所有元素：a = append(a[:i], append(b, a[i:]...)...)\n  取出位于切片 a 最末尾的元素 x：x, a = a[len(a)-1], a[:len(a)-1]\n  将元素 x 追加到切片 a：a = append(a, x)\n  因此，您可以使用切片和 append 操作来表示任意可变长度的序列。\n从数学的角度来看，切片相当于向量，如果需要的话可以定义一个向量作为切片的别名来进行操作。\n如果您需要更加完整的方案，可以学习一下 Eleanor McHugh 编写的几个包：slices、chain 和 lists。\n map 字典 特点\nkey-value 键值对存储\nmap是无序的\n声明方式\nvar m1 = map[int]string // 声明map 赋值会出错 m2 := map[int]string{} // 声明并初始化map 可赋值 m3 := make(map[int]string) // 等值于m2  len(m2) // 获取map数量 ~~cap(m2)~~ // 报错!!! map不能使用cap方法  赋值\nkey值相同赋值会被覆盖\n判断是否key是否存在\nm2[key] 会返回两个值，第一个是value，第二个是bool代表key是否存在\nif v, has := m2[1]; has { fmt.Println(\u0026#34;value=\u0026#34;, v, \u0026#34;has=\u0026#34;, has) } 删除\ndelete(m2[1])  struct 结构体 声明方式\ntype Person struct { name string age int sex byte } var man Person = Person{\u0026#34;tedy\u0026#34;, \u0026#39;m\u0026#39;, 18} man2 := Person{name: \u0026#34;tedy\u0026#34;, sex: \u0026#39;f\u0026#39;} 传参方式\n默认值传递，一般不用，内存占用大，效率低\n结构体地址\n结构体指针变量的值 == 结构体首个元素的地址\n结构体指针内存模型\n强制自定义构建方法\ntype matrix struct { ... } func NewMatrix(params) *matrix { m := new(matrix) // 初始化 m  return m } package main import \u0026#34;matrix\u0026#34; ... wrong := new(matrix.matrix) // 编译失败（matrix 是私有的） right := matrix.NewMatrix(...) // 实例化 matrix 的唯一方式  字符串处理 // 按指定字符拆分 ret := strings.Split(str, \u0026#34;,\u0026#34;) // 按空格拆分 ret := strings.Fields(str) // 判断字符串结束标记 ret := strings.HasSuffix(\u0026#34;test.txt\u0026#34;, \u0026#34;.txt\u0026#34;) // 判断字符串起始标记 ret := strings.HasPrefix(\u0026#34;test.txt\u0026#34;, \u0026#34;test\u0026#34;)  文件操作 打开文件\n// 创建文件 // 不存在则创建，存在则清空 file, err := os.Create(\u0026#34;./file.txt\u0026#34;) if err != nil { fmt.Println(\u0026#34;create file error: \u0026#34;, err) } defer file.Close() fmt.Println(file) // 读取文件(只读) // 不存在读取失败 file, err := os.Open(\u0026#34;./file.txt\u0026#34;) if err != nil { fmt.Println(\u0026#34;Open file error: \u0026#34;, err) } defer file.Close() fmt.Println(file) // 读写文件(只读/只写/读写) file, err := os.OpenFile(\u0026#34;./file.txt\u0026#34;, os.O_CREATE|os.O_RDWR, 0755) if err != nil { fmt.Println(\u0026#34;OpenFile error: \u0026#34;, err) } defer file.Close() fmt.Println(file) 写文件\n// 写字符串 // windows \\r\\n // linux \\n writeByte, err := file.WriteString(\u0026#34;Hello world\\r\\n\u0026#34;) if err != nil { fmt.Println(\u0026#34;WriteString error: \u0026#34;, err) } fmt.Println(writeByte) // 获取光标 offset, _ := file.Seek(5, io.SeekStart) fmt.Println(offset) // 指定位置写入 writeByte, err := file.WriteAt([]byte(\u0026#34;1hello world\u0026#34;), offset) if err != nil { fmt.Println(\u0026#34;WriteAt error: \u0026#34;, err) } fmt.Println(writeByte) 读文件\n// 创建带有缓冲区的reader reader := bufio.NewReader(file) for { // 读取文件直到某字符 (按行读取) \treadByte, err := reader.ReadBytes(\u0026#39;\\n\u0026#39;) if err == io.EOF { fmt.Println(\u0026#34;ReadFile finished\u0026#34;) break } else if err != nil { fmt.Println(\u0026#34;ReadByte error: \u0026#34;, err) } fmt.Println(string(readByte)) }  读取文件目录 打开文件目录对象跟打开文件对象操作类似，FileMode 参数为 os.ModeDir\n通过Readdir获取到的是目录下的文件对象切片，切片内容为FileInfo接口，遍历操作即可\ntype FileInfo interface { Name() string // base name of the file \tSize() int64 // length in bytes for regular files; system-dependent for others \tMode() FileMode // file mode bits \tModTime() time.Time // modification time \tIsDir() bool // abbreviation for Mode().IsDir() \tSys() interface{} // underlying data source (can return nil) } // 读目录 dirinfo, err := os.OpenFile(\u0026#34;D:\\\\www\u0026#34;, os.O_RDONLY, os.ModeDir) if err != nil { fmt.Println(\u0026#34;OpenDifInfo error: \u0026#34;, err) } defer dirinfo.Close() fileInfo, err := dirinfo.Readdir(0) if err != nil { fmt.Println(\u0026#34;Readdir error: \u0026#34;, err) } for _, info := range fileInfo { if info.IsDir() { fmt.Println(\u0026#34;dir: \u0026#34;, info.Name()) } else { fmt.Println(\u0026#34;file: \u0026#34;, info.Name()) } }  runtime包 Gosched()：\n出让当前goroutine所占用的CPU时间片。当再次获得CPU时，从出让位置恢复继续执行\n— 时间片轮转调度算法\nGoexit()：\nreturn：返回当前函数调用者处。return之前的defer生效\nGoexit：结束当前该goroutine调用者处。goexit之前的defer生效\nGOMAXPROCS()：\n设置当前进程使用最大CPU核数，函数返回上一次调用成功的设置值，首次调用返回默认值。\n channel 通道 定义\nchdannel是一种数据类型，先进先出（FIFO）\n// 无缓冲通道 ch := make(chan int) ch := make(chan string, 0) // 读取 \u0026lt;- ch // 写入 ch \u0026lt;- // 读取和写入必须同时满足才能执行，否则一直阻塞等待  // 获取channel中剩余数据个数 len(ch) // 获取channel容量 cap(ch)  位运算 与运算 \u0026amp;\nA与B位中都为true则结果为true\n1 \u0026amp; 1 -\u0026gt; 1 1 \u0026amp; 0 -\u0026gt; 0 0 \u0026amp; 1 -\u0026gt; 0 0 \u0026amp; 0 -\u0026gt; 0 或运算 |\nA与B位中任意位为true则结果为true\n1 | 1 -\u0026gt; 1 1 | 0 -\u0026gt; 1 0 | 1 -\u0026gt; 1 0 | 0 -\u0026gt; 0 异或运算 ^\nA与B位相同则为false，不同则为true\n1 ^ 1 -\u0026gt; 0 1 ^ 0 -\u0026gt; 1 0 ^ 1 -\u0026gt; 1 0 ^ 0 -\u0026gt; 0 位清除 \u0026amp;^\nB位为true，则清零A位；B位为false，则A位保持不变；\n1 \u0026amp;^ 1 -\u0026gt; 0 1 \u0026amp;^ 0 -\u0026gt; 1 0 \u0026amp;^ 1 -\u0026gt; 0 0 \u0026amp;^ 0 -\u0026gt; 0 ","permalink":"https://nicko-ch.github.io/posts/golang/20201218-go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","summary":"array 数组 声明方式\nvar identifier [len]type // var arr [5]int  var arrAge = [5]int{18, 20, 15, 22, 16} // 声明容量为5的数组并初始化 var arrLazy = [...]int{5, 6, 7, 8, 22} // 初始化数组自动计算容量（实际上已是切片） var arrLazy = []int{5, 6, 7, 8, 22}\t// 初始化得到的实际上是切片slice var arrKeyValue = [5]string{3: \u0026#34;Chris\u0026#34;, 4: \u0026#34;Ron\u0026#34;} // 0,1,2 都未空值 var arrKeyValue = []string{3: \u0026#34;Chris\u0026#34;, 4: \u0026#34;Ron\u0026#34;}\t// 初始化得到的实际上是切片slice  slice 切片 本质\n不是一组数组的指针，是一种数据结构，用来操作内部元素。\n切片名称 [low : high : max] low: 起始下标位置 high: 结束下标位置 len = high - low max: 容量 cap = max - low 声明方式","title":"Go基础语法"},{"content":"Command 命令 git init 初始化仓库 $ git init Initialized empty Git repository in D:/www/git_class/.git/ git config 配置信息  —global [key] [value] 全局配置  $ git config --global user.name \u0026#39;Nicko_Ch\u0026#39; $ git config --global user.email cyn_411@sina.com git add {filename} 将文件添加到暂存区 $ touch README.md $ vim README.md $ git add README.md git status 查看项目的当前状态  -s 精简模式  $ git status On branch master Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: readme.txt $ git status -s M readme.txt git diff 比较文件暂存区与工作区的差异  git diff HEAD 查看所有改动 —cached 查看已缓存的改动 —stat 显示差异摘要（精简）  $ git diff warning: LF will be replaced by CRLF in readme.txt. The file will have its original line endings in your working directory diff --git a/readme.txt b/readme.txt index 9247db6..46d49bf 100644 --- a/readme.txt +++ b/readme.txt @@ -1,2 +1,2 @@ -Git is a distributed version control system. +Git is a version control system. Git is free software. git commit 将暂存区内容添加到仓库  -m 版本消息 -a 不需要执行git add命令，直接提交  $ git commit -m \u0026#34;wrote a readme file\u0026#34; [master (root-commit) f309a7b] wrote a readme file 1 file changed, 2 insertions(+) create mode 100644 readme.txt git log 查看提交记录  —pretty=oneline 单行模式（精简）  $ git log commit 2e4ced01341d4c11fee696d5501a54d9efe0b7d8 (HEAD -\u0026gt; master) Author: chenyaonan \u0026lt;chenyaonan@yy.com\u0026gt; Date: Wed Dec 16 10:54:08 2020 +0800 add GPL commit 441467e621e25042afa5a39d59f0d06e75bda3e6 Author: chenyaonan \u0026lt;chenyaonan@yy.com\u0026gt; Date: Wed Dec 16 10:33:48 2020 +0800 add distributed commit f309a7b35c0182eb5656a76c1342c869c1a283a6 Author: chenyaonan \u0026lt;chenyaonan@yy.com\u0026gt; Date: Wed Dec 16 10:18:42 2020 +0800 wrote a readme file $ git log --pretty=oneline 2e4ced01341d4c11fee696d5501a54d9efe0b7d8 (HEAD -\u0026gt; master) add GPL 441467e621e25042afa5a39d59f0d06e75bda3e6 add distributed f309a7b35c0182eb5656a76c1342c869c1a283a6 wrote a readme file git reflog 查看所有分支的提交记录 $ git reflog 441467e (HEAD -\u0026gt; master) HEAD@{0}: reset: moving to 4414 2e4ced0 HEAD@{1}: reset: moving to 2e4ced01341d4c11fee696d5501a54d9efe0b7d8 441467e (HEAD -\u0026gt; master) HEAD@{2}: reset: moving to HEAD^ 2e4ced0 HEAD@{3}: commit: add GPL 441467e (HEAD -\u0026gt; master) HEAD@{4}: commit: add distributed f309a7b HEAD@{5}: commit (initial): wrote a readme file git reset [HEAD] 回退到指定版本  —mixed 默认选项 —soft 保留工作区，并且重置到置顶版本（新差异放入暂存区） —hard 强制回滚（会删除版本信息）   HEAD 说明：\n  HEAD 表示当前版本 HEAD^ 上一个版本 HEAD^^ 上上一个版本 HEAD^^^ 上上上一个版本 以此类推\u0026hellip;  可以使用 ～数字表示\n HEAD~0 表示当前版本 HEAD~1 上一个版本 HEAD^2 上上一个版本 HEAD^3 上上上一个版本 以此类推\u0026hellip;    $ git reset --hard HEAD^ HEAD is now at 441467e add distributed git revert [HEAD] 撤销某次提交 $ git revert de5d349136589435 Removing rm.txt [master 5fb281e] Revert \u0026#34;add rm.txt\u0026#34; 1 file changed, 0 insertions(+), 0 deletions(-) delete mode 100644 rm.txt git checkout [HEAD] 切换分支 $ git checkout feature/20201212-learngit git checkout — [file] 撤销修改 $ git checkout -- readme.txt git rm [file] 删除文件 $ rm readme.txt $ git rm readme.txt rm \u0026#39;readme.txt\u0026#39; $ git commit -m \u0026#34;delete readme.txt\u0026#34; [master 625d001] delete readme.txt 1 file changed, 0 insertions(+), 0 deletions(-) delete mode 100644 readme.txt git tag 打标签  -l \u0026lsquo;keyword\u0026rsquo; 搜索标签名  $ git tag v1.0 $ git tag v1.0 // 后期打标签 $ git tag v0.1 a66325 ","permalink":"https://nicko-ch.github.io/posts/git/20201216-git%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","summary":"Command 命令 git init 初始化仓库 $ git init Initialized empty Git repository in D:/www/git_class/.git/ git config 配置信息  —global [key] [value] 全局配置  $ git config --global user.name \u0026#39;Nicko_Ch\u0026#39; $ git config --global user.email cyn_411@sina.com git add {filename} 将文件添加到暂存区 $ touch README.md $ vim README.md $ git add README.md git status 查看项目的当前状态  -s 精简模式  $ git status On branch master Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;.","title":"Git基础语法"},{"content":"   Terms     分布式事务方式   bloom filter   Bitmap   nginx平滑重启原理   Linux内核特性之VDSO   NTP UPDATE 和 NTPD   QUICK   Head-of-line blocking   cgroup   Scaling Memcache At Facebook   errorgroup   pipeline   链表   bytegraph   neo4j   发号器   Graph DB   位与操作   网易DDB   sharding   SOA   DDD   Machine line   COW   \u0026ldquo;nginx_pool_t \u0026quot;   tcmalloc   sync.pool 对象池   内存池   内存碎片 内存对齐   微博redis关系链   redis-cluster   single fly 单飞模式   一致性哈希   有界负载一致性哈希   slot sharding   pipeline   databus   flink   LVS    ","permalink":"https://nicko-ch.github.io/posts/%E6%9D%82%E9%A1%B9/20201215-terms/","summary":"Terms     分布式事务方式   bloom filter   Bitmap   nginx平滑重启原理   Linux内核特性之VDSO   NTP UPDATE 和 NTPD   QUICK   Head-of-line blocking   cgroup   Scaling Memcache At Facebook   errorgroup   pipeline   链表   bytegraph   neo4j   发号器   Graph DB   位与操作   网易DDB   sharding   SOA   DDD   Machine line   COW   \u0026ldquo;nginx_pool_t \u0026quot;   tcmalloc   sync.","title":"Terms"},{"content":"Laradock 切换 数据库5.7版本 1. 修改.env文件 源文件\n### MYSQL #################################################\rMYSQL_VERSION=latest\rMYSQL_DATABASE=default\rMYSQL_USER=default\rMYSQL_PASSWORD=secret\rMYSQL_PORT=3306\rMYSQL_ROOT_PASSWORD=root123456\rMYSQL_ENTRYPOINT_INITDB=./mysql/docker-entrypoint-initdb.d\r修改为\n### MYSQL #################################################\rMYSQL_VERSION=5.7.24\rMYSQL_DATABASE=default\rMYSQL_USER=default\rMYSQL_PASSWORD=secret\rMYSQL_PORT=3306\rMYSQL_ROOT_PASSWORD=root123456\rMYSQL_ENTRYPOINT_INITDB=./mysql/docker-entrypoint-initdb.d\r 2. 删除旧容器相关数据 2.1 列出所有容器 docker ps -a\r2.2 停止所有容器 docker ps -a\r2.3 删除容器 docker rm \u0026lt;容器ID1\u0026gt; \u0026lt;容器ID2\u0026gt; ...\r2.4 列出镜像 docker images\r2.5 删除镜像 docker rmi \u0026lt;镜像ID1\u0026gt; \u0026lt;镜像ID2\u0026gt; ...\r2.6 查看挂载盘 docker volume ls\r2.7 删除镜像 docker volume rm \u0026lt;VOLUME NAME1\u0026gt; \u0026lt;VOLUME NAME2\u0026gt; ...\r 3. 重新加载创建新容器 3.1 启动Mysql docker-compose up -d mysql\r 未清理干净残留数据可能导致错误 导致产生 Exited(2) 错误 mysql_1 | 2017-05-19T08:37:22.284861Z 0 [ERROR] InnoDB: posix_fallocate(): Failed to preallocate data for file ./mysql/time_zone.ibd, desired size 16384 bytes. Operating system error number 28. Check that the disk is not full or a disk quota exceeded. Make sure the file system supports this function. Some operating system error numbers are described at http://dev.mysql.com/doc/refman/5.7/en/ operating-system-error-codes.html\rmysql_1 | 2017-05-19T08:37:22.284915Z 0 [Warning] InnoDB: Retry attempts for writing partial data failed.\rmysql_1 | 2017-05-19T08:37:22.284923Z 0 [Warning] InnoDB: Error while writing 16384 zeroes to ./mysql/time_zone.ibd starting at offset 131072\rmysql_1 | 2017-05-19T08:37:22.335184Z 0 [ERROR] InnoDB: posix_fallocate(): Failed to preallocate data for file ./mysql/time_zone.ibd, desired size 16384 bytes. Operating system error number 28. Check that the disk is not full or a disk quota exceeded. Make sure the file system supports this function. Some operating system error numbers are described at http://dev.mysql.com/doc/refman/5.7/en/ operating-system-error-codes.html\rmysql_1 | 2017-05-19T08:37:22.335236Z 0 [Warning] InnoDB: Retry attempts for writing partial data failed.\rmysql_1 | 2017-05-19T08:37:22.335244Z 0 [Warning] InnoDB: Error while writing 16384 zeroes to ./mysql/time_zone.ibd starting at offset 131072\rmysql_1 | 2017-05-19T08:37:22.385395Z 0 [ERROR] InnoDB: posix_fallocate(): Failed to preallocate data for file ./mysql/time_zone.ibd, desired size 16384 bytes. Operating system error number 28. Check that the disk is not full or a disk quota exceeded. Make sure the file system supports this function. Some operating system error numbers are described at http://dev.mysql.com/doc/refman/5.7/en/ operating-system-error-codes.html\rmysql_1 | 2017-05-19T08:37:22.385444Z 0 [Warning] InnoDB: Retry attempts for writing partial data failed.\rmysql_1 | 2017-05-19T08:37:22.385452Z 0 [Warning] InnoDB: Error while writing 16384 zeroes to ./mysql/time_zone.ibd starting at offset 131072\rmysql_1 | 2017-05-19T08:37:22.435737Z 0 [ERROR] InnoDB: posix_fallocate(): Failed to preallocate data for file ./mysql/time_zone.ibd, desired size 16384 bytes. Operating system error number 28. Check that the disk is not full or a disk quota exceeded. Make sure the file system supports this function. Some operating system error numbers are described at http://dev.mysql.com/doc/refman/5.7/en/ operating-system-error-codes.html\rmysql_1 | 2017-05-19T08:37:22.435788Z 0 [Warning] InnoDB: Retry attempts for writing partial data failed.\rmysql_1 | 2017-05-19T08:37:22.435797Z 0 [Warning] InnoDB: Error while writing 16384 zeroes to ./mysql/time_zone.ibd starting at offset 131072\rmysql_1 | 2017-05-19T08:37:22.435957Z 0 [ERROR] [FATAL] InnoDB: Out of tablespace during rollback. Consider increasing your tablespace.\rmysql_1 | 2017-05-19 08:37:22 0x7fd031586700 InnoDB: Assertion failure in thread 140532157802240 in file ut0ut.cc line 916\rmysql_1 | InnoDB: We intentionally generate a memory trap.\rmysql_1 | InnoDB: Submit a detailed bug report to http://bugs.mysql.com.\rmysql_1 | InnoDB: If you get repeated assertion failures or crashes, even\rmysql_1 | InnoDB: immediately after the mysqld startup, there may be\rmysql_1 | InnoDB: corruption in the InnoDB tablespace. Please refer to\rmysql_1 | InnoDB: http://dev.mysql.com/doc/refman/5.7/en/forcing-innodb-recovery.html\rmysql_1 | InnoDB: about forcing recovery.\rmysql_1 | 08:37:22 UTC - mysqld got signal 6 ;\rmysql_1 | This could be because you hit a bug. It is also possible that this binary\rmysql_1 | or one of the libraries it was linked against is corrupt, improperly built,\rmysql_1 | or misconfigured. This error can also be caused by malfunctioning hardware.\rmysql_1 | Attempting to collect some information that could help diagnose the problem.\rmysql_1 | As this is a crash and something is definitely wrong, the information\rmysql_1 | collection process might fail.\rmysql_1 |\rmysql_1 | key_buffer_size=8388608\rmysql_1 | read_buffer_size=131072\rmysql_1 | max_used_connections=0\rmysql_1 | max_threads=151\rmysql_1 | thread_count=0\rmysql_1 | connection_count=0\rmysql_1 | It is possible that mysqld could use up to\rmysql_1 | key_buffer_size + (read_buffer_size + sort_buffer_size)*max_threads = 68190 K bytes of memory\rmysql_1 | Hope that's ok; if not, decrease some variables in the equation.\rmysql_1 |\rmysql_1 | Thread pointer: 0x0\rmysql_1 | Attempting backtrace. You can use the following information to find out\rmysql_1 | where mysqld died. If you see no messages after this, something went\rmysql_1 | terribly wrong...\rmysql_1 | stack_bottom = 0 thread_stack 0x40000\rmysql_1 | mysqld(my_print_stacktrace+0x2c)[0xe81c7c]\rmysql_1 | mysqld(handle_fatal_signal+0x459)[0x7aa4c9]\rmysql_1 | /lib/x86_64-linux-gnu/libpthread.so.0(+0xf890)[0x7fd04d101890]\rmysql_1 | /lib/x86_64-linux-gnu/libc.so.6(gsignal+0x37)[0x7fd04bb0a067]\rmysql_1 | /lib/x86_64-linux-gnu/libc.so.6(abort+0x148)[0x7fd04bb0b448]\rmysql_1 | mysqld[0x780c0b]\rmysql_1 | mysqld(_ZN2ib5fatalD1Ev+0x15d)[0x110b54d]\rmysql_1 | mysqld(_Z13row_undo_stepP9que_thr_t+0x66c)[0x109785c]\rmysql_1 | mysqld(_Z15que_run_threadsP9que_thr_t+0xa34)[0x1026a74]\rmysql_1 | mysqld(_Z31trx_rollback_or_clean_recoveredm+0xd2f)[0x10e693f]\rmysql_1 | mysqld(trx_rollback_or_clean_all_recovered+0x4e)[0x10e77de]\rmysql_1 | /lib/x86_64-linux-gnu/libpthread.so.0(+0x8064)[0x7fd04d0fa064]\rmysql_1 | /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7fd04bbbd62d]\rmysql_1 | The manual page at http://dev.mysql.com/doc/mysql/en/crashing.html contains\rmysql_1 | information that should help you find out what is causing the crash.\rlaradock_mysql_1 exited with code 2\r处理方法  删除容器挂载盘 清空mysql挂载目录  ~/.laradock/data (默认目录)\r 修改.env文件中mysql保存路径  # Choose storage path on your machine. For all storage systems\rDATA_PATH_HOST=~/.laradock/\u0026lt;project name\u0026gt;/data\r  ","permalink":"https://nicko-ch.github.io/posts/%E6%9D%82%E9%A1%B9/20181107-laradock-%E5%88%87%E6%8D%A2%E6%95%B0%E6%8D%AE%E5%BA%93%E9%94%99%E8%AF%AF/","summary":"Laradock 切换 数据库5.7版本 1. 修改.env文件 源文件\n### MYSQL #################################################\rMYSQL_VERSION=latest\rMYSQL_DATABASE=default\rMYSQL_USER=default\rMYSQL_PASSWORD=secret\rMYSQL_PORT=3306\rMYSQL_ROOT_PASSWORD=root123456\rMYSQL_ENTRYPOINT_INITDB=./mysql/docker-entrypoint-initdb.d\r修改为\n### MYSQL #################################################\rMYSQL_VERSION=5.7.24\rMYSQL_DATABASE=default\rMYSQL_USER=default\rMYSQL_PASSWORD=secret\rMYSQL_PORT=3306\rMYSQL_ROOT_PASSWORD=root123456\rMYSQL_ENTRYPOINT_INITDB=./mysql/docker-entrypoint-initdb.d\r 2. 删除旧容器相关数据 2.1 列出所有容器 docker ps -a\r2.2 停止所有容器 docker ps -a\r2.3 删除容器 docker rm \u0026lt;容器ID1\u0026gt; \u0026lt;容器ID2\u0026gt; ...\r2.4 列出镜像 docker images\r2.5 删除镜像 docker rmi \u0026lt;镜像ID1\u0026gt; \u0026lt;镜像ID2\u0026gt; ...\r2.6 查看挂载盘 docker volume ls\r2.7 删除镜像 docker volume rm \u0026lt;VOLUME NAME1\u0026gt; \u0026lt;VOLUME NAME2\u0026gt; .","title":"Laradock 切换数据库错误"},{"content":"phpstorm 为了方便用户管理项目目录，目前可以将项目文件夹设置为 4 类 Test,Sources,Excluded,Resource Root。 1. Test (颜色为绿色) \u0026gt; 测试主目录，如 `Laravel` 的 `tests` 目录\r2. Source (颜色为蓝色) \u0026gt; 项目主代码目录，如 `Laravel` 的 `app` 目录\r3. Excluded (颜色为红色) \u0026gt; 第三方扩展依赖(不会修改代码)，不建立索引，不由`phpstorm`管理，如 `Laravel` 的 `vendor` 目录\r4. Resource Root (颜色为紫色) \u0026gt; 前端资源，如 `Laravel` 的 `public` 目录\r合理设置项目的目录是有作用的，如  1 设置 Test 目录，可以在project勾选只显示 Test,方便测试时查看 2 设置 Excluded 目录，可以减少 phpstorm 建立索引的时间 3 设置 Resource Root 目录，以 Laravel 为例，可以帮助检测模板文件的资源路径    ","permalink":"https://nicko-ch.github.io/posts/%E6%9D%82%E9%A1%B9/20181101-phpstorm-%E9%A1%B9%E7%9B%AE%E7%9B%AE%E5%BD%95%E5%88%86%E7%B1%BB%E7%AE%A1%E7%90%86%E9%85%8D%E7%BD%AE/","summary":"phpstorm 为了方便用户管理项目目录，目前可以将项目文件夹设置为 4 类 Test,Sources,Excluded,Resource Root。 1. Test (颜色为绿色) \u0026gt; 测试主目录，如 `Laravel` 的 `tests` 目录\r2. Source (颜色为蓝色) \u0026gt; 项目主代码目录，如 `Laravel` 的 `app` 目录\r3. Excluded (颜色为红色) \u0026gt; 第三方扩展依赖(不会修改代码)，不建立索引，不由`phpstorm`管理，如 `Laravel` 的 `vendor` 目录\r4. Resource Root (颜色为紫色) \u0026gt; 前端资源，如 `Laravel` 的 `public` 目录\r合理设置项目的目录是有作用的，如  1 设置 Test 目录，可以在project勾选只显示 Test,方便测试时查看 2 设置 Excluded 目录，可以减少 phpstorm 建立索引的时间 3 设置 Resource Root 目录，以 Laravel 为例，可以帮助检测模板文件的资源路径    ","title":"PHPStorm 项目目录分类管理配置"},{"content":"『Cmd 技术渲染的沙箱页面，点击此处编写自己的文档』\nCmd Markdown 简明语法手册 标签： Cmd-Markdown\n 1. 斜体和粗体 使用 * 和 ** 表示斜体和粗体。\n示例：\n这是 斜体，这是 粗体。\n2. 分级标题 使用 === 表示一级标题，使用 \u0026mdash; 表示二级标题。\n示例：\n这是一个一级标题\r============================\r这是一个二级标题\r--------------------------------------------------\r### 这是一个三级标题\r你也可以选择在行首加井号表示不同级别的标题 (H1-H6)，例如：# H1, ## H2, ### H3，#### H4。\n3. 外链接 使用 [描述](链接地址) 为文字增加外链接。\n示例：\n这是去往 本人博客 的链接。\n4. 无序列表 使用 *，+，- 表示无序列表。\n示例：\n 无序列表项 一 无序列表项 二 无序列表项 三  5. 有序列表 使用数字和点表示有序列表。\n示例：\n 有序列表项 一 有序列表项 二 有序列表项 三  6. 文字引用 使用 \u0026gt; 表示文字引用。\n示例：\n 野火烧不尽，春风吹又生。\n 7. 行内代码块 使用 `代码` 表示行内代码块。\n示例：\n让我们聊聊 html。\n8. 代码块 使用 四个缩进空格 表示代码块。\n示例：\n这是一个代码块，此行左侧有四个不可见的空格。\r 9. 插入图像 使用 ![描述](图片链接地址) 插入图像。\n示例：\nCmd Markdown 高阶语法手册 1. 内容目录 在段落中填写 [TOC] 以显示全文内容的目录结构。\n[TOC]\n2. 标签分类 在编辑区任意行的列首位置输入以下代码给文稿标签：\n标签： 数学 英语 Markdown\n或者\nTags： 数学 英语 Markdown\n3. 删除线 使用 ~~ 表示删除线。\n这是一段错误的文本。\n4. 注脚 使用 [^keyword] 表示注脚。\n这是一个注脚1的样例。\n这是第二个注脚2的样例。\n5. LaTeX 公式 $ 表示行内公式：\n质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。\n$$ 表示整行公式：\n$$\\sum_{i=1}^n a_i=0$$\n$$f(x_1,x_x,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2 $$\n$$\\sum^{j-1}{k=0}{\\widehat{\\gamma}{kj} z_k}$$\n访问 MathJax 参考更多使用方法。\n6. 加强的代码块 支持四十一种编程语言的语法高亮的显示，行号显示。\n非代码示例：\n$ sudo apt-get install vim-gnome\rPython 示例：\n@requires_authorization def somefunc(param1=\u0026#39;\u0026#39;, param2=0): \u0026#39;\u0026#39;\u0026#39;A docstring\u0026#39;\u0026#39;\u0026#39; if param1 \u0026gt; param2: # interesting print \u0026#39;Greater\u0026#39; return (param2 - param1 + 1) or None class SomeClass: pass \u0026gt;\u0026gt;\u0026gt; message = \u0026#39;\u0026#39;\u0026#39;interpreter ... prompt\u0026#39;\u0026#39;\u0026#39; JavaScript 示例：\n/** * nth element in the fibonacci series. * @param n \u0026gt;= 0 * @return the nth element, \u0026gt;= 0. */ function fib(n) { var a = 1, b = 1; var tmp; while (--n \u0026gt;= 0) { tmp = a; a += b; b = tmp; } return a; } document.write(fib(10)); 7. 流程图 示例 st=\u0026gt;start: Start:\u0026gt;https://www.zybuluo.com\rio=\u0026gt;inputoutput: verification\rop=\u0026gt;operation: Your Operation\rcond=\u0026gt;condition: Yes or No?\rsub=\u0026gt;subroutine: Your Subroutine\re=\u0026gt;end\rst-\u0026gt;io-\u0026gt;op-\u0026gt;cond\rcond(yes)-\u0026gt;e\rcond(no)-\u0026gt;sub-\u0026gt;io\r更多语法参考：流程图语法参考 8. 序列图 示例 1 Alice-\u0026gt;Bob: Hello Bob, how are you?\rNote right of Bob: Bob thinks\rBob--\u0026gt;Alice: I am good thanks!\r示例 2 sequenceDiagram\rTitle: Here is a title\rA-\u0026gt;B: Normal line\rB--\u0026gt;C: Dashed line\rC-\u0026gt;\u0026gt;D: Open arrow\rD--\u0026gt;\u0026gt;A: Dashed open arrow\r更多语法参考：序列图语法参考 9. 甘特图 甘特图内在思想简单。基本是一条线条图，横轴表示时间，纵轴表示活动（项目），线条表示在整个期间上计划和实际的活动完成情况。它直观地表明任务计划在什么时候进行，及实际进展与计划要求的对比。\ngantt\rdateFormat YYYY-MM-DD\rtitle Adding GANTT diagram functionality to mermaid\rsection A section\rCompleted task :done, des1, 2014-01-06,2014-01-08\rActive task :active, des2, 2014-01-09, 3d\rFuture task : des3, after des2, 5d\rFuture task2 : des4, after des3, 5d\rsection Critical tasks\rCompleted task in the critical line :crit, done, 2014-01-06,24h\rImplement parser and jison :crit, done, after des1, 2d\rCreate tests for parser :crit, active, 3d\rFuture task in critical line :crit, 5d\rCreate tests for renderer :2d\rAdd to mermaid :1d\rsection Documentation\rDescribe gantt syntax :active, a1, after des1, 3d\rAdd gantt diagram to demo page :after a1 , 20h\rAdd another diagram to demo page :doc1, after a1 , 48h\rsection Last section\rDescribe gantt syntax :after doc1, 3d\rAdd gantt diagram to demo page :20h\rAdd another diagram to demo page :48h\r更多语法参考：甘特图语法参考 10. Mermaid 流程图 graph LR\rA[Hard edge] --\u0026gt;|Link text| B(Round edge)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result one]\rC --\u0026gt;|Two| E[Result two]\r更多语法参考：Mermaid 流程图语法参考 11. Mermaid 序列图 sequenceDiagram\rAlice-\u0026gt;John: Hello John, how are you?\rJohn--\u0026gt;Alice: Great!\r更多语法参考：Mermaid 序列图语法参考 12. 表格支持    项目 价格 数量     计算机 $1600 5   手机 $12 12   管线 $1 234    13. 定义型列表  名词 1 定义 1（左侧有一个可见的冒号和四个不可见的空格） 代码块 2 这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格） 代码块（左侧有八个不可见的空格）\r   14. Html 标签 本站支持在 Markdown 语法中嵌套 Html 标签，譬如，你可以用 Html 写一个纵跨两行的表格：\n\u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th rowspan=\u0026#34;2\u0026#34;\u0026gt;值班人员\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;星期一\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;星期二\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;星期三\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;李强\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;张明\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;王平\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; 15. 内嵌图标 本站的图标系统对外开放，在文档中输入\n\u0026lt;i class=\u0026quot;icon-weibo\u0026quot;\u0026gt;\u0026lt;/i\u0026gt;\r 即显示微博的图标： 替换 上述 i 标签 内的 icon-weibo 以显示不同的图标，例如：\n\u0026lt;i class=\u0026quot;icon-renren\u0026quot;\u0026gt;\u0026lt;/i\u0026gt;\r 即显示人人的图标： 更多的图标和玩法可以参看 font-awesome 官方网站。\n16. 待办事宜 Todo 列表 使用带有 [ ] 或 [x] （未完成或已完成）项的列表语法撰写一个待办事宜列表，并且支持子列表嵌套以及混用Markdown语法，例如：\n- [ ] **Cmd Markdown 开发** - [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 - [ ] 支持以 PDF 格式导出文稿 - [x] 新增Todo列表功能 [语法参考](https://github.com/blog/1375-task-lists-in-gfm-issues-pulls-comments) - [x] 改进 LaTex 功能 - [x] 修复 LaTex 公式渲染问题 - [x] 新增 LaTex 公式编号功能 [语法参考](http://docs.mathjax.org/en/latest/tex.html#tex-eq-numbers) - [ ] **七月旅行准备** - [ ] 准备邮轮上需要携带的物品 - [ ] 浏览日本免税店的物品 - [x] 购买蓝宝石公主号七月一日的船票 对应显示如下待办事宜 Todo 列表：\n Cmd Markdown 开发  改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 支持以 PDF 格式导出文稿 新增Todo列表功能 语法参考 改进 LaTex 功能  修复 LaTex 公式渲染问题 新增 LaTex 公式编号功能 语法参考     七月旅行准备  准备邮轮上需要携带的物品 浏览日本免税店的物品 购买蓝宝石公主号七月一日的船票        这是一个 注脚 的 文本。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n 这是另一个 注脚 的 文本。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://nicko-ch.github.io/posts/%E6%9D%82%E9%A1%B9/20181031-md%E7%AE%80%E6%98%8E%E8%AF%AD%E6%B3%95%E6%89%8B%E5%86%8C/","summary":"『Cmd 技术渲染的沙箱页面，点击此处编写自己的文档』\nCmd Markdown 简明语法手册 标签： Cmd-Markdown\n 1. 斜体和粗体 使用 * 和 ** 表示斜体和粗体。\n示例：\n这是 斜体，这是 粗体。\n2. 分级标题 使用 === 表示一级标题，使用 \u0026mdash; 表示二级标题。\n示例：\n这是一个一级标题\r============================\r这是一个二级标题\r--------------------------------------------------\r### 这是一个三级标题\r你也可以选择在行首加井号表示不同级别的标题 (H1-H6)，例如：# H1, ## H2, ### H3，#### H4。\n3. 外链接 使用 [描述](链接地址) 为文字增加外链接。\n示例：\n这是去往 本人博客 的链接。\n4. 无序列表 使用 *，+，- 表示无序列表。\n示例：\n 无序列表项 一 无序列表项 二 无序列表项 三  5. 有序列表 使用数字和点表示有序列表。\n示例：\n 有序列表项 一 有序列表项 二 有序列表项 三  6.","title":"Cmd Markdown 简明语法手册"},{"content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start Create a new post $ hexo new \u0026#34;My New Post\u0026#34; More info: Writing\nRun server $ hexo server More info: Server\nGenerate static files $ hexo generate More info: Generating\nDeploy to remote sites $ hexo deploy More info: Deployment\n  ","permalink":"https://nicko-ch.github.io/posts/%E6%9D%82%E9%A1%B9/20181023-quick-start/","summary":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start Create a new post $ hexo new \u0026#34;My New Post\u0026#34; More info: Writing\nRun server $ hexo server More info: Server\nGenerate static files $ hexo generate More info: Generating\nDeploy to remote sites $ hexo deploy More info: Deployment","title":"Hello World"},{"content":"Prerequisites 1. install hugo //下载hugo编译文件 2. install git Add Content 新增文章\nhugo new posts/my-first-post.md 修改文章属性\n--- title: \u0026#34;My First Post\u0026#34; categoried: 分类 date: 2022-11-20T09:03:20-08:00 tags: - 标签1 - 标签2 draft: true --- Debug hugo server -D\t//启动服务 -D 生成草稿 Publish hugo -D\t//生成草稿 git commit //git提交github.io Hugo Help PS W:\\www\\nicko-ch.github.io\u0026gt; hugo help hugo is the main command, used to build your Hugo site. Hugo is a Fast and Flexible Static Site Generator built with love by spf13 and friends in Go. Complete documentation is available at http://gohugo.io/. Usage: hugo [flags] hugo [command] Available Commands: completion generate the autocompletion script for the specified shell config Print the site configuration convert Convert your content to different formats deploy Deploy your site to a Cloud provider. env Print Hugo version and environment info gen A collection of several useful generators. help Help about any command import Import your site from others. list Listing out various types of content mod Various Hugo Modules helpers. new Create new content for your site server A high performance webserver version Print the version number of Hugo Flags: -b, --baseURL string hostname (and path) to the root, e.g. http://spf13.com/ -D, --buildDrafts include content marked as draft -E, --buildExpired include expired content -F, --buildFuture include content with publishdate in the future --cacheDir string filesystem path to cache directory. Defaults: $TMPDIR/hugo_cache/ --cleanDestinationDir remove files from destination not found in static directories --config string config file (default is path/config.yaml|json|toml) --configDir string config dir (default \u0026#34;config\u0026#34;) -c, --contentDir string filesystem path to content directory --debug debug output -d, --destination string filesystem path to write files to --disableKinds strings disable different kind of pages (home, RSS etc.) --enableGitInfo add Git revision, date and author info to the pages -e, --environment string build environment --forceSyncStatic copy all files when static is changed. --gc enable to run some cleanup tasks (remove unused cache files) after the build -h, --help help for hugo --i18n-warnings print missing translations --ignoreCache ignores the cache directory --ignoreVendor ignores any _vendor directory --ignoreVendorPaths string ignores any _vendor for module paths matching the given Glob pattern -l, --layoutDir string filesystem path to layout directory --log enable Logging --logFile string log File path (if set, logging enabled automatically) --minify minify any supported output format (HTML, XML etc.) --noChmod don\u0026#39;t sync permission mode of files --noTimes don\u0026#39;t sync modification time of files --path-warnings print warnings on duplicate target paths etc. --poll string set this to a poll interval, e.g --poll 700ms, to use a poll based approach to watch for file system changes --print-mem print memory usage to screen at intervals --quiet build in quiet mode --renderToMemory render to memory (only useful for benchmark testing) -s, --source string filesystem path to read files relative from --templateMetrics display metrics about template executions --templateMetricsHints calculate some improvement hints when combined with --templateMetrics -t, --theme strings themes to use (located in /themes/THEMENAME/) --themesDir string filesystem path to themes directory --trace file write trace to file (not useful in general) -v, --verbose verbose output --verboseLog verbose logging -w, --watch watch filesystem for changes and recreate as needed Additional help topics: hugo check Contains some verification checks Use \u0026#34;hugo [command] --help\u0026#34; for more information about a command. ","permalink":"https://nicko-ch.github.io/posts/hugo-readme/","summary":"Prerequisites 1. install hugo //下载hugo编译文件 2. install git Add Content 新增文章\nhugo new posts/my-first-post.md 修改文章属性\n--- title: \u0026#34;My First Post\u0026#34; categoried: 分类 date: 2022-11-20T09:03:20-08:00 tags: - 标签1 - 标签2 draft: true --- Debug hugo server -D\t//启动服务 -D 生成草稿 Publish hugo -D\t//生成草稿 git commit //git提交github.io Hugo Help PS W:\\www\\nicko-ch.github.io\u0026gt; hugo help hugo is the main command, used to build your Hugo site. Hugo is a Fast and Flexible Static Site Generator built with love by spf13 and friends in Go.","title":"Hugo Readme"}]