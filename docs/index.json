[{"content":"描述 快速排序是对插入算法的一种优化，利用对问题的二分化，实现递归完成快速排序 ，在所有算法中二分化是最常用的方式，将问题尽量的分成两种情况加以分析， 最终以形成类似树的方式加以利用，因为在比较模型中的算法中，最快的排序时间复杂度为 O(log~n~).\n原理  选取边界值：temp 遍历比较数组中每个值与边界值大小关系：小于边界值放小于数组，大于边界值放大于数组 递归排序大、小数组 合并返回当前已排完序数组  PS：注意递归结束条件，数组中长度小于2，代表\npackage main import \u0026#34;fmt\u0026#34; func main() { sortSlice := quickSort([]int{1, 9, 10, 30, 2, 5, 45, 8, 63, 234, 12}) fmt.Println(sortSlice) } func quickSort(arr []int) []int { if len(arr) \u0026lt;= 2 { return arr } temp := arr[0] var low, high = make([]int, 0), make([]int, 0) for i := 1; i \u0026lt; len(arr); i++ { if arr[i] \u0026lt; temp { low = append(low, arr[i]) } else { high = append(high, arr[i]) } } lowSlice := quickSort(low) highSlice := quickSort(high) return append(append(lowSlice, temp), highSlice...) } ","permalink":"https://nicko-ch.github.io/posts/2022/20220418-%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/","summary":"描述 快速排序是对插入算法的一种优化，利用对问题的二分化，实现递归完成快速排序 ，在所有算法中二分化是最常用的方式，将问题尽量的分成两种情况加以分析， 最终以形成类似树的方式加以利用，因为在比较模型中的算法中，最快的排序时间复杂度为 O(log~n~).\n原理  选取边界值：temp 遍历比较数组中每个值与边界值大小关系：小于边界值放小于数组，大于边界值放大于数组 递归排序大、小数组 合并返回当前已排完序数组  PS：注意递归结束条件，数组中长度小于2，代表\npackage main import \u0026#34;fmt\u0026#34; func main() { sortSlice := quickSort([]int{1, 9, 10, 30, 2, 5, 45, 8, 63, 234, 12}) fmt.Println(sortSlice) } func quickSort(arr []int) []int { if len(arr) \u0026lt;= 2 { return arr } temp := arr[0] var low, high = make([]int, 0), make([]int, 0) for i := 1; i \u0026lt; len(arr); i++ { if arr[i] \u0026lt; temp { low = append(low, arr[i]) } else { high = append(high, arr[i]) } } lowSlice := quickSort(low) highSlice := quickSort(high) return append(append(lowSlice, temp), highSlice.","title":"算法系列 - 快速排序"},{"content":"1. 控制器类型 1.1 有状态服务 Statefulset  稳定持久化 稳定网络标志(地址) 有序部署 有序收缩(删除)  1.2 无状态服务 RC（ReplicationController） 副本数量与期望值之间的管理\nRS（ReplicaSet） 功能类似于RC，但是多了集合式的标签选择器\nDeployment 支持滚动更新以及回滚\nDaemonSet 单例模式\n确保Node上有且只运行一个同类型pod\nJob 负责批处理任务，即仅执行一次的任务，它可以保证批处理任务一个或者多个Pod成功结束\nCron Job 周期性执行任务\n2. 网络通讯方式 2.1 同 Pod 间不同容器间 IO\n2.2 不同 Pod 间的通讯 同物理机 Docker0 网桥实现报文转发\n不同物理机 flannel UDP 数据包二次封装\n","permalink":"https://nicko-ch.github.io/posts/2022/20220323-kubernetes%E5%9F%BA%E7%A1%80/","summary":"1. 控制器类型 1.1 有状态服务 Statefulset  稳定持久化 稳定网络标志(地址) 有序部署 有序收缩(删除)  1.2 无状态服务 RC（ReplicationController） 副本数量与期望值之间的管理\nRS（ReplicaSet） 功能类似于RC，但是多了集合式的标签选择器\nDeployment 支持滚动更新以及回滚\nDaemonSet 单例模式\n确保Node上有且只运行一个同类型pod\nJob 负责批处理任务，即仅执行一次的任务，它可以保证批处理任务一个或者多个Pod成功结束\nCron Job 周期性执行任务\n2. 网络通讯方式 2.1 同 Pod 间不同容器间 IO\n2.2 不同 Pod 间的通讯 同物理机 Docker0 网桥实现报文转发\n不同物理机 flannel UDP 数据包二次封装","title":"Kubernetes基础"},{"content":"Hugo is the world’s fastest framework for building websites. It is written in Go.\nIt makes use of a variety of open source projects including:\n https://github.com/russross/blackfriday https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper  Learn more and contribute on GitHub.\n","permalink":"https://nicko-ch.github.io/about/","summary":"Hugo is the world’s fastest framework for building websites. It is written in Go.\nIt makes use of a variety of open source projects including:\n https://github.com/russross/blackfriday https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper  Learn more and contribute on GitHub.","title":"About"},{"content":"物理层 将计算机通过物理的方式连接起来，通过0/1的形式传输数据\n数据链路层 将电信号0和1以帧形势整合成一个个的数据包，将数据以包的形式进行解析。并且将数据包发送到子网络中的所有机器，让机器识别数据包头中的MAC地址跟自己是否匹配，从而捕获分析数据，此过程称为广播。\n网络层 在外网中，通过MAC地址去广播通信效率非常低，所以网络层主要是通过IP协议与其他的子网络进行通信。数据包通过外网ip发送到置顶的子网，子网设备内部再通过广播获取数据包。\n传输层 机器接受到数据包后，通过网卡内的端口传输到各各应用进程中。典型代表：udp、tcp协议\n应用层 应用进程通过Email、HTTP、FTP等通用协议进行收发数据包实现通信。\n","permalink":"https://nicko-ch.github.io/posts/2021/20210822-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%80%83%E7%A0%94408-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","summary":"物理层 将计算机通过物理的方式连接起来，通过0/1的形式传输数据\n数据链路层 将电信号0和1以帧形势整合成一个个的数据包，将数据以包的形式进行解析。并且将数据包发送到子网络中的所有机器，让机器识别数据包头中的MAC地址跟自己是否匹配，从而捕获分析数据，此过程称为广播。\n网络层 在外网中，通过MAC地址去广播通信效率非常低，所以网络层主要是通过IP协议与其他的子网络进行通信。数据包通过外网ip发送到置顶的子网，子网设备内部再通过广播获取数据包。\n传输层 机器接受到数据包后，通过网卡内的端口传输到各各应用进程中。典型代表：udp、tcp协议\n应用层 应用进程通过Email、HTTP、FTP等通用协议进行收发数据包实现通信。","title":"计算机考研408 - 计算机网络"},{"content":"进位计数制 r进制 → 十进制 二进制 ↔ 八/十六进制 十进制 → r进制 整数位(除基取余法) 小数位(乘积取整法) ","permalink":"https://nicko-ch.github.io/posts/2021/20210816-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%80%83%E7%A0%94408-%E8%BF%9B%E4%BD%8D%E8%AE%A1%E6%95%B0%E5%88%B6/","summary":"进位计数制 r进制 → 十进制 二进制 ↔ 八/十六进制 十进制 → r进制 整数位(除基取余法) 小数位(乘积取整法) ","title":"计算机考研408 - 进位计数制"},{"content":"方法一：git reset\n原理： git reset的作用是修改HEAD的位置，即将HEAD指向的位置改变为之前存在的某个版本，如下图所示，假设我们要回退到版本一：\n适用场景： 如果想恢复到之前某个提交的版本，且那个版本之后提交的版本我们都不要了，就可以用这种方法。\n具体操作：\n1. 查看版本号：\n可以使用命令“git log”查看：\n也可以在github网站上查看：\n","permalink":"https://nicko-ch.github.io/posts/2021/20210604-git%E6%81%A2%E5%A4%8D%E4%B9%8B%E5%89%8D%E7%89%88%E6%9C%AC%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95resetrevert/","summary":"方法一：git reset\n原理： git reset的作用是修改HEAD的位置，即将HEAD指向的位置改变为之前存在的某个版本，如下图所示，假设我们要回退到版本一：\n适用场景： 如果想恢复到之前某个提交的版本，且那个版本之后提交的版本我们都不要了，就可以用这种方法。\n具体操作：\n1. 查看版本号：\n可以使用命令“git log”查看：\n也可以在github网站上查看：","title":"Git恢复之前版本的两种方法reset、revert"},{"content":"核心原理 Namespace  独立进程，实现容器的 隔离性\n Linux Namespaces机制提供一种资源隔离方案。PID,IPC,Network等系统资源不再是全局性的，而是属于某个特定的Namespace。每个namespace下的资源对于其他namespace下的资源都是透明，不可见的。系统中可以同时存在两个进程号为0,1,2的进程，由于属于不同的namespace，所以它们之间并不冲突。而在用户层面上只能看到属于用户自己namespace下的资源，例如使用ps命令只能列出自己namespace下的进程。\nCgroups  控制进程资源分配，实现容器的 限制性\n Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。\n基于namespace实现的隔离性，只限于容器中的可视范围控制。实际上对于宿主机而言，容器中的进程也是宿主进程中的其中一个，所以理论上，容器进程和宿主进程占用的资源权限是一致的。为了防止某个容器抢占大量的资源导致其他容器乃至宿主机的奔溃，所以docker使用的linux中的cgroups进行进程资源的限制。\nps：限制某进程使用的CPU核数等\nRootfs  修改容器进程对于文件系统挂载点的可视范围，实现容器的 一致性\n 在 Linux 操作系统里，有一个名为 chroot 的命令可以帮助你在 shell 中方便地完成这个工作。顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置。\n实际上，Mount Namespace 正是基于对 chroot 的不断改良才被发明出来的，它也是 Linux 操作系统里的第一个 Namespace。它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。\n而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。\nrootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。\n由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。\n镜像 为了防止容器碎片化，提高容器的复用率。Docker支持用Dockerfile的形式，对于现有容器镜像进行二次开发和定制化。\nUnion File System Union File System 也叫 UnionFS，最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。比如，我现在有两个目录 A 和 B，它们分别有两个文件：\n$ tree\r.\r├── A\r│ ├── a\r│ └── x\r└── B\r├── b\r└── x\r然后，我使用联合挂载的方式，将这两个目录挂载到一个公共的目录 C 上：\n$ mkdir C\r$ mount -t aufs -o dirs=./A:./B none ./C\r这时，我再查看目录 C 的内容，就能看到目录 A 和 B 下的文件被合并到了一起：\n$ tree ./C\r./C\r├── a\r├── b\r└── x\rLayer Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。\n1. 只读层 它是这个容器的 rootfs 最下面的五层，对应的正是 ubuntu:latest 镜像的五层。可以看到，它们的挂载方式都是只读的（ro+wh，即 readonly+whiteout）。\n这时，我们可以分别查看一下这些层的内容：\n$ ls /var/lib/docker/aufs/diff/72b0744e06247c7d0...\retc sbin usr var\r$ ls /var/lib/docker/aufs/diff/32e8e20064858c0f2...\rrun\r$ ls /var/lib/docker/aufs/diff/a524a729adadedb900...\rbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var\r可以看到，这些层，都以增量的方式分别包含了 Ubuntu 操作系统的一部分。\n2. 可读写层 最上层的可读写层，挂载方式为：rw，即read write，Dockfile的操作将会让内容以文件的形式增量出现在这层。\n所以，最上面这个可读写层的作用，就是专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里。而当我们使用完了这个被修改过的容器之后，还可以使用 docker commit 和 push 指令，保存这个被修改过的可读写层，并上传到 Docker Hub 上，供其他人使用；而与此同时，原先的只读层里的内容则不会有任何变化。这，就是增量 rootfs 的好处。\n3. Init层 它是一个以“-init”结尾的层，夹在只读层和读写层之间。Init 层是 Docker 项目单独生成的一个内部层，专门用来存放 /etc/hosts、/etc/resolv.conf 等信息。\n需要这样一层的原因是，这些文件本来属于只读的 Ubuntu 镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如 hostname，所以就需要在可读写层对它们进行修改。\n可是，这些修改往往只对当前的容器有效，我们并不希望执行 docker commit 时，把这些信息连同可读写层一起提交掉。\n所以，Docker 做法是，在修改了这些文件之后，以一个单独的层挂载了出来。而用户执行 docker commit 只会提交可读写层，所以是不包含这些内容的。\n机制 Docker Exec $ docker exec -it 4ddf4638572d /bin/sh exec命令底层是调用了linux的setns()系统调用，作用是修改某进程内的namespace文件，将新的进程加入到指定的namespace中去。这样就实现了，讲宿主机的进程内嵌到指定的容器，并且访问视图namespace还是跟容器的一致。\nVolume  Volume 机制，允许你将宿主机上指定的目录或者文件，挂载到容器里面进行读取和修改操作。\n Linux 的绑定挂载（bind mount）机制。它的主要作用就是，允许你将一个目录或者文件，而不是整个设备，挂载到一个指定的目录上。并且，这时你在该挂载点上进行的任何操作，只是发生在被挂载的目录或者文件上，而原挂载点的内容则会被隐藏起来且不受影响。\n","permalink":"https://nicko-ch.github.io/posts/2021/20210602-docker%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/","summary":"核心原理 Namespace  独立进程，实现容器的 隔离性\n Linux Namespaces机制提供一种资源隔离方案。PID,IPC,Network等系统资源不再是全局性的，而是属于某个特定的Namespace。每个namespace下的资源对于其他namespace下的资源都是透明，不可见的。系统中可以同时存在两个进程号为0,1,2的进程，由于属于不同的namespace，所以它们之间并不冲突。而在用户层面上只能看到属于用户自己namespace下的资源，例如使用ps命令只能列出自己namespace下的进程。\nCgroups  控制进程资源分配，实现容器的 限制性\n Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。\n基于namespace实现的隔离性，只限于容器中的可视范围控制。实际上对于宿主机而言，容器中的进程也是宿主进程中的其中一个，所以理论上，容器进程和宿主进程占用的资源权限是一致的。为了防止某个容器抢占大量的资源导致其他容器乃至宿主机的奔溃，所以docker使用的linux中的cgroups进行进程资源的限制。\nps：限制某进程使用的CPU核数等\nRootfs  修改容器进程对于文件系统挂载点的可视范围，实现容器的 一致性\n 在 Linux 操作系统里，有一个名为 chroot 的命令可以帮助你在 shell 中方便地完成这个工作。顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置。\n实际上，Mount Namespace 正是基于对 chroot 的不断改良才被发明出来的，它也是 Linux 操作系统里的第一个 Namespace。它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。\n而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。\nrootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。\n由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。\n镜像 为了防止容器碎片化，提高容器的复用率。Docker支持用Dockerfile的形式，对于现有容器镜像进行二次开发和定制化。\nUnion File System Union File System 也叫 UnionFS，最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。比如，我现在有两个目录 A 和 B，它们分别有两个文件：\n$ tree\r.\r├── A\r│ ├── a\r│ └── x\r└── B\r├── b\r└── x\r然后，我使用联合挂载的方式，将这两个目录挂载到一个公共的目录 C 上：","title":"Docker核心原理"},{"content":"概述 基本名词 Producer (消息生产者)：\n向 kafka broker 发消息的客户端；\nConsumer (消息消费者)：\n向 kafka broker 取消息的客户端；\nConsumer Group (消费者组)：\n由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。\nBroker (服务器)：\n一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个broker可以容纳多个 topic。\nReplica (副本)：\n为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。\nLeader (主)：\n每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对 象都是 leader。\nFollower (从)：\n每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 leader 。\nTopic (主题)：\n主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。\nPartition (分区)：\n为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列；\nRebalance (重平衡)：\n消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。\n核心原理 分区 分区的作用就是提供负载均衡的能力，或者说对数据进行分区的主要原因，就是为了实现系统的高伸缩性（Scalability）\n分区策略：\n1、轮询策略：轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。\n2、随机策略：所谓随机就是我们随意地将消息放置到任意一个分区上。\n3、按key指定策略：将计算得出相同的key值，分配到相同的分区上。这种策略常用于某些需要顺序消费的业务应用场景。\n零拷贝 传统的io操作：\n1、第一次：将磁盘文件，读取到操作系统内核缓冲区；\n2、第二次：将内核缓冲区的数据，copy到application应用程序的buffer；\n3、第三步：将application应用程序buffer中的数据，copy到socket网络发送缓冲区(属于操作系统内核的缓冲区)；\n4、第四次：将socket buffer的数据，copy到网卡，由网卡进行网络传输。\n总结：假设内容中途不需要任何修改，内核态与用户态第二和第三步的操作则是没有意义的，为了减少io的消耗，人们提出了零拷贝的思想。\n零拷贝方式：\n原理上都是为了减少io操作的次数\n1、mmap（Memory Mapped Files）\n此方式适用于Producer到Broker的入列过程，这样即使Broker需要对消息进行修改，也可以减少io操作，直接讲内容修改映射到磁盘对应的空间，避免了用户态的过程io拷贝。\nPS：mmap也有一个很明显的缺陷——不可靠，写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。Kafka提供了一个参数——producer.type来控制是不是主动flush；如果Kafka写入到mmap之后就立即flush然后再返回Producer叫同步(sync)；写入mmap之后立即返回Producer不调用flush叫异步(async)。\n2、sendfile\n此方式适用于Broker到Consumer的出列过程，消费端获取消息的时候，不需要经过用户态的修改，可以内核态硬件之间直接进行io交互。\n","permalink":"https://nicko-ch.github.io/posts/2021/20210412-kafa%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/","summary":"概述 基本名词 Producer (消息生产者)：\n向 kafka broker 发消息的客户端；\nConsumer (消息消费者)：\n向 kafka broker 取消息的客户端；\nConsumer Group (消费者组)：\n由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。\nBroker (服务器)：\n一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个broker可以容纳多个 topic。\nReplica (副本)：\n为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。\nLeader (主)：\n每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对 象都是 leader。\nFollower (从)：\n每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 leader 。\nTopic (主题)：\n主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。\nPartition (分区)：\n为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列；","title":"Kafa核心技术与实战"},{"content":"1. 为什么要用分布式ID 1.1 什么是分布式ID 拿MySQL数据库举个栗子：\n在我们业务数据量不大的时候，单库单表完全可以支撑现有业务，数据再大一点搞个MySQL主从同步读写分离也能对付。\n但随着数据日渐增长，主从同步也扛不住了，就需要对数据库进行分库分表，但分库分表后需要有一个唯一ID来标识一条数据，数据库的自增ID显然不能满足需求；特别一点的如订单、优惠券也都需要有唯一ID做标识。此时一个能够生成全局唯一ID的系统是非常必要的。那么这个全局唯一ID就叫分布式ID。\n1.2 那么分布式ID需要满足那些条件？  全局唯一：必须保证ID是全局性唯一的，基本要求 高性能：高可用低延时，ID生成响应要块，否则反倒会成为业务瓶颈 高可用：100%的可用性是骗人的，但是也要无限接近于100%的可用性 好接入：要秉着拿来即用的设计原则，在系统设计和实现上要尽可能的简单 趋势递增：最好趋势递增，这个要求就得看具体业务场景了，一般不严格要求  2. 分布式ID都有哪些生成方式 2.1 UUID 优点：\n 生成足够简单，本地生成无网络消耗，具有唯一性  缺点：\n 无序的字符串，不具备自增特性 没有具体的业务含义 长度较大，不适合作为数据库主键，严重影响查询性能  2.2 数据库自增ID 优点：\n 实现简单，ID主键，数值类型，带自增特性  缺点：\n DB单机生成，存在并发宕机风险，无法扛住高并发场景  2.3 数据库集群模式 为了应对单机数据库的并发压力，设计上可以用双主模式集群的方式解决，但是这样也会引入一个新的问题，两个Mysql实例都是自增ID从1开始，会产生重复的ID怎么办？\n解决方案：设置起始值和自增步长\nMySQL_1 配置：\nset @@auto_increment_offset = 1; -- 起始值\rset @@auto_increment_increment = 2; -- 步长\rMySQL_2 配置：\nset @@auto_increment_offset = 2; -- 起始值\rset @@auto_increment_increment = 2; -- 步长\r这样两个MySQL实例的自增ID分别就是：\n 1、3、5、7、9 2、4、6、8、10\n 如果日后并发上升，就要对Mysql节点进行扩容，这是一个比较麻烦的事情。并且这样会涉及到新增的Mysql实例起始值和步长修改问题，必要时可能还需要停机修改\n优点：\n 解决单点DB性能问题  缺点：\n 不利于后续扩展，而且实际上单个数据库自身压力还是大，依旧无法满足高并发场景。  2.4 数据库号段模式 号段模式是当下分布式ID生成器的主流实现方式之一，号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，例如 (1,1000] 代表1000个ID，具体的业务服务将本号段，生成1~1000的自增ID并加载到内存。表结构如下：\nCREATE TABLE id_generator (\rid int(10) NOT NULL,\rmax_id bigint(20) NOT NULL COMMENT '当前最大id',\rstep int(20) NOT NULL COMMENT '号段的布长',\rbiz_type int(20) NOT NULL COMMENT '业务类型',\rversion int(20) NOT NULL COMMENT '版本号',\rPRIMARY KEY (`id`)\r)\rbiz_type ：代表不同业务类型\nmax_id ：当前最大的可用id\nstep ：代表号段的长度\nversion ：是一个乐观锁，每次都更新version，保证并发时数据的正确性\n等这批号段ID用完，再次向数据库申请新号段，对max_id字段做一次update操作，update max_id= max_id + step，update成功则说明新号段获取成功，新的号段范围是(max_id ,max_id +step]。\nupdate id_generator set max_id = #{max_id+step}, version = version + 1 where version = # {version} and biz_type = XXX\r由于多业务端可能同时操作，所以采用版本号version乐观锁方式更新，这种分布式ID生成方式不强依赖于数据库，不会频繁的访问数据库，对数据库的压力小很多。\n2.5 Redis模式 Redis也同样可以实现，原理就是利用redis的 incr命令实现ID的原子性自增。\n127.0.0.1:6379\u0026gt; set seq_id 1 // 初始化自增ID为1\rOK\r127.0.0.1:6379\u0026gt; incr seq_id // 增加1，并返回递增后的数值\r(integer) 2\r用redis实现需要注意一点，要考虑到redis持久化的问题。redis有两种持久化方式RDB和AOF\n RDB会定时打一个快照进行持久化，假如连续自增但redis没及时持久化，而这会Redis挂掉了，重启Redis后会出现ID重复的情况。 AOF会对每条写命令进行持久化，即使Redis挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致Redis重启恢复的数据时间过长。  2.6 雪花算法（Snowflake） Snowflake生成的是Long类型的ID，一个Long类型占8个字节，每个字节占8比特，也就是说一个Long类型占64个比特。\nSnowflake ID组成结构：正数位（占1比特）+ 时间戳（占41比特）+ 机器ID（占5比特）+ 数据中心（占5比特）+ 自增值（占12比特），总共64比特组成的一个Long类型。\n 第一个bit位（1bit）：Java中long的最高位是符号位代表正负，正数是0，负数是1，一般生成ID都为正数，所以默认为0。 时间戳部分（41bit）：毫秒级的时间，不建议存当前时间戳，而是用（当前时间戳 - 固定开始时间戳）的差值，可以使产生的ID从更小的值开始；41位的时间戳可以使用69年，(1L \u0026laquo; 41) / (1000L * 60 * 60 * 24 * 365) = 69年 工作机器id（10bit）：也被叫做workId，这个可以灵活配置，机房或者机器号组合都可以。 序列号部分（12bit），自增值支持同一毫秒内同一个节点可以生成4096个ID  根据这个算法的逻辑，只需要将这个算法用Java语言实现出来，封装为一个工具方法，那么各个业务应用可以直接使用该工具方法来获取分布式ID，只需保证每个业务应用有自己的工作机器id即可，而不需要单独去搭建一个获取分布式ID的应用。\n2.7 百度（uid-generator） uid-generator是由百度技术部开发，项目GitHub地址 https://github.com/baidu/uid-generator\nuid-generator是基于Snowflake算法实现的，与原始的snowflake算法不同在于，uid-generator支持自定义时间戳、工作机器ID和 序列号 等各部分的位数，而且uid-generator中采用用户自定义workId的生成策略。\nuid-generator需要与数据库配合使用，需要新增一个WORKER_NODE表。当应用启动时会向数据库表中去插入一条数据，插入成功后返回的自增ID就是该机器的workId数据由host，port组成。\n对于uid-generator ID组成结构：\nworkId，占用了22个bit位，时间占用了28个bit位，序列化占用了13个bit位，需要注意的是，和原始的snowflake不太一样，时间的单位是秒，而不是毫秒，workId也不一样，而且同一应用每次重启就会消费一个workId。\n2.8 美团（Leaf） Leaf由美团开发，github地址：https://github.com/Meituan-Dianping/Leaf\nLeaf同时支持号段模式和snowflake算法模式，可以切换使用。\n号段模式 先导入源码 https://github.com/Meituan-Dianping/Leaf ，在建一张表leaf_alloc\nDROP TABLE IF EXISTS `leaf_alloc`;\rCREATE TABLE `leaf_alloc` (\r`biz_tag` varchar(128) NOT NULL DEFAULT '' COMMENT '业务key',\r`max_id` bigint(20) NOT NULL DEFAULT '1' COMMENT '当前已经分配了的最大id',\r`step` int(11) NOT NULL COMMENT '初始步长，也是动态调整的最小步长',\r`description` varchar(256) DEFAULT NULL COMMENT '业务key的描述',\r`update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '数据库维护的更新时间',\rPRIMARY KEY (`biz_tag`)\r) ENGINE=InnoDB;\r然后在项目中开启号段模式，配置对应的数据库信息，并关闭snowflake模式\nleaf.name=com.sankuai.leaf.opensource.test\rleaf.segment.enable=true\rleaf.jdbc.url=jdbc:mysql://localhost:3306/leaf_test?useUnicode=true\u0026amp;characterEncoding=utf8\u0026amp;characterSetResults=utf8\rleaf.jdbc.username=root\rleaf.jdbc.password=root\rleaf.snowflake.enable=false\r#leaf.snowflake.zk.address=\r#leaf.snowflake.port=\r启动leaf-server 模块的 LeafServerApplication项目就跑起来了\n号段模式获取分布式自增ID的测试url ：http：//localhost：8080/api/segment/get/leaf-segment-test\n监控号段模式：http://localhost:8080/cache\nsnowflake模式 Leaf的snowflake模式依赖于ZooKeeper，不同于原始snowflake算法也主要是在workId的生成上，Leaf中workId是基于ZooKeeper的顺序Id来生成的，每个应用在使用Leaf-snowflake时，启动时都会都在Zookeeper中生成一个顺序Id，相当于一台机器对应一个顺序节点，也就是一个workId。\nleaf.snowflake.enable=true\rleaf.snowflake.zk.address=127.0.0.1\rleaf.snowflake.port=2181\rsnowflake模式获取分布式自增ID的测试url：http://localhost:8080/api/snowflake/get/test\n2.9 滴滴（Tinyid） Tinyid由滴滴开发，Github地址：https://github.com/didi/tinyid。\nTinyid是基于号段模式原理实现的与Leaf如出一辙，每个服务获取一个号段（1000,2000]、（2000,3000]、（3000,4000]\nhttps://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aN77sK4V1x5e5dSVZcibkzSRRKsAGqcpaauibVfY9iaOR5LFvzDPictNjHXmmdhr31153iaiaStvXIJEo2g/640?wx_fmt=png\u0026amp;tp=webp\u0026amp;wxfrom=5\u0026amp;wx_lazy=1\u0026amp;wx_co=1\nTinyid提供http和tinyid-client两种方式接入\nHttp方式接入 （1）导入Tinyid源码：\ngit clone https://github.com/didi/tinyid.git\n（2）创建数据表：\nCREATE TABLE `tiny_id_info` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;自增主键\u0026#39;, `biz_type` varchar(63) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;业务类型，唯一\u0026#39;, `begin_id` bigint(20) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;开始id，仅记录初始值，无其他含义。初始化时begin_id和max_id应相同\u0026#39;, `max_id` bigint(20) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;当前最大id\u0026#39;, `step` int(11) DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;步长\u0026#39;, `delta` int(11) NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;每次id增量\u0026#39;, `remainder` int(11) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;余数\u0026#39;, `create_time` timestamp NOT NULL DEFAULT \u0026#39;2010-01-01 00:00:00\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `update_time` timestamp NOT NULL DEFAULT \u0026#39;2010-01-01 00:00:00\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, `version` bigint(20) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;版本号\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `uniq_biz_type` (`biz_type`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT \u0026#39;id信息表\u0026#39;; CREATE TABLE `tiny_id_token` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;自增id\u0026#39;, `token` varchar(255) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;token\u0026#39;, `biz_type` varchar(63) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;此token可访问的业务类型标识\u0026#39;, `remark` varchar(255) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;备注\u0026#39;, `create_time` timestamp NOT NULL DEFAULT \u0026#39;2010-01-01 00:00:00\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `update_time` timestamp NOT NULL DEFAULT \u0026#39;2010-01-01 00:00:00\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT \u0026#39;token信息表\u0026#39;; INSERT INTO `tiny_id_info` (`id`, `biz_type`, `begin_id`, `max_id`, `step`, `delta`, `remainder`, `create_time`, `update_time`, `version`) VALUES (1, \u0026#39;test\u0026#39;, 1, 1, 100000, 1, 0, \u0026#39;2018-07-21 23:52:58\u0026#39;, \u0026#39;2018-07-22 23:19:27\u0026#39;, 1); INSERT INTO `tiny_id_info` (`id`, `biz_type`, `begin_id`, `max_id`, `step`, `delta`, `remainder`, `create_time`, `update_time`, `version`) VALUES (2, \u0026#39;test_odd\u0026#39;, 1, 1, 100000, 2, 1, \u0026#39;2018-07-21 23:52:58\u0026#39;, \u0026#39;2018-07-23 00:39:24\u0026#39;, 3); INSERT INTO `tiny_id_token` (`id`, `token`, `biz_type`, `remark`, `create_time`, `update_time`) VALUES (1, \u0026#39;0f673adf80504e2eaa552f5d791b644c\u0026#39;, \u0026#39;test\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2017-12-14 16:36:46\u0026#39;, \u0026#39;2017-12-14 16:36:48\u0026#39;); INSERT INTO `tiny_id_token` (`id`, `token`, `biz_type`, `remark`, `create_time`, `update_time`) VALUES (2, \u0026#39;0f673adf80504e2eaa552f5d791b644c\u0026#39;, \u0026#39;test_odd\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2017-12-14 16:36:46\u0026#39;, \u0026#39;2017-12-14 16:36:48\u0026#39;); （3）配置数据库：\ndatasource.tinyid.names=primary\rdatasource.tinyid.primary.driver-class-name=com.mysql.jdbc.Driver\rdatasource.tinyid.primary.url=jdbc:mysql://ip:port/databaseName?autoReconnect=true\u0026amp;useUnicode=true\u0026amp;characterEncoding=UTF-8\rdatasource.tinyid.primary.username=root\rdatasource.tinyid.primary.password=123456\r（4）启动tinyid-server后测试\n获取分布式自增ID: http://localhost:9999/tinyid/id/nextIdSimple?bizType=test\u0026amp;token=0f673adf80504e2eaa552f5d791b644c'\r返回结果: 3\r批量获取分布式自增ID:\rhttp://localhost:9999/tinyid/id/nextIdSimple?bizType=test\u0026amp;token=0f673adf80504e2eaa552f5d791b644c\u0026amp;batchSize=10'\r返回结果: 4,5,6,7,8,9,10,11,12,13\rJava客户端方式接入 重复Http方式的（2）（3）操作\n引入依赖\n \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.xiaoju.uemc.tinyid\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;tinyid-client\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;${tinyid.version}\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r配置文件\ntinyid.server =localhost:9999\rtinyid.token =0f673adf80504e2eaa552f5d791b644c\rtest 、tinyid.token是在数据库表中预先插入的数据，test 是具体业务类型，tinyid.token表示可访问的业务类型\n// 获取单个分布式自增ID\rLong id = TinyId . nextId( \u0026quot; test \u0026quot; );\r// 按需批量分布式自增ID\rList\u0026lt; Long \u0026gt; ids = TinyId . nextId( \u0026quot; test \u0026quot; , 10 );\r","permalink":"https://nicko-ch.github.io/posts/2021/20210408-%E5%88%86%E5%B8%83%E5%BC%8F%E5%94%AF%E4%B8%80id/","summary":"1. 为什么要用分布式ID 1.1 什么是分布式ID 拿MySQL数据库举个栗子：\n在我们业务数据量不大的时候，单库单表完全可以支撑现有业务，数据再大一点搞个MySQL主从同步读写分离也能对付。\n但随着数据日渐增长，主从同步也扛不住了，就需要对数据库进行分库分表，但分库分表后需要有一个唯一ID来标识一条数据，数据库的自增ID显然不能满足需求；特别一点的如订单、优惠券也都需要有唯一ID做标识。此时一个能够生成全局唯一ID的系统是非常必要的。那么这个全局唯一ID就叫分布式ID。\n1.2 那么分布式ID需要满足那些条件？  全局唯一：必须保证ID是全局性唯一的，基本要求 高性能：高可用低延时，ID生成响应要块，否则反倒会成为业务瓶颈 高可用：100%的可用性是骗人的，但是也要无限接近于100%的可用性 好接入：要秉着拿来即用的设计原则，在系统设计和实现上要尽可能的简单 趋势递增：最好趋势递增，这个要求就得看具体业务场景了，一般不严格要求  2. 分布式ID都有哪些生成方式 2.1 UUID 优点：\n 生成足够简单，本地生成无网络消耗，具有唯一性  缺点：\n 无序的字符串，不具备自增特性 没有具体的业务含义 长度较大，不适合作为数据库主键，严重影响查询性能  2.2 数据库自增ID 优点：\n 实现简单，ID主键，数值类型，带自增特性  缺点：\n DB单机生成，存在并发宕机风险，无法扛住高并发场景  2.3 数据库集群模式 为了应对单机数据库的并发压力，设计上可以用双主模式集群的方式解决，但是这样也会引入一个新的问题，两个Mysql实例都是自增ID从1开始，会产生重复的ID怎么办？\n解决方案：设置起始值和自增步长\nMySQL_1 配置：\nset @@auto_increment_offset = 1; -- 起始值\rset @@auto_increment_increment = 2; -- 步长\rMySQL_2 配置：\nset @@auto_increment_offset = 2; -- 起始值\rset @@auto_increment_increment = 2; -- 步长\r这样两个MySQL实例的自增ID分别就是：","title":"分布式唯一ID"},{"content":"基础篇 01丨基础架构：一条SQL查询语句是如何执行的？ 02丨日志系统：一条SQL更新语句是如何执行的？ 03丨事务隔离：为什么你改了我还看不见？  ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）\n  读未提交（read uncommitted）是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交（read committed）是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读（repeatable read）是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化（serializable ），顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。  04丨深入浅出索引（上） 哈希表 适用于只有等值查询的场景，效率高，但无法范围查询\n有序数组 等值查询和范围查询场景中的性能就都非常优秀，但是更新数据效率低下，所有后续数据需往后移\n二叉树（BST） 各方面都非常优秀，但是极端情况下可能会发展为链表\n平衡二叉树（AVL） 二叉树的变异体，会根据情况自动左右旋转，维持子节点的平衡，但是树高无法维护\n红黑树（RBT） 相比较平衡二叉树，平衡条件宽松，只需保证左右深度差一倍，使写的操作变化减少，提高写的性能\nB树 可以拥有多节点，解决平衡二叉树存在的树层级太高，降低查询复杂度\nB+树 B树的变异体，讲数据存储在叶节点（也成为聚簇索引），叶子节点会保存前后的指针地址\n05丨深入浅出索引（下） 覆盖索引 由于非主键索引存在回表的情况，所以select时选择主键字段，可以防止回表从而提高查询效率\n最左前缀原则 实践篇 09丨普通索引和唯一索引，应该怎么选择？ 查询过程  对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。   结论：性能上微乎其微，业务看具体场景\n 理论上唯一索引的性能会比普通索引快，但是引擎是按页进行读写的，所以查询key行数据时候，去取出的data page大概率会有下一行的记录，所以只需要在内存级别再判断一次下一行的记录是否符合条件。\n即使复杂情况，key行在data page最后一行，必须读取下一页。这种情况换做整型的索引，但个data page可以存放上千个key，出现这种概率的情况也是极小的。\n更新过程 了解新概念change buffer\n 当需要更新数据时候，在不影响一致性的情况下，innoDB会将这部分操作直接写到change buffer中。这样就不需要从磁盘中读取data page了。 将change buffer写入data page的过程称为merge，访问数据也则会触发，系统也会定期执行。 读取data page会占用buffer pool，这种方式可以提高内存利用率。  实际对比\n唯一索引需要将data page读入内存，判断是否存在该值，所以无法使用change buffer\n普通索引则只需要更新记录到change buffer即可结束\n 结论：读多写少的情况建议用普通索引，强业务一致性则用唯一索引\n redo log 和 change buffer 区别  redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。  10丨MySQL为什么有时候会选错索引？ 出现场景 优化器会根据不同情况选择对应的最有索引进行查询，当表数据中抽样统计的预估行数等信息出现误差时，导致优化器选择了非最优查询方式。\n执行流程 处理方法   使用analyze table命令刷新抽样统计\n  使用force index(i1)强制依赖某索引\nselect * from t force index(a) where a between 10000 and 20000;   11丨怎么给字符串字段加索引？ 完整索引 直接创建完整索引，查询次数少，但是比较占用空间\n前缀索引 节省空间，但是匹配精度降低，会增加查询扫描次数，并且无法使用覆盖索引\n倒序存储 基于前缀索引，倒序存储数据，增加数据区分度\nhash字段 创建hash字段索引，查询性能稳定，但是有额外的存储开销，并且不支持范围查询\n12丨为什么我的MySQL会“抖”一下？ 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n 执行某sql时，可能存在redo log刷新数据到到磁盘的情况，而刷新的情况可能会比较多，导致延迟比较长\n  **场景1：**redo log写满时，需要暂停所有更新操作，把数据刷入磁盘并且往前移checkpoint **场景2：**内存满了，会淘汰某些数据页，假如为“脏页”，就要先将数据刷入磁盘 **场景3：**空闲时间，应用会自动将脏页数据刷入磁盘 **场景4：**mysql关闭的话，也会将脏页数据刷入磁盘  13丨为什么表数据删掉一半，表文件大小不变？ **原因：**表数据的删除，只是讲行标记为可复用状态，但实际上还是占用内存磁盘空间的。\n**解决：**1. 重建表 alter table A engine=InnoDB\nOnline DDL（Mysql 5.6开始引入） 优化表重建过程中，有新的更新语句执行时不会阻塞整个流程\n重建表流程：\n 建立一个临时文件，扫描表 A 主键的所有数据页； 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中； 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态； 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态； 用临时文件替换表 A 的数据文件。  14丨count这么慢，我该怎么办？  MyISAM 表虽然 count(*) 很快，但是不支持事务； show table status 命令虽然返回很快，但是不准确； InnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。  对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。\n对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\n对于 count(字段) 来说：\n 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加； 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。  但是 count(*)是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。\n 结论：按照效率排序的话，count(字段)\u0026lt;count(主键 id)\u0026lt;count(1)≈count()，所以我建议你，尽量使用 count()\n 16丨“orderby”是怎么工作的？ 全字段排序流程  初始化 sort_buffer，确定放入 name、city、age 这三个字段； 从索引 city 找到第一个满足 city=\u0026lsquo;杭州’条件的主键 id，也就是图中的 ID_X； 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中； 从索引 city 取下一个记录的主键 id； 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y； 对 sort_buffer 中的数据按照字段 name 做快速排序； 按照排序结果取前 1000 行返回给客户端。  rowid排序流程  初始化 sort_buffer，确定放入两个字段，即 name 和 id； 从索引 city 找到第一个满足 city=\u0026lsquo;杭州’条件的主键 id，也就是图中的 ID_X； 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中； 从索引 city 取下一个记录的主键 id； 重复步骤 3、4 直到不满足 city=\u0026lsquo;杭州’条件为止，也就是图中的 ID_Y； 对 sort_buffer 中的数据按照字段 name 进行排序； 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。  优化  可将常需要排序的字段做联合索引 使用覆盖索引优化回表逻辑  普通排序：\n联合索引优化：\n结果Extra字段去除了Using filesort字眼，表示排序去除了文件排序方式\nalter table t add index city_user(city, name); 覆盖索引优化：\n结果Extra字段为Using index表示使用了覆盖索引，性能会更高\n17丨如何正确地显示随机消息？ 小结\n今天这篇文章，我是借着随机排序的需求，跟你介绍了 MySQL 对临时表排序的执行过程。\n如果你直接使用 order by rand()，这个语句需要 Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要量避开这种写法。\n今天的例子里面，我们不是仅仅在数据库内部解决问题，还会让应用代码配合拼接 SQL 语句。在实际应用的过程中，比较规范的用法就是：尽量将业务逻辑写在业务代码中，让数据库只做“读写数据”的事情。因此，这类方法的应用还是比较广泛的。\n18丨为什么这些SQL语句逻辑相同，性能却差异巨大？ 小结\n今天我给你举了三个例子，其实是在说同一件事儿，即：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\n第二个例子是隐式类型转换，第三个例子是隐式字符编码转换，它们都跟第一个例子一样，因为要求在索引字段上做函数操作而导致了全索引扫描。\nMySQL 的优化器确实有“偷懒”的嫌疑，即使简单地把 where id+1=1000 改写成 where id=1000-1 就能够用上索引快速查找，也不会主动做这个语句重写。\n因此，每次你的业务代码升级时，把可能出现的、新的 SQL 语句 explain 一下，是一个很好的习惯。\n19丨为什么我只查一行的语句，也执行这么慢？ ","permalink":"https://nicko-ch.github.io/posts/2021/20210222-mysql%E5%AE%9E%E6%88%9845%E8%AE%B2/","summary":"基础篇 01丨基础架构：一条SQL查询语句是如何执行的？ 02丨日志系统：一条SQL更新语句是如何执行的？ 03丨事务隔离：为什么你改了我还看不见？  ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）\n  读未提交（read uncommitted）是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交（read committed）是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读（repeatable read）是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化（serializable ），顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。  04丨深入浅出索引（上） 哈希表 适用于只有等值查询的场景，效率高，但无法范围查询\n有序数组 等值查询和范围查询场景中的性能就都非常优秀，但是更新数据效率低下，所有后续数据需往后移\n二叉树（BST） 各方面都非常优秀，但是极端情况下可能会发展为链表\n平衡二叉树（AVL） 二叉树的变异体，会根据情况自动左右旋转，维持子节点的平衡，但是树高无法维护\n红黑树（RBT） 相比较平衡二叉树，平衡条件宽松，只需保证左右深度差一倍，使写的操作变化减少，提高写的性能\nB树 可以拥有多节点，解决平衡二叉树存在的树层级太高，降低查询复杂度\nB+树 B树的变异体，讲数据存储在叶节点（也成为聚簇索引），叶子节点会保存前后的指针地址\n05丨深入浅出索引（下） 覆盖索引 由于非主键索引存在回表的情况，所以select时选择主键字段，可以防止回表从而提高查询效率\n最左前缀原则 实践篇 09丨普通索引和唯一索引，应该怎么选择？ 查询过程  对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。   结论：性能上微乎其微，业务看具体场景\n 理论上唯一索引的性能会比普通索引快，但是引擎是按页进行读写的，所以查询key行数据时候，去取出的data page大概率会有下一行的记录，所以只需要在内存级别再判断一次下一行的记录是否符合条件。\n即使复杂情况，key行在data page最后一行，必须读取下一页。这种情况换做整型的索引，但个data page可以存放上千个key，出现这种概率的情况也是极小的。\n更新过程 了解新概念change buffer\n 当需要更新数据时候，在不影响一致性的情况下，innoDB会将这部分操作直接写到change buffer中。这样就不需要从磁盘中读取data page了。 将change buffer写入data page的过程称为merge，访问数据也则会触发，系统也会定期执行。 读取data page会占用buffer pool，这种方式可以提高内存利用率。  实际对比","title":"Mysql实战45讲 - 丁奇"},{"content":"基础用法  benchmark和普通单元测试用例一样，文件命名都为 _test.go 函数名以 Benchmark 开头，参数是 b *testing.B。 对比普通的单元测试用例： 函数名以 Test 开头，参数是 t *testing.T。  运行用例 基础用例  运行当前 package 内的用例：go test example 或 go test . 运行子 package 内的用例： go test example/\u0026lt;package name\u0026gt; 或 go test ./\u0026lt;package name\u0026gt; 如果想递归测试当前目录下的所有的 package：go test ./... 或 go test example/...。  $ go test -bench . goos: darwin goarch: amd64 pkg: example BenchmarkFib-8 200 5865240 ns/op PASS ok example 1.782s  正则匹配，例：只运行以 Fib 结尾的benchmark用例  $ go test -bench=\u0026#39;Fib$\u0026#39; . goos: darwin goarch: amd64 pkg: example BenchmarkFib-8 202 5980669 ns/op PASS ok example 1.813s  BenchmarkFib-8 中的 -8 即 GOMAXPROCS，默认等于 CPU 核数。可以通过 -cpu 参数改变 GOMAXPROCS，-cpu 支持传入一个列表作为参数，例如：  $ go test -bench=\u0026#39;Fib$\u0026#39; -cpu=2,4 . goos: darwin goarch: amd64 pkg: example BenchmarkFib-2 206 5774888 ns/op BenchmarkFib-4 205 5799426 ns/op PASS ok example 3.563s 在这个例子中，改变 CPU 的核数对结果几乎没有影响，因为这个 Fib 的调用是串行的。\n202 和 5980669 ns/op 表示用例执行了 202 次，每次花费约 0.006s。总耗时比 1s 略多。\n 对于性能测试来说，提升测试准确度的一个重要手段就是增加测试的次数。我们可以使用 -benchtime 和 -count 两个参数达到这个目的。  提升准确度 对于性能测试来说，提升测试准确度的一个重要手段就是增加测试的次数。我们可以使用 -benchtime 和 -count 两个参数达到这个目的。\nbenchmark 的默认时间是 1s，那么我们可以使用 -benchtime 指定为 5s。例如：\n$ go test -bench='Fib$' -benchtime=5s .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkFib-8 1033 5769818 ns/op\rPASS\rok example 6.554s\r 实际执行的时间是 6.5s，比 benchtime 的 5s 要长，测试用例编译、执行、销毁等是需要时间的。\n 将 -benchtime 设置为 5s，用例执行次数也变成了原来的 5倍，每次函数调用时间仍为 0.6s，几乎没有变化。\n benchtime 的值除了是时间外，还可以是具体的次数。例如，执行 30 次可以用 benchtime=30x：  $ go test -bench='Fib$' -benchtime=50x .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkFib-8 50 6121066 ns/op\rPASS\rok example 0.319s\r调用 50 次 fib(30)，仅花费了 0.319s。\n count 参数可以用来设置 benchmark 的轮数。例如，进行 3 轮 benchmark。  $ go test -bench='Fib$' -benchtime=5s -count=3 .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkFib-8 975 5946624 ns/op\rBenchmarkFib-8 1023 5820582 ns/op\rBenchmarkFib-8 961 6096816 ns/op\rPASS\rok example 19.463s\r内存分配情况  benchmem 参数可以度量内存分配的次数。内存分配次数也性能也是息息相关的，例如不合理的切片容量，将导致内存重新分配，带来不必要的开销。  在下面的例子中，generateWithCap 和 generate 的作用是一致的，生成一组长度为 n 的随机序列。唯一的不同在于，generateWithCap 创建切片时，将切片的容量(capacity)设置为 n，这样切片就会一次性申请 n 个整数所需的内存。\n// generate_test.go package main import ( \u0026#34;math/rand\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) func generateWithCap(n int) []int { rand.Seed(time.Now().UnixNano()) nums := make([]int, 0, n) for i := 0; i \u0026lt; n; i++ { nums = append(nums, rand.Int()) } return nums } func generate(n int) []int { rand.Seed(time.Now().UnixNano()) nums := make([]int, 0) for i := 0; i \u0026lt; n; i++ { nums = append(nums, rand.Int()) } return nums } func BenchmarkGenerateWithCap(b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { generateWithCap(1000000) } } func BenchmarkGenerate(b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { generate(1000000) } } 运行该用例的结果是：\ngo test -bench='Generate' .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkGenerateWithCap-8 44 24294582 ns/op\rBenchmarkGenerate-8 34 30342763 ns/op\rPASS\rok example 2.171s\r可以看到生成 100w 个数字的随机序列，GenerateWithCap 的耗时比 Generate 少 20%。\n我们可以使用 -benchmem 参数看到内存分配的情况：\ngoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkGenerateWithCap-8 43 24335658 ns/op 8003641 B/op 1 allocs/op\rBenchmarkGenerate-8 33 30403687 ns/op 45188395 B/op 40 allocs/op\rPASS\rok example 2.121s\rGenerate 分配的内存是 GenerateWithCap 的 6 倍，设置了切片容量，内存只分配一次，而不设置切片容量，内存分配了 40 次。\n测试不同的输入 不同的函数复杂度不同，O(1)，O(n)，O(n^2) 等，利用 benchmark 验证复杂度一个简单的方式，是构造不同的输入。对刚才的 benchmark 稍作改造，便能够达到目的。\n// generate_test.go package main import ( \u0026#34;math/rand\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) func generate(n int) []int { rand.Seed(time.Now().UnixNano()) nums := make([]int, 0) for i := 0; i \u0026lt; n; i++ { nums = append(nums, rand.Int()) } return nums } func benchmarkGenerate(i int, b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { generate(i) } } func BenchmarkGenerate1000(b *testing.B) { benchmarkGenerate(1000, b) } func BenchmarkGenerate10000(b *testing.B) { benchmarkGenerate(10000, b) } func BenchmarkGenerate100000(b *testing.B) { benchmarkGenerate(100000, b) } func BenchmarkGenerate1000000(b *testing.B) { benchmarkGenerate(1000000, b) } 这里，我们实现一个辅助函数 benchmarkGenerate 允许传入参数 i，并构造了 4 个不同输入的 benchmark 用例。运行结果如下：\n$ go test -bench . goos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkGenerate1000-8 34048 34643 ns/op\rBenchmarkGenerate10000-8 4070 295642 ns/op\rBenchmarkGenerate100000-8 403 3230415 ns/op\rBenchmarkGenerate1000000-8 39 32083701 ns/op\rPASS\rok example 6.597s\r通过测试结果可以发现，输入变为原来的 10 倍，函数每次调用的时长也差不多是原来的 10 倍，这说明复杂度是线性的。\nResetTimer 如果在 benchmark 开始前，需要一些准备工作，如果准备工作比较耗时，则需要将这部分代码的耗时忽略掉。比如下面的例子：\nfunc BenchmarkFib(b *testing.B) { time.Sleep(time.Second * 3) // 模拟耗时准备任务 \tfor n := 0; n \u0026lt; b.N; n++ { fib(30) // run fib(30) b.N times \t} } 运行结果是：\n$ go test -bench='Fib$' -benchtime=50x .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkFib-8 50 65912552 ns/op\rPASS\rok example 6.319s\r50次调用，每次调用约 0.66s，是之前的 0.06s 的 11 倍。究其原因，受到了耗时准备任务的干扰。我们需要用 ResetTimer 屏蔽掉：\nfunc BenchmarkFib(b *testing.B) { time.Sleep(time.Second * 3) // 模拟耗时准备任务 \tb.ResetTimer() // 重置定时器 \tfor n := 0; n \u0026lt; b.N; n++ { fib(30) // run fib(30) b.N times \t} } $ go test -bench='Fib$' -benchtime=50x .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkFib-8 50 6187485 ns/op\rPASS\rok example 6.330s\rStopTimer \u0026amp; StartTimer 还有一种情况，每次函数调用前后需要一些准备工作和清理工作，我们可以使用 StopTimer 暂停计时以及使用 StartTimer 开始计时。\n例如，如果测试一个冒泡函数的性能，每次调用冒泡函数前，需要随机生成一个数字序列，这是非常耗时的操作，这种场景下，就需要使用 StopTimer 和 StartTimer 避免将这部分时间计算在内。\n例如：\n// sort_test.go package main import ( \u0026#34;math/rand\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) func generateWithCap(n int) []int { rand.Seed(time.Now().UnixNano()) nums := make([]int, 0, n) for i := 0; i \u0026lt; n; i++ { nums = append(nums, rand.Int()) } return nums } func bubbleSort(nums []int) { for i := 0; i \u0026lt; len(nums); i++ { for j := 1; j \u0026lt; len(nums)-i; j++ { if nums[j] \u0026lt; nums[j-1] { nums[j], nums[j-1] = nums[j-1], nums[j] } } } } func BenchmarkBubbleSort(b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { b.StopTimer() nums := generateWithCap(10000) b.StartTimer() bubbleSort(nums) } } 执行该用例，每次排序耗时约 0.1s。\n$ go test -bench='Sort$' .\rgoos: darwin\rgoarch: amd64\rpkg: example\rBenchmarkBubbleSort-8 9 113280509 ns/op\rPASS\rok example 1.146s\r","permalink":"https://nicko-ch.github.io/posts/2021/20210220-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-benchmark/","summary":"基础用法  benchmark和普通单元测试用例一样，文件命名都为 _test.go 函数名以 Benchmark 开头，参数是 b *testing.B。 对比普通的单元测试用例： 函数名以 Test 开头，参数是 t *testing.T。  运行用例 基础用例  运行当前 package 内的用例：go test example 或 go test . 运行子 package 内的用例： go test example/\u0026lt;package name\u0026gt; 或 go test ./\u0026lt;package name\u0026gt; 如果想递归测试当前目录下的所有的 package：go test ./... 或 go test example/...。  $ go test -bench . goos: darwin goarch: amd64 pkg: example BenchmarkFib-8 200 5865240 ns/op PASS ok example 1.782s  正则匹配，例：只运行以 Fib 结尾的benchmark用例  $ go test -bench=\u0026#39;Fib$\u0026#39; .","title":"Go高级编程 - Benchmark"},{"content":"Golang\u0026quot;调度器\u0026quot;由来 单进程时代  单一执行流程，CPU只能顺序的执行任务队列 进程阻塞导致CPU占用，浪费硬件资源，影响执行效率  多进程、多线程时代  设计变得复杂  进程/线程的数量越多，切换CPU执行时间片成本越大 多线程随着同步竞争（如 锁、竞争资源冲突等）   缺点  高内存占用 （进程：虚拟内存4G；线程：约4MB） 高CPU调度消耗    协程（co-routine）  N:1  无法利用多个CPU 出现阻塞的瓶颈   1:1  跟多线程/多进程模型无异 协程切换成本高   M:N  能够利用多核 过于依赖协程调度器的优化和算法    调度器的优化  早期Go调度器  基本的全局Go队列和比较传统的轮询利用多个thread去调度 弊端  创建、销毁、调度G都需要每个M获取锁，形成了激烈的锁竞争 M转移G会造成延迟和额外的系统负载 系统调用（CPU在M之间的切换）导致频繁的线程阻塞和取消阻塞的操作增加了系统的开销     Goroutine优化  内存占用低（几KB，大量开辟） 灵活调度，切换成本低    GMP模型的设计思想 GMP模型简介 GMP\n G：goroutine 携程 P：processor 处理器 M：thread 内核线程\n 全局队列\n 存放等待运行的G  P的本地队列\n 存放等待运行的G 数量限制（不超过256个G） 优先将创建的G存放在P的本地队列中，如果满了会放在全局队列  P列表\n 程序启动时创建 数量最多有GOMAXPROCS个（可配置）  M列表\n 当前操作系统分配到当前GO程序的内核线程数  P和M的数量\n  P\n 环境变量$GOMAXPROCS 在程序中通过runtime.GOMAXPROCS()来设置\n   M\n Go语言本身限定M最大10000（忽略） runtime/debug 包中的SetMaxThreads函数设置 有一个M阻塞，会创建新的M； 有一个M空闲，会回收或者睡眠；\n   调度器设计策略 复用线程\n 避免频繁的创建、销毁线程，而是对线程的复用   work stealing 机制\n 当本线程无可运行的G时，尝试从其他线程绑定的P队列偷取G，而不是销毁线程。偷取数量不是单个，而是别的队列后半部分\n   hand off 机制\n 当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移到其他的空闲线程执行\n     利用并行\n GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分部在多个CPU上同时运行  抢占\n 在coroutine中等待一个协程主动让出CPU才执行下一个协程，在GO中，一个goroutine最多占用CPU 10ms，防止其他goroutine饿死  全局G队列\n 假如M的本地队列P为空，则优先从全局队列获取G，如果全局队列为空，才尝试去别的队列偷取  调度优先级  runnext-\u0026gt;local runq-\u0026gt;global runq-\u0026gt;netpoller-\u0026gt;steal\n go func() 经历过程 步骤流程  我们通过 go func()来创建一个goroutine； 有两个存储G的队列，一个是局部调度器P的本地队列、一个是全局G队列。新创建的G会先保存在P的本地队列中，如果P的本地队列已经满了就会保存在全局的队列中； G只能运行在M中，一个M必须持有一个P，M与P是1：1的关系。M会从P的本地队列列弹出一个可执行状态的G来执行，如果P的本地队列列为空，就会想其他的MP组合偷取一个可执行的G来执行； 一个M调度G执行的过程是一个循环机制； 当M执行某一个G时候如果发生了syscall或则其余阻塞操作，M会阻塞，如果当前有一些G在执行，runtime会把这个线程M从P中摘除(detach)，然后再创建一个新的操作系统的线程(如果有空闲的线程可用就复用空闲线程)来服务于这个P； 当M系统调用结束时候，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程M变成休眠状态， 加入到空闲线程中，然后这个G会被放入全局队列列中。  调度器的声明周期 M0  M0是启动程序后的编号为0的主线程，这个M对应的实例会再全局变量runtime.m0中，不需要再heap上分配，M0负责执行初始化操作和启动第一个G，在之后M0就和其他的M一样了。\n G0  G0是每次启动一个M都会第一个创建的goroutine，G0仅用于负责调度的G，G0不指向任何可执行的函数，每个M都会有一个自己的G0。在调度或系统调用时会使用G0的栈空间，全局变量的G0是M0的G0。\n 可视化GMP编程 基本trace编程 // 1. 创建trace文件 f, err := os.Create(\u0026#34;trace.out\u0026#34;) // 2. 启动trace trace.Start(f) // 3. 停止trace trace.Stop() // go build运行之后，会得到一个trace.out文件 使用可视化工具 $go tool trace trace.out Debug Trace调试 // schedtrace 为间隔多久打印信息 GODEBUG=schedtrace=1000 ./trace 参数解析  SCHED 调试信息 0ms 从程序启动到输出经历的时间 gomaxprocs P的数量（一般默认是和CPU的核数一致） idleprocs 处理idle状态的P的数量，gomaxprocs-idleprocs=目前正在执行的P数量 threads 线程数量（包括M0，包括GODEBUG调试的线程） spinningthreads 处于自旋状态的thread数量 idlethread 处理idle状态的thread runqueue 全局G队列的G数量 [0, 0] 每个P的local queue本地队列中，目前存在的G数量  场景 场景1  P拥有G1，M1获取P后开始运行G1，G1使⽤用go func()创建了G2，为了了局部性G2优先加入到P1的本地队列。  场景2  G1运行完成后(函数：goexit)，M上运行的goroutine切换为G0，G0负责调度时协程的切换（函数：schedule）。 从P的本地队列取G2，从G0切换到G2，并开始运行G2(函数：execute)。实现了线程M1的复⽤用。  场景3、4、5 场景6  规定：在创建G时，运行的G会尝试唤醒其他空闲的P和M组合去执行。 假定G2唤醒了M2，M2绑定了P2，并运行G0，但P2本地队列没有G，M2此时为自旋线程（没有G但为运行状态的线程，不断寻找G）。  场景7  M2尝试从全局队列(简称“GQ”)取一批G放到P2的本地队列（函数：findrunnable()）。M2从全局队列取的G数量量符合下⾯面的公式： $n = min(len(GQ)/GOMAXPROCS + 1, len(GQ/2))$  场景8  全局队列已经没有G，那m就要执行work stealing(偷取)：从其他有G的P哪里偷取一半G过来，放到自己的P本地队列。P2从P1的本地队列尾部取一半的G，本例中一半则只有1个G8，放到P2的本地队列并执行。  场景9  最多有GOMAXPROCS个自旋的线程(当前例子中的GOMAXPROCS=4，所以一共4个P)，多余的没事做线程会让他们休眠。  场景10  假定当前除了M3和M4为自旋线程，还有M5和M6为空闲的线程(没有得到P的绑定，注意我们这里最多就只能够存在4个P，所以P的数量应该永远是M\u0026gt;=P, 大部分都是M在抢占需要运行的P)，G8创建了了G9，G8进行了阻塞的系统调用，M2和P2立即解绑，P2会执行以下判断：如果P2本地队列有G、全局队列有G或有空闲的M，P2都会立⻢马唤醒1个M和它绑定，否则P2则会加入到空闲P列表，等待M来获取可用的p。本场景中，P2本地队列有G9，可以和其他空闲的线程M5绑定。  场景11  M2和P2会解绑，但M2会记住P2，然后G8和M2进⼊入系统调⽤用状态。当G8和M2退出系统调用时，会尝试获取P2，如果无法获取，则获取空闲的P，如果依然没有，G8会被记为可运行状态，并加入到全局队列,M2因为没有P的绑定而变成休眠状态(长时间休眠等待GC回收销毁)。  ","permalink":"https://nicko-ch.github.io/posts/2021/20210207-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-gmp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/","summary":"Golang\u0026quot;调度器\u0026quot;由来 单进程时代  单一执行流程，CPU只能顺序的执行任务队列 进程阻塞导致CPU占用，浪费硬件资源，影响执行效率  多进程、多线程时代  设计变得复杂  进程/线程的数量越多，切换CPU执行时间片成本越大 多线程随着同步竞争（如 锁、竞争资源冲突等）   缺点  高内存占用 （进程：虚拟内存4G；线程：约4MB） 高CPU调度消耗    协程（co-routine）  N:1  无法利用多个CPU 出现阻塞的瓶颈   1:1  跟多线程/多进程模型无异 协程切换成本高   M:N  能够利用多核 过于依赖协程调度器的优化和算法    调度器的优化  早期Go调度器  基本的全局Go队列和比较传统的轮询利用多个thread去调度 弊端  创建、销毁、调度G都需要每个M获取锁，形成了激烈的锁竞争 M转移G会造成延迟和额外的系统负载 系统调用（CPU在M之间的切换）导致频繁的线程阻塞和取消阻塞的操作增加了系统的开销     Goroutine优化  内存占用低（几KB，大量开辟） 灵活调度，切换成本低    GMP模型的设计思想 GMP模型简介 GMP\n G：goroutine 携程 P：processor 处理器 M：thread 内核线程","title":"Go高级编程 - GMP并发模型"},{"content":"标记清除法  STW（stop the world）→ 标记对象依赖关系 → 清楚待回收对象 → 结束STW\n 步骤：\n 暂停程序业务逻辑, 找出不可达的对象，和可达对象。 开始标记，程序找出它所有可达的对象，并做上标记。 开始清除未标记对象。 停止STW，让程序恢复运行。  缺点：\n STW严重影响程序的运行效率 标记需要扫描整个heap 清除数据也会导致产生多余的heap碎片  优化：\n 将步骤3和4互换位置，缩短STW的范围  三色标记法  白色：待回收对象 灰色：待扫描对象 黑色：已扫描对象\n 目标：处理完所有灰色的对象为止\n  步骤：\n  将所有的对象标记为默认颜色“白色”\n  从根节点（Root Set）出发，遍历将被根节点引用的对象标记为\u0026quot;灰色\u0026quot;\n  遍历灰色集合，将灰色对象引用的白色对象标记为“灰色”，然后将遍历完的灰色对象标记为“黑色”\n  重复步骤3，直到灰色集合中无任何对象\n  最后回收所有白色集合对象\n  缺点（不启动STW保护）：\n有可能造成对象丢失，即过程中黑色对象引用了白色对象，同时白色对象丢失了灰色对象的关系，导致GC把黑色对象引用的白色对象被回收\n需同时满足两条件：\n 一个白色对象被黑色对象引用（白色被挂载到黑色下） 灰色对象与被挂载的白色对象关系遭到破坏（灰色同时丢失了白色的挂载）  强弱三色不变式 强三色不变式  强制性不允许黑色对象引用白色对象（破坏条件1）\n 弱三色不变式  允许黑色对象引用白色对象，但白色对象必须存在链路上游有灰色对象保持有引用关系（破坏条件2）\n 屏障机制 插入屏障 （为保证性能不在栈上使用）\n 在A对象引用B对象的时候，B对象被标记为灰色。（将B挂载在A下，B必须标记为灰色）\n 满足强三色不变式（不存在黑色对象引用白色对象的情况，因为白色强制变为灰色）\n步骤：\n 当黑色对象引用白色对象时，触发写入屏障，使白色对象置为灰色对象。（使白色对象进入灰色集合，进入下一轮遍历） 堆上的灰色集合遍历完成后，栈进行STW，  缺点：\n结束时需要STW来重新扫描栈\n删除屏障 实际也是写，将后对象置为nil，又名为删除写屏障。\n 被删除的对象，如果自身为白色或者灰色，那么都会被标记为灰色。\n 满足弱三色不变式（保护灰色对象到白色对象的路径不会断）\n步骤：\n 当对象被删除时，触发删除写屏障，使删除对象置为灰色。（使删除对象这一轮GC不被删除） 第二轮GC，上一轮不被删除的对象讲没有上游指向，即可被GC回收  缺点：\n回收精度低，在一个对象被删除后，需要在第二轮GC才能被清楚。\n混合写屏障 栈不启用屏障\n 变形的弱三色不变式（结合了插入、删除写屏障两者的优点）\n 核心：\n GC开始时将栈上的可达对象全部扫描并标记为黑色（之后不再进行二次重复扫描，无需STW） GC期间，任何在栈上创建的新对象，均为黑色。 被删除的对象标记为灰色 被添加的对象标记为灰色  总结  GO V1.3 普通的标记清除法，整体过程需要STW，效率极低 GO V1.5 三色标记法，堆空间启动屏障，栈空间不启动，堆全部扫描后，需要重新启动一次STW扫描栈，效率普通 GO V1.8 三色标记法 + 混合写屏障机制，堆空间启动，栈空间不启动，通过特殊规则实现弱三色不变式，整体过程几乎不用STW，效率极高  ","permalink":"https://nicko-ch.github.io/posts/2021/20210105-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-gc%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%8E%9F%E7%90%86/","summary":"标记清除法  STW（stop the world）→ 标记对象依赖关系 → 清楚待回收对象 → 结束STW\n 步骤：\n 暂停程序业务逻辑, 找出不可达的对象，和可达对象。 开始标记，程序找出它所有可达的对象，并做上标记。 开始清除未标记对象。 停止STW，让程序恢复运行。  缺点：\n STW严重影响程序的运行效率 标记需要扫描整个heap 清除数据也会导致产生多余的heap碎片  优化：\n 将步骤3和4互换位置，缩短STW的范围  三色标记法  白色：待回收对象 灰色：待扫描对象 黑色：已扫描对象\n 目标：处理完所有灰色的对象为止\n  步骤：\n  将所有的对象标记为默认颜色“白色”\n  从根节点（Root Set）出发，遍历将被根节点引用的对象标记为\u0026quot;灰色\u0026quot;\n  遍历灰色集合，将灰色对象引用的白色对象标记为“灰色”，然后将遍历完的灰色对象标记为“黑色”\n  重复步骤3，直到灰色集合中无任何对象\n  最后回收所有白色集合对象\n  缺点（不启动STW保护）：\n有可能造成对象丢失，即过程中黑色对象引用了白色对象，同时白色对象丢失了灰色对象的关系，导致GC把黑色对象引用的白色对象被回收\n需同时满足两条件：\n 一个白色对象被黑色对象引用（白色被挂载到黑色下） 灰色对象与被挂载的白色对象关系遭到破坏（灰色同时丢失了白色的挂载）  强弱三色不变式 强三色不变式  强制性不允许黑色对象引用白色对象（破坏条件1）\n 弱三色不变式  允许黑色对象引用白色对象，但白色对象必须存在链路上游有灰色对象保持有引用关系（破坏条件2）","title":"Go高级编程 - GC垃圾回收原理"},{"content":"new() 和 make() 的区别 看起来二者没有什么区别，都在堆上分配内存，但是它们的行为不同，适用于不同的类型。\n new(T) 为每个新的类型T分配一片内存，初始化为 0 并且返回类型为*T的内存地址：这种方法 返回一个指向类型为 T，值为 0 的地址的指针，它适用于值类型如数组和结构体；它相当于 \u0026amp;T{}。 make(T) 返回一个类型为 T 的初始值，它只适用于3种内建的引用类型：切片、map 和 channel。  换言之，new 函数分配内存，make 函数初始化；下图给出了区别：\n译者注：如何理解new、make、slice、map、channel的关系\n1.slice、map以及channel都是golang内建的一种引用类型，三者在内存中存在多个组成部分， 需要对内存组成部分初始化后才能使用，而make就是对三者进行初始化的一种操作方式\n2. new 获取的是存储指定变量内存地址的一个变量，对于变量内部结构并不会执行相应的初始化操作， 所以slice、map、channel需要make进行初始化并获取对应的内存地址，而非new简单的获取内存地址\n 编程内存模型  kernel内核区为操作系统专用 函数中局部变量是在stack中存放的 stack中的内存在函数结束后会被释放 函数中new和make声明的变量是在heap中存放的   fmt函数参数说明 基本\n%v\tthe value in a default format\rwhen printing structs, the plus flag (%+v) adds field names\r%#v\ta Go-syntax representation of the value\r%T\ta Go-syntax representation of the type of the value\r%%\ta literal percent sign; consumes no value\rThe default format for %v is:\nbool: %t\rint, int8 etc.: %d\ruint, uint8 etc.: %d, %#x if printed with %#v\rfloat32, complex64, etc: %g\rstring: %s\rchan: %p\rpointer: %p\rBoolean:\n%t\tthe word true or false\rInteger:\n%b\tbase 2\r%c\tthe character represented by the corresponding Unicode code point\r%d\tbase 10\r%o\tbase 8\r%q\ta single-quoted character literal safely escaped with Go syntax.\r%x\tbase 16, with lower-case letters for a-f\r%X\tbase 16, with upper-case letters for A-F\r%U\tUnicode format: U+1234; same as \u0026quot;U+%04X\u0026quot;\rFloating-point and complex constituents:\n%b\tdecimalless scientific notation with exponent a power of two,\rin the manner of strconv.FormatFloat with the 'b' format,\re.g. -123456p-78\r%e\tscientific notation, e.g. -1.234456e+78\r%E\tscientific notation, e.g. -1.234456E+78\r%f\tdecimal point but no exponent, e.g. 123.456\r%F\tsynonym for %f\r%g\t%e for large exponents, %f otherwise\r%G\t%E for large exponents, %F otherwise\rString and slice of bytes (treated equivalently with these verbs):\n%s\tthe uninterpreted bytes of the string or slice\r%q\ta double-quoted string safely escaped with Go syntax\r%x\tbase 16, lower-case, two characters per byte\r%X\tbase 16, upper-case, two characters per byte\rPointer:\n%p\tbase 16 notation, with leading 0x\r IO缓冲区原理 写：\n程序会将内容写入系统缓冲区，成功则默认为写入成功。系统缓冲区再又系统调度，实际落盘。\n读：\n底层会将整个扇区的内容读取到用户缓存区，减少磁盘的物理操作\n 进程与线程 就绪态(初始态)：等待CPU时间片\n运行态：占用CPU进行运算\n挂起态：假设进程需要等待数据，会主动让出CPU进入挂起态，数据接收后再重置为就绪态\n停止态：进程终止\nlinux fork进程流程\n进程回收\n正常子进程退出，会收父进程管理回收\n孤儿进程\n父进程先于子进程结束，子进程没法回收，则子进程成为孤儿进程。子进程会被init进程接管，称为init进程领养孤儿进程。\n僵尸进程\n进程终止，父进程尚未回收，且子进程残留资源（PCB）存放在内核中，编程僵尸进程。\n进程与线程的关系\n线程：LWP（light weight process）轻量级的进程，本质仍是进程（Linux下）\n进程：独立的地址空间，拥有PCB\n线程：有独立的PCB，但是没有独立的地址空间（共享）\n区别：在于是否共享地址空间。独居（进程）；合租（线程）；\n线程：最小的执行单位\n进程：最小的分配职员单位，可看成是只有一个线程的进程\n 调度模型  一言蔽之，调度的本质就是 P 将 G 合理的分配给某个 M 的过程。\n  并发与并行区别 并发：指同一时刻有多条执行任务，CPU核心通过快速的切换时间单元实现的执行多任务。宏观上是同时的，但微观上仍是顺序执行的，只是进程间快速切换\n并行：值同一时刻，多条指令再多个CPU内核中同时执行，宏观和微观上都是同时执行的。\n","permalink":"https://nicko-ch.github.io/posts/2021/20210104-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-%E5%9F%BA%E7%A1%80/","summary":"new() 和 make() 的区别 看起来二者没有什么区别，都在堆上分配内存，但是它们的行为不同，适用于不同的类型。\n new(T) 为每个新的类型T分配一片内存，初始化为 0 并且返回类型为*T的内存地址：这种方法 返回一个指向类型为 T，值为 0 的地址的指针，它适用于值类型如数组和结构体；它相当于 \u0026amp;T{}。 make(T) 返回一个类型为 T 的初始值，它只适用于3种内建的引用类型：切片、map 和 channel。  换言之，new 函数分配内存，make 函数初始化；下图给出了区别：\n译者注：如何理解new、make、slice、map、channel的关系\n1.slice、map以及channel都是golang内建的一种引用类型，三者在内存中存在多个组成部分， 需要对内存组成部分初始化后才能使用，而make就是对三者进行初始化的一种操作方式\n2. new 获取的是存储指定变量内存地址的一个变量，对于变量内部结构并不会执行相应的初始化操作， 所以slice、map、channel需要make进行初始化并获取对应的内存地址，而非new简单的获取内存地址\n 编程内存模型  kernel内核区为操作系统专用 函数中局部变量是在stack中存放的 stack中的内存在函数结束后会被释放 函数中new和make声明的变量是在heap中存放的   fmt函数参数说明 基本\n%v\tthe value in a default format\rwhen printing structs, the plus flag (%+v) adds field names\r%#v\ta Go-syntax representation of the value\r%T\ta Go-syntax representation of the type of the value\r%%\ta literal percent sign; consumes no value\rThe default format for %v is:","title":"Go高级编程 - 基础"},{"content":"","permalink":"https://nicko-ch.github.io/posts/2020/20201231-go%E4%BC%98%E7%A7%80%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%88%86%E4%BA%AB/","summary":"","title":"Go优秀开源项目分享"},{"content":"   Title Link Description     Golang深入理解GPM模型 https://www.bilibili.com/video/BV19r4y1w7Nx    Golang中GC回收机制三色标记与混合写屏障 https://www.bilibili.com/video/BV1wz4y1y7Kd    Golang修养之路 https://www.kancloud.cn/aceld/golang/1858955    Go语言规范 https://golang.google.cn/ref/spec    GO 命令教程 https://github.com/hyper0x/go_command_tutorial    Go 语言性能优化 https://cch123.github.io/perf_opt/    图解 Go pprof 收集数据的工作流 https://mp.weixin.qq.com/s/HQzz2NQ2lSg_LLsNB7C-mw    7天用Go从零实现Web框架Gee教程 https://geektutu.com/post/gee.html    build-web-application-with-golang https://github.com/astaxie/build-web-application-with-golang    B站最深度的Golang学习到实战 up主强力推荐 https://www.bilibili.com/video/BV1TK4y1a7ex    Go contributor 解答：关于 Go GC 的 20 个核心问题 https://blog.csdn.net/RA681t58CJxsgCkJ31/article/details/103884524    Go 语言笔试面试题汇总 https://geektutu.com/post/qa-golang.html    Go 语言简明教程 https://geektutu.com/post/quick-golang.html    Go 语言高性能编程 https://geektutu.com/post/high-performance-go.html    Go语言高级编程(Advanced Go Programming) https://chai2010.gitbooks.io/advanced-go-programming-book/content/    关于Golang GC的一些误解\u0026ndash;真的比Java算法更领先吗？ https://mp.weixin.qq.com/s/eDd212DhjIRGpytBkgfzAg    图示Golang垃圾回收机制 https://zhuanlan.zhihu.com/p/297177002?utm_source=wechat_session\u0026amp;utm_medium=social\u0026amp;utm_oi=26711194337280\u0026amp;utm_campaign=shareopn    无闻 unknwon/the-way-to-go_ZH_CN https://github.com/unknwon/the-way-to-go_ZH_CN/blob/master/eBook/directory.md    bilibili技术总监毛剑：B站高可用架构实践 https://zhuanlan.zhihu.com/p/139258985     ","permalink":"https://nicko-ch.github.io/posts/2020/20201221-refference-go%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B/","summary":"Title Link Description     Golang深入理解GPM模型 https://www.bilibili.com/video/BV19r4y1w7Nx    Golang中GC回收机制三色标记与混合写屏障 https://www.bilibili.com/video/BV1wz4y1y7Kd    Golang修养之路 https://www.kancloud.cn/aceld/golang/1858955    Go语言规范 https://golang.google.cn/ref/spec    GO 命令教程 https://github.com/hyper0x/go_command_tutorial    Go 语言性能优化 https://cch123.github.io/perf_opt/    图解 Go pprof 收集数据的工作流 https://mp.weixin.qq.com/s/HQzz2NQ2lSg_LLsNB7C-mw    7天用Go从零实现Web框架Gee教程 https://geektutu.com/post/gee.html    build-web-application-with-golang https://github.com/astaxie/build-web-application-with-golang    B站最深度的Golang学习到实战 up主强力推荐 https://www.bilibili.com/video/BV1TK4y1a7ex    Go contributor 解答：关于 Go GC 的 20 个核心问题 https://blog.","title":"Refference - Go高级编程"},{"content":"array 数组 声明方式\nvar identifier [len]type // var arr [5]int  var arrAge = [5]int{18, 20, 15, 22, 16} // 声明容量为5的数组并初始化 var arrLazy = [...]int{5, 6, 7, 8, 22} // 初始化数组自动计算容量（实际上已是切片） var arrLazy = []int{5, 6, 7, 8, 22}\t// 初始化得到的实际上是切片slice var arrKeyValue = [5]string{3: \u0026#34;Chris\u0026#34;, 4: \u0026#34;Ron\u0026#34;} // 0,1,2 都未空值 var arrKeyValue = []string{3: \u0026#34;Chris\u0026#34;, 4: \u0026#34;Ron\u0026#34;}\t// 初始化得到的实际上是切片slice  slice 切片 本质\n不是一组数组的指针，是一种数据结构，用来操作内部元素。\n切片名称 [low : high : max] low: 起始下标位置 high: 结束下标位置 len = high - low max: 容量 cap = max - low 声明方式\nvar slice []type = arr[start:end] // 已存在arr数组时  var slice []type = make([]type, len) // 未生成数组时用make声明 var slice1 := make([]type, len) // 同上，简写  var s2 := make([]int, 10) // cap(s2) == len(s2) == 10  // make 函数参数 func make([]T, len, cap) 基本元素\n 数组与切片定义区别  创建数组时 [n] 指定数组长度 创建切片时 [] 为空，或者...\n  字符串与切片 内存结构\n修改字符串中的某个字符\n例如，将字符串 \u0026ldquo;hello\u0026rdquo; 转换为 \u0026ldquo;cello\u0026rdquo;：\ns := \u0026#34;hello\u0026#34; c := []byte(s) c[0] = \u0026#39;c\u0026#39; s2 := string(c) // s2 == \u0026#34;cello\u0026#34;  append函数常用操作 我们在第 7.5 节提到的 append 非常有用，它能够用于各种方面的操作：\n  将切片 b 的元素追加到切片 a 之后：a = append(a, b...)\n  复制切片 a 的元素到新的切片 b 上：\nb = make([]T, len(a))\rcopy(b, a)\n  删除位于索引 i 的元素：a = append(a[:i], a[i+1:]...)\n  切除切片 a 中从索引 i 至 j 位置的元素：a = append(a[:i], a[j:]...)\n  为切片 a 扩展 j 个元素长度：a = append(a, make([]T, j)...)\n  在索引 i 的位置插入元素 x：a = append(a[:i], append([]T{x}, a[i:]...)...)\n  在索引 i 的位置插入长度为 j 的新切片：a = append(a[:i], append(make([]T, j), a[i:]...)...)\n  在索引 i 的位置插入切片 b 的所有元素：a = append(a[:i], append(b, a[i:]...)...)\n  取出位于切片 a 最末尾的元素 x：x, a = a[len(a)-1], a[:len(a)-1]\n  将元素 x 追加到切片 a：a = append(a, x)\n  因此，您可以使用切片和 append 操作来表示任意可变长度的序列。\n从数学的角度来看，切片相当于向量，如果需要的话可以定义一个向量作为切片的别名来进行操作。\n如果您需要更加完整的方案，可以学习一下 Eleanor McHugh 编写的几个包：slices、chain 和 lists。\n map 字典 特点\nkey-value 键值对存储\nmap是无序的\n声明方式\nvar m1 = map[int]string // 声明map 赋值会出错 m2 := map[int]string{} // 声明并初始化map 可赋值 m3 := make(map[int]string) // 等值于m2  len(m2) // 获取map数量 ~~cap(m2)~~ // 报错!!! map不能使用cap方法  赋值\nkey值相同赋值会被覆盖\n判断是否key是否存在\nm2[key] 会返回两个值，第一个是value，第二个是bool代表key是否存在\nif v, has := m2[1]; has { fmt.Println(\u0026#34;value=\u0026#34;, v, \u0026#34;has=\u0026#34;, has) } 删除\ndelete(m2[1])  struct 结构体 声明方式\ntype Person struct { name string age int sex byte } var man Person = Person{\u0026#34;tedy\u0026#34;, \u0026#39;m\u0026#39;, 18} man2 := Person{name: \u0026#34;tedy\u0026#34;, sex: \u0026#39;f\u0026#39;} 传参方式\n默认值传递，一般不用，内存占用大，效率低\n结构体地址\n结构体指针变量的值 == 结构体首个元素的地址\n结构体指针内存模型\n强制自定义构建方法\ntype matrix struct { ... } func NewMatrix(params) *matrix { m := new(matrix) // 初始化 m  return m } package main import \u0026#34;matrix\u0026#34; ... wrong := new(matrix.matrix) // 编译失败（matrix 是私有的） right := matrix.NewMatrix(...) // 实例化 matrix 的唯一方式  字符串处理 // 按指定字符拆分 ret := strings.Split(str, \u0026#34;,\u0026#34;) // 按空格拆分 ret := strings.Fields(str) // 判断字符串结束标记 ret := strings.HasSuffix(\u0026#34;test.txt\u0026#34;, \u0026#34;.txt\u0026#34;) // 判断字符串起始标记 ret := strings.HasPrefix(\u0026#34;test.txt\u0026#34;, \u0026#34;test\u0026#34;)  文件操作 打开文件\n// 创建文件 // 不存在则创建，存在则清空 file, err := os.Create(\u0026#34;./file.txt\u0026#34;) if err != nil { fmt.Println(\u0026#34;create file error: \u0026#34;, err) } defer file.Close() fmt.Println(file) // 读取文件(只读) // 不存在读取失败 file, err := os.Open(\u0026#34;./file.txt\u0026#34;) if err != nil { fmt.Println(\u0026#34;Open file error: \u0026#34;, err) } defer file.Close() fmt.Println(file) // 读写文件(只读/只写/读写) file, err := os.OpenFile(\u0026#34;./file.txt\u0026#34;, os.O_CREATE|os.O_RDWR, 0755) if err != nil { fmt.Println(\u0026#34;OpenFile error: \u0026#34;, err) } defer file.Close() fmt.Println(file) 写文件\n// 写字符串 // windows \\r\\n // linux \\n writeByte, err := file.WriteString(\u0026#34;Hello world\\r\\n\u0026#34;) if err != nil { fmt.Println(\u0026#34;WriteString error: \u0026#34;, err) } fmt.Println(writeByte) // 获取光标 offset, _ := file.Seek(5, io.SeekStart) fmt.Println(offset) // 指定位置写入 writeByte, err := file.WriteAt([]byte(\u0026#34;1hello world\u0026#34;), offset) if err != nil { fmt.Println(\u0026#34;WriteAt error: \u0026#34;, err) } fmt.Println(writeByte) 读文件\n// 创建带有缓冲区的reader reader := bufio.NewReader(file) for { // 读取文件直到某字符 (按行读取) \treadByte, err := reader.ReadBytes(\u0026#39;\\n\u0026#39;) if err == io.EOF { fmt.Println(\u0026#34;ReadFile finished\u0026#34;) break } else if err != nil { fmt.Println(\u0026#34;ReadByte error: \u0026#34;, err) } fmt.Println(string(readByte)) }  读取文件目录 打开文件目录对象跟打开文件对象操作类似，FileMode 参数为 os.ModeDir\n通过Readdir获取到的是目录下的文件对象切片，切片内容为FileInfo接口，遍历操作即可\ntype FileInfo interface { Name() string // base name of the file \tSize() int64 // length in bytes for regular files; system-dependent for others \tMode() FileMode // file mode bits \tModTime() time.Time // modification time \tIsDir() bool // abbreviation for Mode().IsDir() \tSys() interface{} // underlying data source (can return nil) } // 读目录 dirinfo, err := os.OpenFile(\u0026#34;D:\\\\www\u0026#34;, os.O_RDONLY, os.ModeDir) if err != nil { fmt.Println(\u0026#34;OpenDifInfo error: \u0026#34;, err) } defer dirinfo.Close() fileInfo, err := dirinfo.Readdir(0) if err != nil { fmt.Println(\u0026#34;Readdir error: \u0026#34;, err) } for _, info := range fileInfo { if info.IsDir() { fmt.Println(\u0026#34;dir: \u0026#34;, info.Name()) } else { fmt.Println(\u0026#34;file: \u0026#34;, info.Name()) } }  runtime包 Gosched()：\n出让当前goroutine所占用的CPU时间片。当再次获得CPU时，从出让位置恢复继续执行\n— 时间片轮转调度算法\nGoexit()：\nreturn：返回当前函数调用者处。return之前的defer生效\nGoexit：结束当前该goroutine调用者处。goexit之前的defer生效\nGOMAXPROCS()：\n设置当前进程使用最大CPU核数，函数返回上一次调用成功的设置值，首次调用返回默认值。\n channel 通道 定义\nchdannel是一种数据类型，先进先出（FIFO）\n// 无缓冲通道 ch := make(chan int) ch := make(chan string, 0) // 读取 \u0026lt;- ch // 写入 ch \u0026lt;- // 读取和写入必须同时满足才能执行，否则一直阻塞等待  // 获取channel中剩余数据个数 len(ch) // 获取channel容量 cap(ch)  位运算 与运算 \u0026amp;\nA与B位中都为true则结果为true\n1 \u0026amp; 1 -\u0026gt; 1 1 \u0026amp; 0 -\u0026gt; 0 0 \u0026amp; 1 -\u0026gt; 0 0 \u0026amp; 0 -\u0026gt; 0 或运算 |\nA与B位中任意位为true则结果为true\n1 | 1 -\u0026gt; 1 1 | 0 -\u0026gt; 1 0 | 1 -\u0026gt; 1 0 | 0 -\u0026gt; 0 异或运算 ^\nA与B位相同则为false，不同则为true\n1 ^ 1 -\u0026gt; 0 1 ^ 0 -\u0026gt; 1 0 ^ 1 -\u0026gt; 1 0 ^ 0 -\u0026gt; 0 位清除 \u0026amp;^\nB位为true，则清零A位；B位为false，则A位保持不变；\n1 \u0026amp;^ 1 -\u0026gt; 0 1 \u0026amp;^ 0 -\u0026gt; 1 0 \u0026amp;^ 1 -\u0026gt; 0 0 \u0026amp;^ 0 -\u0026gt; 0 ","permalink":"https://nicko-ch.github.io/posts/2020/20201218-go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","summary":"array 数组 声明方式\nvar identifier [len]type // var arr [5]int  var arrAge = [5]int{18, 20, 15, 22, 16} // 声明容量为5的数组并初始化 var arrLazy = [...]int{5, 6, 7, 8, 22} // 初始化数组自动计算容量（实际上已是切片） var arrLazy = []int{5, 6, 7, 8, 22}\t// 初始化得到的实际上是切片slice var arrKeyValue = [5]string{3: \u0026#34;Chris\u0026#34;, 4: \u0026#34;Ron\u0026#34;} // 0,1,2 都未空值 var arrKeyValue = []string{3: \u0026#34;Chris\u0026#34;, 4: \u0026#34;Ron\u0026#34;}\t// 初始化得到的实际上是切片slice  slice 切片 本质\n不是一组数组的指针，是一种数据结构，用来操作内部元素。\n切片名称 [low : high : max] low: 起始下标位置 high: 结束下标位置 len = high - low max: 容量 cap = max - low 声明方式","title":"Go基础语法"},{"content":"Command 命令 git init 初始化仓库 $ git init Initialized empty Git repository in D:/www/git_class/.git/ git config 配置信息  —global [key] [value] 全局配置  $ git config --global user.name \u0026#39;Nicko_Ch\u0026#39; $ git config --global user.email cyn_411@sina.com git add {filename} 将文件添加到暂存区 $ touch README.md $ vim README.md $ git add README.md git status 查看项目的当前状态  -s 精简模式  $ git status On branch master Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: readme.txt $ git status -s M readme.txt git diff 比较文件暂存区与工作区的差异  git diff HEAD 查看所有改动 —cached 查看已缓存的改动 —stat 显示差异摘要（精简）  $ git diff warning: LF will be replaced by CRLF in readme.txt. The file will have its original line endings in your working directory diff --git a/readme.txt b/readme.txt index 9247db6..46d49bf 100644 --- a/readme.txt +++ b/readme.txt @@ -1,2 +1,2 @@ -Git is a distributed version control system. +Git is a version control system. Git is free software. git commit 将暂存区内容添加到仓库  -m 版本消息 -a 不需要执行git add命令，直接提交  $ git commit -m \u0026#34;wrote a readme file\u0026#34; [master (root-commit) f309a7b] wrote a readme file 1 file changed, 2 insertions(+) create mode 100644 readme.txt git log 查看提交记录  —pretty=oneline 单行模式（精简）  $ git log commit 2e4ced01341d4c11fee696d5501a54d9efe0b7d8 (HEAD -\u0026gt; master) Author: chenyaonan \u0026lt;chenyaonan@yy.com\u0026gt; Date: Wed Dec 16 10:54:08 2020 +0800 add GPL commit 441467e621e25042afa5a39d59f0d06e75bda3e6 Author: chenyaonan \u0026lt;chenyaonan@yy.com\u0026gt; Date: Wed Dec 16 10:33:48 2020 +0800 add distributed commit f309a7b35c0182eb5656a76c1342c869c1a283a6 Author: chenyaonan \u0026lt;chenyaonan@yy.com\u0026gt; Date: Wed Dec 16 10:18:42 2020 +0800 wrote a readme file $ git log --pretty=oneline 2e4ced01341d4c11fee696d5501a54d9efe0b7d8 (HEAD -\u0026gt; master) add GPL 441467e621e25042afa5a39d59f0d06e75bda3e6 add distributed f309a7b35c0182eb5656a76c1342c869c1a283a6 wrote a readme file git reflog 查看所有分支的提交记录 $ git reflog 441467e (HEAD -\u0026gt; master) HEAD@{0}: reset: moving to 4414 2e4ced0 HEAD@{1}: reset: moving to 2e4ced01341d4c11fee696d5501a54d9efe0b7d8 441467e (HEAD -\u0026gt; master) HEAD@{2}: reset: moving to HEAD^ 2e4ced0 HEAD@{3}: commit: add GPL 441467e (HEAD -\u0026gt; master) HEAD@{4}: commit: add distributed f309a7b HEAD@{5}: commit (initial): wrote a readme file git reset [HEAD] 回退到指定版本  —mixed 默认选项 —soft 保留工作区，并且重置到置顶版本（新差异放入暂存区） —hard 强制回滚（会删除版本信息）   HEAD 说明：\n  HEAD 表示当前版本 HEAD^ 上一个版本 HEAD^^ 上上一个版本 HEAD^^^ 上上上一个版本 以此类推\u0026hellip;  可以使用 ～数字表示\n HEAD~0 表示当前版本 HEAD~1 上一个版本 HEAD^2 上上一个版本 HEAD^3 上上上一个版本 以此类推\u0026hellip;    $ git reset --hard HEAD^ HEAD is now at 441467e add distributed git revert [HEAD] 撤销某次提交 $ git revert de5d349136589435 Removing rm.txt [master 5fb281e] Revert \u0026#34;add rm.txt\u0026#34; 1 file changed, 0 insertions(+), 0 deletions(-) delete mode 100644 rm.txt git checkout [HEAD] 切换分支 $ git checkout feature/20201212-learngit git checkout — [file] 撤销修改 $ git checkout -- readme.txt git rm [file] 删除文件 $ rm readme.txt $ git rm readme.txt rm \u0026#39;readme.txt\u0026#39; $ git commit -m \u0026#34;delete readme.txt\u0026#34; [master 625d001] delete readme.txt 1 file changed, 0 insertions(+), 0 deletions(-) delete mode 100644 readme.txt git tag 打标签  -l \u0026lsquo;keyword\u0026rsquo; 搜索标签名  $ git tag v1.0 $ git tag v1.0 // 后期打标签 $ git tag v0.1 a66325 ","permalink":"https://nicko-ch.github.io/posts/2020/20201216-git%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","summary":"Command 命令 git init 初始化仓库 $ git init Initialized empty Git repository in D:/www/git_class/.git/ git config 配置信息  —global [key] [value] 全局配置  $ git config --global user.name \u0026#39;Nicko_Ch\u0026#39; $ git config --global user.email cyn_411@sina.com git add {filename} 将文件添加到暂存区 $ touch README.md $ vim README.md $ git add README.md git status 查看项目的当前状态  -s 精简模式  $ git status On branch master Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;.","title":"Git基础语法"},{"content":"   Terms     分布式事务方式   bloom filter   Bitmap   nginx平滑重启原理   Linux内核特性之VDSO   NTP UPDATE 和 NTPD   QUICK   Head-of-line blocking   cgroup   Scaling Memcache At Facebook   errorgroup   pipeline   链表   bytegraph   neo4j   发号器   Graph DB   位与操作   网易DDB   sharding   SOA   DDD   Machine line   COW   \u0026ldquo;nginx_pool_t \u0026quot;   tcmalloc   sync.pool 对象池   内存池   内存碎片 内存对齐   微博redis关系链   redis-cluster   single fly 单飞模式   一致性哈希   有界负载一致性哈希   slot sharding   pipeline   databus   flink   LVS    ","permalink":"https://nicko-ch.github.io/posts/2020/20201215-terms/","summary":"Terms     分布式事务方式   bloom filter   Bitmap   nginx平滑重启原理   Linux内核特性之VDSO   NTP UPDATE 和 NTPD   QUICK   Head-of-line blocking   cgroup   Scaling Memcache At Facebook   errorgroup   pipeline   链表   bytegraph   neo4j   发号器   Graph DB   位与操作   网易DDB   sharding   SOA   DDD   Machine line   COW   \u0026ldquo;nginx_pool_t \u0026quot;   tcmalloc   sync.","title":"Terms"},{"content":"Laradock 切换 数据库5.7版本 1. 修改.env文件 源文件\n### MYSQL #################################################\rMYSQL_VERSION=latest\rMYSQL_DATABASE=default\rMYSQL_USER=default\rMYSQL_PASSWORD=secret\rMYSQL_PORT=3306\rMYSQL_ROOT_PASSWORD=root123456\rMYSQL_ENTRYPOINT_INITDB=./mysql/docker-entrypoint-initdb.d\r修改为\n### MYSQL #################################################\rMYSQL_VERSION=5.7.24\rMYSQL_DATABASE=default\rMYSQL_USER=default\rMYSQL_PASSWORD=secret\rMYSQL_PORT=3306\rMYSQL_ROOT_PASSWORD=root123456\rMYSQL_ENTRYPOINT_INITDB=./mysql/docker-entrypoint-initdb.d\r 2. 删除旧容器相关数据 2.1 列出所有容器 docker ps -a\r2.2 停止所有容器 docker ps -a\r2.3 删除容器 docker rm \u0026lt;容器ID1\u0026gt; \u0026lt;容器ID2\u0026gt; ...\r2.4 列出镜像 docker images\r2.5 删除镜像 docker rmi \u0026lt;镜像ID1\u0026gt; \u0026lt;镜像ID2\u0026gt; ...\r2.6 查看挂载盘 docker volume ls\r2.7 删除镜像 docker volume rm \u0026lt;VOLUME NAME1\u0026gt; \u0026lt;VOLUME NAME2\u0026gt; ...\r 3. 重新加载创建新容器 3.1 启动Mysql docker-compose up -d mysql\r 未清理干净残留数据可能导致错误 导致产生 Exited(2) 错误 mysql_1 | 2017-05-19T08:37:22.284861Z 0 [ERROR] InnoDB: posix_fallocate(): Failed to preallocate data for file ./mysql/time_zone.ibd, desired size 16384 bytes. Operating system error number 28. Check that the disk is not full or a disk quota exceeded. Make sure the file system supports this function. Some operating system error numbers are described at http://dev.mysql.com/doc/refman/5.7/en/ operating-system-error-codes.html\rmysql_1 | 2017-05-19T08:37:22.284915Z 0 [Warning] InnoDB: Retry attempts for writing partial data failed.\rmysql_1 | 2017-05-19T08:37:22.284923Z 0 [Warning] InnoDB: Error while writing 16384 zeroes to ./mysql/time_zone.ibd starting at offset 131072\rmysql_1 | 2017-05-19T08:37:22.335184Z 0 [ERROR] InnoDB: posix_fallocate(): Failed to preallocate data for file ./mysql/time_zone.ibd, desired size 16384 bytes. Operating system error number 28. Check that the disk is not full or a disk quota exceeded. Make sure the file system supports this function. Some operating system error numbers are described at http://dev.mysql.com/doc/refman/5.7/en/ operating-system-error-codes.html\rmysql_1 | 2017-05-19T08:37:22.335236Z 0 [Warning] InnoDB: Retry attempts for writing partial data failed.\rmysql_1 | 2017-05-19T08:37:22.335244Z 0 [Warning] InnoDB: Error while writing 16384 zeroes to ./mysql/time_zone.ibd starting at offset 131072\rmysql_1 | 2017-05-19T08:37:22.385395Z 0 [ERROR] InnoDB: posix_fallocate(): Failed to preallocate data for file ./mysql/time_zone.ibd, desired size 16384 bytes. Operating system error number 28. Check that the disk is not full or a disk quota exceeded. Make sure the file system supports this function. Some operating system error numbers are described at http://dev.mysql.com/doc/refman/5.7/en/ operating-system-error-codes.html\rmysql_1 | 2017-05-19T08:37:22.385444Z 0 [Warning] InnoDB: Retry attempts for writing partial data failed.\rmysql_1 | 2017-05-19T08:37:22.385452Z 0 [Warning] InnoDB: Error while writing 16384 zeroes to ./mysql/time_zone.ibd starting at offset 131072\rmysql_1 | 2017-05-19T08:37:22.435737Z 0 [ERROR] InnoDB: posix_fallocate(): Failed to preallocate data for file ./mysql/time_zone.ibd, desired size 16384 bytes. Operating system error number 28. Check that the disk is not full or a disk quota exceeded. Make sure the file system supports this function. Some operating system error numbers are described at http://dev.mysql.com/doc/refman/5.7/en/ operating-system-error-codes.html\rmysql_1 | 2017-05-19T08:37:22.435788Z 0 [Warning] InnoDB: Retry attempts for writing partial data failed.\rmysql_1 | 2017-05-19T08:37:22.435797Z 0 [Warning] InnoDB: Error while writing 16384 zeroes to ./mysql/time_zone.ibd starting at offset 131072\rmysql_1 | 2017-05-19T08:37:22.435957Z 0 [ERROR] [FATAL] InnoDB: Out of tablespace during rollback. Consider increasing your tablespace.\rmysql_1 | 2017-05-19 08:37:22 0x7fd031586700 InnoDB: Assertion failure in thread 140532157802240 in file ut0ut.cc line 916\rmysql_1 | InnoDB: We intentionally generate a memory trap.\rmysql_1 | InnoDB: Submit a detailed bug report to http://bugs.mysql.com.\rmysql_1 | InnoDB: If you get repeated assertion failures or crashes, even\rmysql_1 | InnoDB: immediately after the mysqld startup, there may be\rmysql_1 | InnoDB: corruption in the InnoDB tablespace. Please refer to\rmysql_1 | InnoDB: http://dev.mysql.com/doc/refman/5.7/en/forcing-innodb-recovery.html\rmysql_1 | InnoDB: about forcing recovery.\rmysql_1 | 08:37:22 UTC - mysqld got signal 6 ;\rmysql_1 | This could be because you hit a bug. It is also possible that this binary\rmysql_1 | or one of the libraries it was linked against is corrupt, improperly built,\rmysql_1 | or misconfigured. This error can also be caused by malfunctioning hardware.\rmysql_1 | Attempting to collect some information that could help diagnose the problem.\rmysql_1 | As this is a crash and something is definitely wrong, the information\rmysql_1 | collection process might fail.\rmysql_1 |\rmysql_1 | key_buffer_size=8388608\rmysql_1 | read_buffer_size=131072\rmysql_1 | max_used_connections=0\rmysql_1 | max_threads=151\rmysql_1 | thread_count=0\rmysql_1 | connection_count=0\rmysql_1 | It is possible that mysqld could use up to\rmysql_1 | key_buffer_size + (read_buffer_size + sort_buffer_size)*max_threads = 68190 K bytes of memory\rmysql_1 | Hope that's ok; if not, decrease some variables in the equation.\rmysql_1 |\rmysql_1 | Thread pointer: 0x0\rmysql_1 | Attempting backtrace. You can use the following information to find out\rmysql_1 | where mysqld died. If you see no messages after this, something went\rmysql_1 | terribly wrong...\rmysql_1 | stack_bottom = 0 thread_stack 0x40000\rmysql_1 | mysqld(my_print_stacktrace+0x2c)[0xe81c7c]\rmysql_1 | mysqld(handle_fatal_signal+0x459)[0x7aa4c9]\rmysql_1 | /lib/x86_64-linux-gnu/libpthread.so.0(+0xf890)[0x7fd04d101890]\rmysql_1 | /lib/x86_64-linux-gnu/libc.so.6(gsignal+0x37)[0x7fd04bb0a067]\rmysql_1 | /lib/x86_64-linux-gnu/libc.so.6(abort+0x148)[0x7fd04bb0b448]\rmysql_1 | mysqld[0x780c0b]\rmysql_1 | mysqld(_ZN2ib5fatalD1Ev+0x15d)[0x110b54d]\rmysql_1 | mysqld(_Z13row_undo_stepP9que_thr_t+0x66c)[0x109785c]\rmysql_1 | mysqld(_Z15que_run_threadsP9que_thr_t+0xa34)[0x1026a74]\rmysql_1 | mysqld(_Z31trx_rollback_or_clean_recoveredm+0xd2f)[0x10e693f]\rmysql_1 | mysqld(trx_rollback_or_clean_all_recovered+0x4e)[0x10e77de]\rmysql_1 | /lib/x86_64-linux-gnu/libpthread.so.0(+0x8064)[0x7fd04d0fa064]\rmysql_1 | /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7fd04bbbd62d]\rmysql_1 | The manual page at http://dev.mysql.com/doc/mysql/en/crashing.html contains\rmysql_1 | information that should help you find out what is causing the crash.\rlaradock_mysql_1 exited with code 2\r处理方法  删除容器挂载盘 清空mysql挂载目录  ~/.laradock/data (默认目录)\r 修改.env文件中mysql保存路径  # Choose storage path on your machine. For all storage systems\rDATA_PATH_HOST=~/.laradock/\u0026lt;project name\u0026gt;/data\r  ","permalink":"https://nicko-ch.github.io/posts/2018/20181107-laradock-%E5%88%87%E6%8D%A2%E6%95%B0%E6%8D%AE%E5%BA%93%E9%94%99%E8%AF%AF/","summary":"Laradock 切换 数据库5.7版本 1. 修改.env文件 源文件\n### MYSQL #################################################\rMYSQL_VERSION=latest\rMYSQL_DATABASE=default\rMYSQL_USER=default\rMYSQL_PASSWORD=secret\rMYSQL_PORT=3306\rMYSQL_ROOT_PASSWORD=root123456\rMYSQL_ENTRYPOINT_INITDB=./mysql/docker-entrypoint-initdb.d\r修改为\n### MYSQL #################################################\rMYSQL_VERSION=5.7.24\rMYSQL_DATABASE=default\rMYSQL_USER=default\rMYSQL_PASSWORD=secret\rMYSQL_PORT=3306\rMYSQL_ROOT_PASSWORD=root123456\rMYSQL_ENTRYPOINT_INITDB=./mysql/docker-entrypoint-initdb.d\r 2. 删除旧容器相关数据 2.1 列出所有容器 docker ps -a\r2.2 停止所有容器 docker ps -a\r2.3 删除容器 docker rm \u0026lt;容器ID1\u0026gt; \u0026lt;容器ID2\u0026gt; ...\r2.4 列出镜像 docker images\r2.5 删除镜像 docker rmi \u0026lt;镜像ID1\u0026gt; \u0026lt;镜像ID2\u0026gt; ...\r2.6 查看挂载盘 docker volume ls\r2.7 删除镜像 docker volume rm \u0026lt;VOLUME NAME1\u0026gt; \u0026lt;VOLUME NAME2\u0026gt; .","title":"Laradock 切换数据库错误"},{"content":"phpstorm 为了方便用户管理项目目录，目前可以将项目文件夹设置为 4 类 Test,Sources,Excluded,Resource Root。 1. Test (颜色为绿色) \u0026gt; 测试主目录，如 `Laravel` 的 `tests` 目录\r2. Source (颜色为蓝色) \u0026gt; 项目主代码目录，如 `Laravel` 的 `app` 目录\r3. Excluded (颜色为红色) \u0026gt; 第三方扩展依赖(不会修改代码)，不建立索引，不由`phpstorm`管理，如 `Laravel` 的 `vendor` 目录\r4. Resource Root (颜色为紫色) \u0026gt; 前端资源，如 `Laravel` 的 `public` 目录\r合理设置项目的目录是有作用的，如  1 设置 Test 目录，可以在project勾选只显示 Test,方便测试时查看 2 设置 Excluded 目录，可以减少 phpstorm 建立索引的时间 3 设置 Resource Root 目录，以 Laravel 为例，可以帮助检测模板文件的资源路径    ","permalink":"https://nicko-ch.github.io/posts/2018/20181101-phpstorm-%E9%A1%B9%E7%9B%AE%E7%9B%AE%E5%BD%95%E5%88%86%E7%B1%BB%E7%AE%A1%E7%90%86%E9%85%8D%E7%BD%AE/","summary":"phpstorm 为了方便用户管理项目目录，目前可以将项目文件夹设置为 4 类 Test,Sources,Excluded,Resource Root。 1. Test (颜色为绿色) \u0026gt; 测试主目录，如 `Laravel` 的 `tests` 目录\r2. Source (颜色为蓝色) \u0026gt; 项目主代码目录，如 `Laravel` 的 `app` 目录\r3. Excluded (颜色为红色) \u0026gt; 第三方扩展依赖(不会修改代码)，不建立索引，不由`phpstorm`管理，如 `Laravel` 的 `vendor` 目录\r4. Resource Root (颜色为紫色) \u0026gt; 前端资源，如 `Laravel` 的 `public` 目录\r合理设置项目的目录是有作用的，如  1 设置 Test 目录，可以在project勾选只显示 Test,方便测试时查看 2 设置 Excluded 目录，可以减少 phpstorm 建立索引的时间 3 设置 Resource Root 目录，以 Laravel 为例，可以帮助检测模板文件的资源路径    ","title":"PHPStorm 项目目录分类管理配置"},{"content":"『Cmd 技术渲染的沙箱页面，点击此处编写自己的文档』\nCmd Markdown 简明语法手册 标签： Cmd-Markdown\n 1. 斜体和粗体 使用 * 和 ** 表示斜体和粗体。\n示例：\n这是 斜体，这是 粗体。\n2. 分级标题 使用 === 表示一级标题，使用 \u0026mdash; 表示二级标题。\n示例：\n这是一个一级标题\r============================\r这是一个二级标题\r--------------------------------------------------\r### 这是一个三级标题\r你也可以选择在行首加井号表示不同级别的标题 (H1-H6)，例如：# H1, ## H2, ### H3，#### H4。\n3. 外链接 使用 [描述](链接地址) 为文字增加外链接。\n示例：\n这是去往 本人博客 的链接。\n4. 无序列表 使用 *，+，- 表示无序列表。\n示例：\n 无序列表项 一 无序列表项 二 无序列表项 三  5. 有序列表 使用数字和点表示有序列表。\n示例：\n 有序列表项 一 有序列表项 二 有序列表项 三  6. 文字引用 使用 \u0026gt; 表示文字引用。\n示例：\n 野火烧不尽，春风吹又生。\n 7. 行内代码块 使用 `代码` 表示行内代码块。\n示例：\n让我们聊聊 html。\n8. 代码块 使用 四个缩进空格 表示代码块。\n示例：\n这是一个代码块，此行左侧有四个不可见的空格。\r 9. 插入图像 使用 ![描述](图片链接地址) 插入图像。\n示例：\nCmd Markdown 高阶语法手册 1. 内容目录 在段落中填写 [TOC] 以显示全文内容的目录结构。\n[TOC]\n2. 标签分类 在编辑区任意行的列首位置输入以下代码给文稿标签：\n标签： 数学 英语 Markdown\n或者\nTags： 数学 英语 Markdown\n3. 删除线 使用 ~~ 表示删除线。\n这是一段错误的文本。\n4. 注脚 使用 [^keyword] 表示注脚。\n这是一个注脚1的样例。\n这是第二个注脚2的样例。\n5. LaTeX 公式 $ 表示行内公式：\n质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。\n$$ 表示整行公式：\n$$\\sum_{i=1}^n a_i=0$$\n$$f(x_1,x_x,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2 $$\n$$\\sum^{j-1}{k=0}{\\widehat{\\gamma}{kj} z_k}$$\n访问 MathJax 参考更多使用方法。\n6. 加强的代码块 支持四十一种编程语言的语法高亮的显示，行号显示。\n非代码示例：\n$ sudo apt-get install vim-gnome\rPython 示例：\n@requires_authorization def somefunc(param1=\u0026#39;\u0026#39;, param2=0): \u0026#39;\u0026#39;\u0026#39;A docstring\u0026#39;\u0026#39;\u0026#39; if param1 \u0026gt; param2: # interesting print \u0026#39;Greater\u0026#39; return (param2 - param1 + 1) or None class SomeClass: pass \u0026gt;\u0026gt;\u0026gt; message = \u0026#39;\u0026#39;\u0026#39;interpreter ... prompt\u0026#39;\u0026#39;\u0026#39; JavaScript 示例：\n/** * nth element in the fibonacci series. * @param n \u0026gt;= 0 * @return the nth element, \u0026gt;= 0. */ function fib(n) { var a = 1, b = 1; var tmp; while (--n \u0026gt;= 0) { tmp = a; a += b; b = tmp; } return a; } document.write(fib(10)); 7. 流程图 示例 st=\u0026gt;start: Start:\u0026gt;https://www.zybuluo.com\rio=\u0026gt;inputoutput: verification\rop=\u0026gt;operation: Your Operation\rcond=\u0026gt;condition: Yes or No?\rsub=\u0026gt;subroutine: Your Subroutine\re=\u0026gt;end\rst-\u0026gt;io-\u0026gt;op-\u0026gt;cond\rcond(yes)-\u0026gt;e\rcond(no)-\u0026gt;sub-\u0026gt;io\r更多语法参考：流程图语法参考 8. 序列图 示例 1 Alice-\u0026gt;Bob: Hello Bob, how are you?\rNote right of Bob: Bob thinks\rBob--\u0026gt;Alice: I am good thanks!\r示例 2 sequenceDiagram\rTitle: Here is a title\rA-\u0026gt;B: Normal line\rB--\u0026gt;C: Dashed line\rC-\u0026gt;\u0026gt;D: Open arrow\rD--\u0026gt;\u0026gt;A: Dashed open arrow\r更多语法参考：序列图语法参考 9. 甘特图 甘特图内在思想简单。基本是一条线条图，横轴表示时间，纵轴表示活动（项目），线条表示在整个期间上计划和实际的活动完成情况。它直观地表明任务计划在什么时候进行，及实际进展与计划要求的对比。\ngantt\rdateFormat YYYY-MM-DD\rtitle Adding GANTT diagram functionality to mermaid\rsection A section\rCompleted task :done, des1, 2014-01-06,2014-01-08\rActive task :active, des2, 2014-01-09, 3d\rFuture task : des3, after des2, 5d\rFuture task2 : des4, after des3, 5d\rsection Critical tasks\rCompleted task in the critical line :crit, done, 2014-01-06,24h\rImplement parser and jison :crit, done, after des1, 2d\rCreate tests for parser :crit, active, 3d\rFuture task in critical line :crit, 5d\rCreate tests for renderer :2d\rAdd to mermaid :1d\rsection Documentation\rDescribe gantt syntax :active, a1, after des1, 3d\rAdd gantt diagram to demo page :after a1 , 20h\rAdd another diagram to demo page :doc1, after a1 , 48h\rsection Last section\rDescribe gantt syntax :after doc1, 3d\rAdd gantt diagram to demo page :20h\rAdd another diagram to demo page :48h\r更多语法参考：甘特图语法参考 10. Mermaid 流程图 graph LR\rA[Hard edge] --\u0026gt;|Link text| B(Round edge)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result one]\rC --\u0026gt;|Two| E[Result two]\r更多语法参考：Mermaid 流程图语法参考 11. Mermaid 序列图 sequenceDiagram\rAlice-\u0026gt;John: Hello John, how are you?\rJohn--\u0026gt;Alice: Great!\r更多语法参考：Mermaid 序列图语法参考 12. 表格支持    项目 价格 数量     计算机 $1600 5   手机 $12 12   管线 $1 234    13. 定义型列表  名词 1 定义 1（左侧有一个可见的冒号和四个不可见的空格） 代码块 2 这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格） 代码块（左侧有八个不可见的空格）\r   14. Html 标签 本站支持在 Markdown 语法中嵌套 Html 标签，譬如，你可以用 Html 写一个纵跨两行的表格：\n\u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th rowspan=\u0026#34;2\u0026#34;\u0026gt;值班人员\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;星期一\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;星期二\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;星期三\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;李强\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;张明\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;王平\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; 15. 内嵌图标 本站的图标系统对外开放，在文档中输入\n\u0026lt;i class=\u0026quot;icon-weibo\u0026quot;\u0026gt;\u0026lt;/i\u0026gt;\r 即显示微博的图标： 替换 上述 i 标签 内的 icon-weibo 以显示不同的图标，例如：\n\u0026lt;i class=\u0026quot;icon-renren\u0026quot;\u0026gt;\u0026lt;/i\u0026gt;\r 即显示人人的图标： 更多的图标和玩法可以参看 font-awesome 官方网站。\n16. 待办事宜 Todo 列表 使用带有 [ ] 或 [x] （未完成或已完成）项的列表语法撰写一个待办事宜列表，并且支持子列表嵌套以及混用Markdown语法，例如：\n- [ ] **Cmd Markdown 开发** - [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 - [ ] 支持以 PDF 格式导出文稿 - [x] 新增Todo列表功能 [语法参考](https://github.com/blog/1375-task-lists-in-gfm-issues-pulls-comments) - [x] 改进 LaTex 功能 - [x] 修复 LaTex 公式渲染问题 - [x] 新增 LaTex 公式编号功能 [语法参考](http://docs.mathjax.org/en/latest/tex.html#tex-eq-numbers) - [ ] **七月旅行准备** - [ ] 准备邮轮上需要携带的物品 - [ ] 浏览日本免税店的物品 - [x] 购买蓝宝石公主号七月一日的船票 对应显示如下待办事宜 Todo 列表：\n Cmd Markdown 开发  改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 支持以 PDF 格式导出文稿 新增Todo列表功能 语法参考 改进 LaTex 功能  修复 LaTex 公式渲染问题 新增 LaTex 公式编号功能 语法参考     七月旅行准备  准备邮轮上需要携带的物品 浏览日本免税店的物品 购买蓝宝石公主号七月一日的船票        这是一个 注脚 的 文本。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n 这是另一个 注脚 的 文本。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://nicko-ch.github.io/posts/2018/20181031-md%E7%AE%80%E6%98%8E%E8%AF%AD%E6%B3%95%E6%89%8B%E5%86%8C/","summary":"『Cmd 技术渲染的沙箱页面，点击此处编写自己的文档』\nCmd Markdown 简明语法手册 标签： Cmd-Markdown\n 1. 斜体和粗体 使用 * 和 ** 表示斜体和粗体。\n示例：\n这是 斜体，这是 粗体。\n2. 分级标题 使用 === 表示一级标题，使用 \u0026mdash; 表示二级标题。\n示例：\n这是一个一级标题\r============================\r这是一个二级标题\r--------------------------------------------------\r### 这是一个三级标题\r你也可以选择在行首加井号表示不同级别的标题 (H1-H6)，例如：# H1, ## H2, ### H3，#### H4。\n3. 外链接 使用 [描述](链接地址) 为文字增加外链接。\n示例：\n这是去往 本人博客 的链接。\n4. 无序列表 使用 *，+，- 表示无序列表。\n示例：\n 无序列表项 一 无序列表项 二 无序列表项 三  5. 有序列表 使用数字和点表示有序列表。\n示例：\n 有序列表项 一 有序列表项 二 有序列表项 三  6.","title":"Cmd Markdown 简明语法手册"},{"content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start Create a new post $ hexo new \u0026#34;My New Post\u0026#34; More info: Writing\nRun server $ hexo server More info: Server\nGenerate static files $ hexo generate More info: Generating\nDeploy to remote sites $ hexo deploy More info: Deployment\n  ","permalink":"https://nicko-ch.github.io/posts/2018/20181023-quick-start/","summary":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start Create a new post $ hexo new \u0026#34;My New Post\u0026#34; More info: Writing\nRun server $ hexo server More info: Server\nGenerate static files $ hexo generate More info: Generating\nDeploy to remote sites $ hexo deploy More info: Deployment","title":"Hello World"},{"content":"Prerequisites 1. install hugo //下载hugo编译文件 2. install git Add Content 新增文章\nhugo new posts/my-first-post.md 修改文章属性\n--- title: \u0026#34;My First Post\u0026#34; categoried: 分类 date: 2022-11-20T09:03:20-08:00 tags: - 标签1 - 标签2 draft: true --- Debug hugo server -D\t//启动服务 -D 生成草稿 Publish hugo -D\t//生成草稿 git commit //git提交github.io Hugo Help PS W:\\www\\nicko-ch.github.io\u0026gt; hugo help hugo is the main command, used to build your Hugo site. Hugo is a Fast and Flexible Static Site Generator built with love by spf13 and friends in Go. Complete documentation is available at http://gohugo.io/. Usage: hugo [flags] hugo [command] Available Commands: completion generate the autocompletion script for the specified shell config Print the site configuration convert Convert your content to different formats deploy Deploy your site to a Cloud provider. env Print Hugo version and environment info gen A collection of several useful generators. help Help about any command import Import your site from others. list Listing out various types of content mod Various Hugo Modules helpers. new Create new content for your site server A high performance webserver version Print the version number of Hugo Flags: -b, --baseURL string hostname (and path) to the root, e.g. http://spf13.com/ -D, --buildDrafts include content marked as draft -E, --buildExpired include expired content -F, --buildFuture include content with publishdate in the future --cacheDir string filesystem path to cache directory. Defaults: $TMPDIR/hugo_cache/ --cleanDestinationDir remove files from destination not found in static directories --config string config file (default is path/config.yaml|json|toml) --configDir string config dir (default \u0026#34;config\u0026#34;) -c, --contentDir string filesystem path to content directory --debug debug output -d, --destination string filesystem path to write files to --disableKinds strings disable different kind of pages (home, RSS etc.) --enableGitInfo add Git revision, date and author info to the pages -e, --environment string build environment --forceSyncStatic copy all files when static is changed. --gc enable to run some cleanup tasks (remove unused cache files) after the build -h, --help help for hugo --i18n-warnings print missing translations --ignoreCache ignores the cache directory --ignoreVendor ignores any _vendor directory --ignoreVendorPaths string ignores any _vendor for module paths matching the given Glob pattern -l, --layoutDir string filesystem path to layout directory --log enable Logging --logFile string log File path (if set, logging enabled automatically) --minify minify any supported output format (HTML, XML etc.) --noChmod don\u0026#39;t sync permission mode of files --noTimes don\u0026#39;t sync modification time of files --path-warnings print warnings on duplicate target paths etc. --poll string set this to a poll interval, e.g --poll 700ms, to use a poll based approach to watch for file system changes --print-mem print memory usage to screen at intervals --quiet build in quiet mode --renderToMemory render to memory (only useful for benchmark testing) -s, --source string filesystem path to read files relative from --templateMetrics display metrics about template executions --templateMetricsHints calculate some improvement hints when combined with --templateMetrics -t, --theme strings themes to use (located in /themes/THEMENAME/) --themesDir string filesystem path to themes directory --trace file write trace to file (not useful in general) -v, --verbose verbose output --verboseLog verbose logging -w, --watch watch filesystem for changes and recreate as needed Additional help topics: hugo check Contains some verification checks Use \u0026#34;hugo [command] --help\u0026#34; for more information about a command. ","permalink":"https://nicko-ch.github.io/posts/hugo-readme/","summary":"Prerequisites 1. install hugo //下载hugo编译文件 2. install git Add Content 新增文章\nhugo new posts/my-first-post.md 修改文章属性\n--- title: \u0026#34;My First Post\u0026#34; categoried: 分类 date: 2022-11-20T09:03:20-08:00 tags: - 标签1 - 标签2 draft: true --- Debug hugo server -D\t//启动服务 -D 生成草稿 Publish hugo -D\t//生成草稿 git commit //git提交github.io Hugo Help PS W:\\www\\nicko-ch.github.io\u0026gt; hugo help hugo is the main command, used to build your Hugo site. Hugo is a Fast and Flexible Static Site Generator built with love by spf13 and friends in Go.","title":"Hugo Readme"}]